{"cells":[{"cell_type":"markdown","metadata":{"id":"BHGcaBXxr_gX"},"source":["# **Exploring Mental Health - Playground Series PS4S11**\n"]},{"cell_type":"markdown","metadata":{"id":"ELxf-BAZsK3a"},"source":["# **Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3mJUoMYTlZcv","executionInfo":{"status":"ok","timestamp":1731955534044,"user_tz":180,"elapsed":228458,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["%%capture\n","\n","# AutoGluon is a SOTA AutoML framework\n","%pip install -q setuptools wheel autogluon.tabular[all,skex] dask[dataframe]\n","%pip install -U -q ipywidgets cloudpickle==2.2.1"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"soYGIyeQevY3","executionInfo":{"status":"ok","timestamp":1731955534044,"user_tz":180,"elapsed":3,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["# %%capture\n","\n","# # LightGBM GPU instalation (restart after installing)\n","# ! git clone --recursive https://github.com/Microsoft/LightGBM\n","\n","# #You can run this oneliner which will build and compile LightGBM with GPU enabled in colab:\n","# ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n","# !mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HV_YRkKhsIWF","executionInfo":{"status":"ok","timestamp":1731955535889,"user_tz":180,"elapsed":1847,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import os\n","import cloudpickle\n","import re\n","from autogluon.tabular import TabularDataset, TabularPredictor\n","from sklearn.metrics import accuracy_score\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21819,"status":"ok","timestamp":1731955557705,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":180},"id":"tFezKkAIsOdk","outputId":"6271e4dd-9565-43b7-ddc2-d4c0ee456bbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"8G5UhLChsOwS","executionInfo":{"status":"ok","timestamp":1731955563886,"user_tz":180,"elapsed":6183,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["base_path = os.getenv('DATA_FOLDER_PATH', '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/')\n","\n","train_data = TabularDataset(os.path.join(base_path, 'train_cleaned.csv'))\n","test_data = TabularDataset(os.path.join(base_path, 'test_cleaned.csv'))\n","submission = TabularDataset(os.path.join(base_path, 'sample_submission.csv'))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VCNA2qwYuWGd","executionInfo":{"status":"ok","timestamp":1731955563886,"user_tz":180,"elapsed":7,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["train_data.drop(columns=['is_original', 'cgpa_bucket'], inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"-qO-SyBMw0Lf"},"source":["# **Autogluon 8hr Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28832482,"status":"ok","timestamp":1731482450783,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"5YYdKDeqwvM1","outputId":"494bfbac-c4b5-4f9a-ad7c-b0997edd5ea2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu\"\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.1.1\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          8\n","Memory Avail:       48.77 GB / 50.99 GB (95.6%)\n","Disk Space Avail:   184.02 GB / 235.68 GB (78.1%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=10, num_bag_sets=10\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 7200s of the 28800s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-11-12 23:20:21,166\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=8093)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Beginning AutoGluon training ... Time limit = 7196s\n","\u001b[36m(_dystack pid=8093)\u001b[0m AutoGluon will save models to \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=8093)\u001b[0m Train Data Rows:    127338\n","\u001b[36m(_dystack pid=8093)\u001b[0m Train Data Columns: 17\n","\u001b[36m(_dystack pid=8093)\u001b[0m Label Column:       depression\n","\u001b[36m(_dystack pid=8093)\u001b[0m Problem Type:       binary\n","\u001b[36m(_dystack pid=8093)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","\u001b[36m(_dystack pid=8093)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tAvailable Memory:                    49397.98 MB\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tTrain Data (Original)  Memory Usage: 50.39 MB (0.1% of available memory)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('float', [])  : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('int', [])    : 5 | ['is_female', 'age', 'is_student', 'suicidal_thoughts', 'family_history']\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('object', []) : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('category', [])  : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('float', [])     : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('int', [])       : 1 | ['age']\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t\t('int', ['bool']) : 4 | ['is_female', 'is_student', 'suicidal_thoughts', 'family_history']\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.5s = Fit runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t17 features in original data used to generate 17 features in processed data.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tTrain Data (Processed) Memory Usage: 8.87 MB (0.0% of available memory)\n","\u001b[36m(_dystack pid=8093)\u001b[0m Data preprocessing and feature engineering runtime = 0.55s ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=8093)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=8093)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=8093)\u001b[0m {\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=8093)\u001b[0m }\n","\u001b[36m(_dystack pid=8093)\u001b[0m AutoGluon will fit 4 stack levels (L1 to L4) ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting 108 L1 models ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2397.87s of the 7195.39s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=8510)\u001b[0m 1 warning generated.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1506\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t73.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t2.99s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 2319.27s of the 7116.79s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1511\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t64.78s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t2.54s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2252.61s of the 7050.13s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1679\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t9.03s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.46s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2238.85s of the 7036.37s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1671\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t8.64s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.88s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 2225.01s of the 7022.54s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\u001b[36m(_ray_fit pid=10127)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10248)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10384)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10506)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10634)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10758)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10890)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=11010)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=11133)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=11259)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1493\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t137.05s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.24s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2086.11s of the 6883.63s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1668\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t5.72s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.87s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2074.63s of the 6872.15s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1664\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t5.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2061.25s of the 6858.77s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.22%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1525\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1224.53s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 834.74s of the 5632.27s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:30] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17177)\u001b[0m \n","\u001b[36m(_ray_fit pid=17177)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:36] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17230)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17230)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17230)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17230)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17230)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17279)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:43] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17332)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17332)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17332)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17332)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17332)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:44] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17381)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:50] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17430)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17430)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17430)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17430)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17430)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:51] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17484)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:57] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17533)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:54] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17533)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17533)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17533)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17533)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:46:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17584)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1508\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t32.41s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.35s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 800.62s of the 5598.15s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1534\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t447.79s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.5s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 351.2s of the 5148.72s of remaining time.\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:47:00] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:47:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [23:47:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=17639)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.16%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1524\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t106.04s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.65s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 242.96s of the 5040.48s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\u001b[36m(_ray_fit pid=20879)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=21054)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=21226)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=21400)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=21572)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1512\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t46.33s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 194.99s of the 4992.51s of remaining time.\n","\u001b[36m(_ray_fit pid=21661)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1524\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t180.49s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.57s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 12.8s of the 4810.32s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.3098\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t32.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.45s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4775.8s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.467, 'LightGBM_BAG_L1': 0.133, 'NeuralNetFastAI_BAG_L1': 0.133, 'LightGBMXT_BAG_L1': 0.067, 'XGBoost_BAG_L1': 0.067, 'NeuralNetTorch_BAG_L1': 0.067, 'NeuralNetTorch_r79_BAG_L1': 0.067}\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1485\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.66s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting 108 L2 models ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2121.72s of the 4774.97s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.24%)\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_ray_fit pid=23534)\u001b[0m 1 warning generated.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1503\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t55.17s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 2064.8s of the 4718.05s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.24%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1499\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t48.79s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.65s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 2014.17s of the 4667.42s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1638\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t25.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.31s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1983.52s of the 4636.77s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1647\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t26.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.92s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1952.12s of the 4605.37s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.25%)\n","\u001b[36m(_ray_fit pid=25132)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25236)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25345)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25461)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25567)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25663)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25769)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25875)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=25979)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=26075)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1493\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t86.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1864.44s of the 4517.69s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1619\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t6.59s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.64s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1851.89s of the 4505.14s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1618\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t6.52s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.87s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1839.15s of the 4492.4s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.38%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.151\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1177.22s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.86s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 659.89s of the 3313.13s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.32%)\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:09] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=31746)\u001b[0m \n","\u001b[36m(_ray_fit pid=31746)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:16] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31799)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=31799)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=31799)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=31799)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=31799)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=31849)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:23] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=31904)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=31904)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=31904)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=31904)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=31904)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=31955)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:30] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32008)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=32008)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=32008)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=32008)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=32008)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=32057)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:37] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32110)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=32110)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=32110)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=32110)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=32110)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=32161)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1494\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t33.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.4s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 624.72s of the 3277.97s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.21%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1514\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t404.62s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.97s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 218.36s of the 2871.6s of remaining time.\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:41] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:25:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=32214)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1505\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t86.84s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.24s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 129.6s of the 2782.85s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.25%)\n","\u001b[36m(_ray_fit pid=35208)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=35378)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=35546)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=35716)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=35888)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1505\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t42.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 85.6s of the 2738.85s of remaining time.\n","\u001b[36m(_ray_fit pid=35971)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.21%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1511\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t88.22s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.07s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2647.64s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 0.36, 'XGBoost_BAG_L2': 0.24, 'NeuralNetFastAI_BAG_L2': 0.12, 'NeuralNetTorch_r79_BAG_L2': 0.12, 'NeuralNetTorch_BAG_L2': 0.08, 'ExtraTreesGini_BAG_L2': 0.04, 'ExtraTreesEntr_BAG_L2': 0.04}\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1489\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting 108 L3 models ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 1764.24s of the 2646.93s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1505\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t48.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.83s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBM_BAG_L3 ... Training model for up to 1713.52s of the 2596.21s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1503\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t47.88s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.59s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 1663.93s of the 2546.62s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.167\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t23.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.23s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 1634.87s of the 2517.56s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1653\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t25.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.93s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_BAG_L3 ... Training model for up to 1604.51s of the 2487.2s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.24%)\n","\u001b[36m(_ray_fit pid=38472)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=38586)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=38692)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=38792)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=38898)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=38990)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=39090)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=39186)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=39284)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=39393)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1498\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t81.27s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 1521.57s of the 2404.26s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1637\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t7.05s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.21s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 1508.85s of the 2391.54s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1631\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t6.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.4s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 1496.37s of the 2379.06s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.37%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1508\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1108.95s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.97s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: XGBoost_BAG_L3 ... Training model for up to 385.42s of the 1268.11s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.31%)\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:14] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=44772)\u001b[0m \n","\u001b[36m(_ray_fit pid=44772)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:21] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44825)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=44825)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=44825)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=44825)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=44825)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=44874)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:28] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=44929)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=44929)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=44929)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=44929)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=44929)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:29] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=44978)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:36] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45031)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=45031)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=45031)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=45031)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=45031)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:36] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=45080)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:43] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45133)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=45133)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=45133)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=45133)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=45133)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:44] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=45188)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1499\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t34.58s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.43s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 349.08s of the 1231.77s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.20%)\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:47] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1516\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t299.04s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.98s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 48.18s of the 930.87s of remaining time.\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [00:59:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=45241)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.27%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1515\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t62.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.92s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the 864.77s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tEnsemble Weights: {'XGBoost_BAG_L3': 0.353, 'CatBoost_BAG_L3': 0.294, 'NeuralNetFastAI_BAG_L3': 0.176, 'NeuralNetTorch_BAG_L3': 0.118, 'ExtraTreesEntr_BAG_L3': 0.059}\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1494\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.51s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting 108 L4 models ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 864.19s of the 864.09s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.22%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1512\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t49.75s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: LightGBM_BAG_L4 ... Training model for up to 812.58s of the 812.49s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.22%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1509\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t48.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 762.14s of the 762.05s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1679\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t22.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.44s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 734.93s of the 734.84s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1665\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t23.76s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t3.54s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: CatBoost_BAG_L4 ... Training model for up to 706.76s of the 706.67s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\u001b[36m(_ray_fit pid=49258)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49360)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49466)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49570)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49666)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49770)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49868)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=49972)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=50068)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=50166)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1503\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t78.57s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 626.5s of the 626.41s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.165\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t6.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 614.25s of the 614.16s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1644\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t6.72s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t4.18s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 601.96s of the 601.87s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.35%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1513\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t466.32s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.88s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: XGBoost_BAG_L4 ... Training model for up to 133.68s of the 133.59s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.29%)\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:09] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:09] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=52918)\u001b[0m \n","\u001b[36m(_ray_fit pid=52918)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:15] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=52971)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=52971)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=52971)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=52971)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=52971)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53021)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:22] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53074)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53074)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53074)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53074)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53074)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:23] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53123)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:29] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53174)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53174)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53174)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53174)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53174)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53227)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:36] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53276)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53276)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53276)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53276)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53276)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:36] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53325)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1504\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t32.32s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.4s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 99.62s of the 99.53s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1529\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t107.29s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.89s\t = Validation runtime\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:39] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m /usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [01:18:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=53380)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_dystack pid=8093)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: WeightedEnsemble_ALL_L5 ... Training model for up to 360.0s of the -10.95s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.36, 'NeuralNetFastAI_BAG_L1': 0.12, 'XGBoost_BAG_L1': 0.12, 'CatBoost_BAG_L2': 0.12, 'NeuralNetTorch_r79_BAG_L1': 0.08, 'XGBoost_BAG_L2': 0.08, 'ExtraTreesGini_BAG_L2': 0.04, 'NeuralNetTorch_BAG_L2': 0.04, 'XGBoost_BAG_L3': 0.04}\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1486\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t1.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the -12.15s of remaining time.\n","\u001b[36m(_dystack pid=8093)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L4': 0.333, 'XGBoost_BAG_L4': 0.333, 'NeuralNetFastAI_BAG_L4': 0.238, 'ExtraTreesEntr_BAG_L4': 0.048, 'NeuralNetTorch_BAG_L4': 0.048}\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t-0.1499\t = Validation score   (-log_loss)\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=8093)\u001b[0m AutoGluon training complete, total runtime = 7208.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1400.9 rows/s (12734 batch size)\n","\u001b[36m(_dystack pid=8093)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu/ds_sub_fit/sub_fit_ho\")\n","\u001b[36m(_dystack pid=8093)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n","Leaderboard on holdout data (DyStack):\n","                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0         WeightedEnsemble_L3      -0.149960  -0.148886    log_loss       24.082763      42.341197  4177.769649                 0.007214                0.002960           0.551790            3       True         29\n","1     WeightedEnsemble_ALL_L5      -0.150031  -0.148566    log_loss       27.707831      53.883126  4498.089552                 0.008713                0.002971           1.091011            5       True         52\n","2              XGBoost_BAG_L2      -0.150095  -0.149435    log_loss       16.324207      28.800141  2408.027665                 1.070303                0.403730          33.452028            2       True         24\n","3         WeightedEnsemble_L2      -0.150100  -0.148521    log_loss        9.397622       9.092962  2161.550804                 0.009042                0.003251           0.655280            2       True         15\n","4         WeightedEnsemble_L4      -0.150219  -0.149373    log_loss       32.906410      61.361445  5993.457453                 0.019980                0.003397           0.507820            4       True         41\n","5             LightGBM_BAG_L2      -0.150273  -0.149930    log_loss       15.498331      29.045876  2423.364894                 0.244427                0.649466          48.789258            2       True         17\n","6              XGBoost_BAG_L3      -0.150288  -0.149868    log_loss       27.699118      53.880155  4496.998541                 0.788787                0.428807          34.582407            3       True         38\n","7           LightGBMXT_BAG_L2      -0.150352  -0.150302    log_loss       15.550746      29.296576  2429.742012                 0.296843                0.900166          55.166376            2       True         16\n","8             CatBoost_BAG_L2      -0.150375  -0.149326    log_loss       15.396454      28.526096  2460.594899                 0.142551                0.129685          86.019263            2       True         20\n","9      NeuralNetFastAI_BAG_L3      -0.150540  -0.150796    log_loss       29.742628      55.421855  5571.364101                 2.832297                1.970507        1108.947967            3       True         37\n","10        WeightedEnsemble_L5      -0.150581  -0.149899    log_loss       41.947642      83.544105  6901.063466                 0.004983                0.003160           0.452369            5       True         53\n","11            CatBoost_BAG_L3      -0.150584  -0.149818    log_loss       27.047791      53.579437  4543.685785                 0.137459                0.128089          81.269651            3       True         34\n","12             XGBoost_BAG_L4      -0.150609  -0.150354    log_loss       37.027494      76.465659  6241.714100                 0.757906                0.401823          32.318623            4       True         50\n","13            CatBoost_BAG_L1      -0.150638  -0.149317    log_loss        0.492501       0.240873   137.046785                 0.492501                0.240873         137.046785            1       True          5\n","14     NeuralNetFastAI_BAG_L2      -0.150656  -0.151046    log_loss       18.023425      30.255626  3551.791368                 2.769522                1.859215        1177.215731            2       True         23\n","15          LightGBMXT_BAG_L3      -0.150707  -0.150493    log_loss       27.228915      54.277512  4511.375508                 0.318584                0.826163          48.959374            3       True         30\n","16            LightGBM_BAG_L3      -0.150726  -0.150267    log_loss       27.191169      54.040656  4510.292767                 0.280838                0.589307          47.876633            3       True         31\n","17  NeuralNetTorch_r79_BAG_L2      -0.150752  -0.151053    log_loss       16.743087      29.461981  2462.797320                 1.489184                1.065570          88.221684            2       True         28\n","18       LightGBMLarge_BAG_L2      -0.150805  -0.150538    log_loss       16.108440      29.632839  2461.417869                 0.854536                1.236428          86.842233            2       True         26\n","19            CatBoost_BAG_L4      -0.151048  -0.150300    log_loss       36.411434      76.186231  6287.965557                 0.141846                0.122395          78.570080            4       True         46\n","20     NeuralNetFastAI_BAG_L4      -0.151140  -0.151324    log_loss       38.881912      77.947850  6675.712654                 2.612324                1.884013         466.317177            4       True         49\n","21            LightGBM_BAG_L4      -0.151165  -0.150904    log_loss       36.686897      76.725398  6258.024470                 0.417309                0.661562          48.628993            4       True         43\n","22             XGBoost_BAG_L1      -0.151205  -0.150775    log_loss        1.139037       0.346952    32.410904                 1.139037                0.346952          32.410904            1       True          9\n","23          LightGBMXT_BAG_L1      -0.151243  -0.150621    log_loss        0.771038       2.992522    73.855886                 0.771038                2.992522          73.855886            1       True          1\n","24          LightGBMXT_BAG_L4      -0.151282  -0.151218    log_loss       36.801030      76.965606  6259.140826                 0.531442                0.901770          49.745348            4       True         42\n","25       LightGBMLarge_BAG_L1      -0.151467  -0.152410    log_loss        1.062371       3.652330   106.036454                 1.062371                3.652330         106.036454            1       True         11\n","26       LightGBMLarge_BAG_L3      -0.151477  -0.151465    log_loss       27.477171      54.371339  4525.379475                 0.566840                0.919990          62.963341            3       True         40\n","27       CatBoost_r177_BAG_L2      -0.151600  -0.150481    log_loss       15.354857      28.491726  2416.817927                 0.100953                0.095316          42.242291            2       True         27\n","28            LightGBM_BAG_L1      -0.151783  -0.151134    log_loss        0.657549       2.543968    64.775362                 0.657549                2.543968          64.775362            1       True          2\n","29      NeuralNetTorch_BAG_L4      -0.151987  -0.152939    log_loss       37.439049      76.953071  6316.686737                 1.169461                0.889235         107.291260            4       True         51\n","30      NeuralNetTorch_BAG_L2      -0.152142  -0.151396    log_loss       16.630947      29.367500  2779.195806                 1.377043                0.971090         404.620169            2       True         25\n","31     NeuralNetFastAI_BAG_L1      -0.152239  -0.152515    log_loss        4.670539       1.891429  1224.528853                 4.670539                1.891429        1224.528853            1       True          8\n","32      NeuralNetTorch_BAG_L3      -0.152243  -0.151624    log_loss       28.169433      54.434090  4761.453255                 1.259101                0.982741         299.037121            3       True         39\n","33       CatBoost_r177_BAG_L1      -0.152408  -0.151209    log_loss        0.098885       0.097780    46.334716                 0.098885                0.097780          46.334716            1       True         12\n","34  NeuralNetTorch_r79_BAG_L1      -0.152864  -0.152361    log_loss        0.810184       0.571019   180.492376                 0.810184                0.571019         180.492376            1       True         13\n","35      ExtraTreesEntr_BAG_L3      -0.154157  -0.163080    log_loss       27.868786      57.847905  4469.112486                 0.958454                4.396556           6.696352            3       True         36\n","36      NeuralNetTorch_BAG_L1      -0.154639  -0.153367    log_loss        0.847731       0.502947   447.785357                 0.847731                0.502947         447.785357            1       True         10\n","37      ExtraTreesEntr_BAG_L4      -0.154732  -0.164387    log_loss       37.261121      80.243478  6216.113958                 0.991533                4.179642           6.718481            4       True         48\n","38      ExtraTreesEntr_BAG_L2      -0.155663  -0.161798    log_loss       16.229231      33.269754  2381.100215                 0.975327                4.873343           6.524579            2       True         22\n","39      ExtraTreesGini_BAG_L2      -0.155878  -0.161924    log_loss       16.251619      33.035603  2381.164406                 0.997716                4.639193           6.588770            2       True         21\n","40      ExtraTreesGini_BAG_L4      -0.156205  -0.164989    log_loss       37.328961      80.076588  6216.311903                 1.059373                4.012752           6.916425            4       True         47\n","41    RandomForestEntr_BAG_L2      -0.157087  -0.164669    log_loss       15.892740      32.314298  2401.272687                 0.638836                3.917888          26.697050            2       True         19\n","42      ExtraTreesGini_BAG_L3      -0.157614  -0.163717    log_loss       27.938278      57.661710  4469.470453                 1.027947                4.210361           7.054319            3       True         35\n","43    RandomForestEntr_BAG_L3      -0.157790  -0.165284    log_loss       27.474942      57.382945  4488.044820                 0.564611                3.931596          25.628687            3       True         33\n","44    RandomForestEntr_BAG_L1      -0.159066  -0.167111    log_loss        0.924320       3.879140     8.641810                 0.924320                3.879140           8.641810            1       True          4\n","45    RandomForestGini_BAG_L1      -0.159217  -0.167914    log_loss        0.920321       3.459626     9.029559                 0.920321                3.459626           9.029559            1       True          3\n","46    RandomForestGini_BAG_L3      -0.161062  -0.166972    log_loss       27.534669      57.679718  4486.379624                 0.624338                4.228370          23.963491            3       True         32\n","47      ExtraTreesEntr_BAG_L1      -0.161128  -0.166353    log_loss        1.303264       3.898246     5.774649                 1.303264                3.898246           5.774649            1       True          7\n","48    RandomForestEntr_BAG_L4      -0.161234  -0.166468    log_loss       36.943419      79.604013  6233.158326                 0.673831                3.540177          23.762849            4       True         45\n","49      ExtraTreesGini_BAG_L1      -0.161336  -0.166825    log_loss        1.366870       3.865709     5.721500                 1.366870                3.865709           5.721500            1       True          6\n","50    RandomForestGini_BAG_L2      -0.162256  -0.163820    log_loss       15.953090      32.710258  2400.036704                 0.699187                4.313848          25.461067            2       True         18\n","51    RandomForestGini_BAG_L4      -0.162363  -0.167867    log_loss       36.993763      79.508093  6232.223009                 0.724175                3.444257          22.827532            4       True         44\n","52       LightGBM_r131_BAG_L1      -0.310393  -0.309787    log_loss        0.189293       0.453868    32.141424                 0.189293                0.453868          32.141424            1       True         14\n","\t3\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t7262s\t = DyStack   runtime |\t21538s\t = Remaining runtime\n","Starting main fit with num_stack_levels=3.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=3)`\n","Beginning AutoGluon training ... Time limit = 21538s\n","AutoGluon will save models to \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu\"\n","Train Data Rows:    143256\n","Train Data Columns: 17\n","Label Column:       depression\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    48448.74 MB\n","\tTrain Data (Original)  Memory Usage: 56.67 MB (0.1% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])  : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\t\t('int', [])    : 5 | ['is_female', 'age', 'is_student', 'suicidal_thoughts', 'family_history']\n","\t\t('object', []) : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\t\t('float', [])     : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\t\t('int', [])       : 1 | ['age']\n","\t\t('int', ['bool']) : 4 | ['is_female', 'is_student', 'suicidal_thoughts', 'family_history']\n","\t0.6s = Fit runtime\n","\t17 features in original data used to generate 17 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 9.98 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.67s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","AutoGluon will fit 4 stack levels (L1 to L4) ...\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L1 models ...\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7177.21s of the 21536.99s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\t-0.1507\t = Validation score   (-log_loss)\n","\t75.38s\t = Training   runtime\n","\t3.53s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 7099.1s of the 21458.88s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\t-0.1512\t = Validation score   (-log_loss)\n","\t69.63s\t = Training   runtime\n","\t2.92s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 7027.51s of the 21387.29s of remaining time.\n","\t-0.1666\t = Validation score   (-log_loss)\n","\t9.87s\t = Training   runtime\n","\t4.53s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 7011.64s of the 21371.42s of remaining time.\n","\t-0.1674\t = Validation score   (-log_loss)\n","\t9.78s\t = Training   runtime\n","\t4.56s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 6995.88s of the 21355.67s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t136.58s\t = Training   runtime\n","\t0.23s\t = Validation runtime\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 6857.62s of the 21217.41s of remaining time.\n","\t-0.1635\t = Validation score   (-log_loss)\n","\t6.58s\t = Training   runtime\n","\t4.93s\t = Validation runtime\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 6842.29s of the 21202.08s of remaining time.\n","\t-0.1651\t = Validation score   (-log_loss)\n","\t6.98s\t = Training   runtime\n","\t5.18s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6828.22s of the 21188.0s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\t-0.1528\t = Validation score   (-log_loss)\n","\t1410.97s\t = Training   runtime\n","\t2.14s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 5415.25s of the 19775.03s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\t-0.1502\t = Validation score   (-log_loss)\n","\t33.18s\t = Training   runtime\n","\t0.37s\t = Validation runtime\n","Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5380.39s of the 19740.17s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\t-0.1531\t = Validation score   (-log_loss)\n","\t484.74s\t = Training   runtime\n","\t0.55s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4893.98s of the 19253.76s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.16%)\n","\t-0.1519\t = Validation score   (-log_loss)\n","\t110.2s\t = Training   runtime\n","\t3.96s\t = Validation runtime\n","Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4781.57s of the 19141.36s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t99.48s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4680.51s of the 19040.29s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\t-0.1514\t = Validation score   (-log_loss)\n","\t589.11s\t = Training   runtime\n","\t0.62s\t = Validation runtime\n","Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 4089.7s of the 18449.49s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n","\t-0.1501\t = Validation score   (-log_loss)\n","\t244.64s\t = Training   runtime\n","\t21.39s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 3840.55s of the 18200.34s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\t-0.1514\t = Validation score   (-log_loss)\n","\t1993.88s\t = Training   runtime\n","\t2.06s\t = Validation runtime\n","Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1844.69s of the 16204.47s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\t-0.1509\t = Validation score   (-log_loss)\n","\t123.85s\t = Training   runtime\n","\t0.42s\t = Validation runtime\n","Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1719.15s of the 16078.94s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t229.7s\t = Training   runtime\n","\t21.0s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1485.65s of the 15845.43s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\t-0.1523\t = Validation score   (-log_loss)\n","\t600.55s\t = Training   runtime\n","\t0.53s\t = Validation runtime\n","Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 883.34s of the 15243.12s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n","\t-0.151\t = Validation score   (-log_loss)\n","\t86.41s\t = Training   runtime\n","\t0.66s\t = Validation runtime\n","Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 795.24s of the 15155.02s of remaining time.\n","\t-0.1713\t = Validation score   (-log_loss)\n","\t10.67s\t = Training   runtime\n","\t4.52s\t = Validation runtime\n","Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 777.75s of the 15137.53s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n","\t-0.1499\t = Validation score   (-log_loss)\n","\t84.6s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 691.54s of the 15051.32s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\t-0.1539\t = Validation score   (-log_loss)\n","\t243.17s\t = Training   runtime\n","\t0.5s\t = Validation runtime\n","Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 446.68s of the 14806.46s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\t-0.1527\t = Validation score   (-log_loss)\n","\t105.04s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 340.03s of the 14699.82s of remaining time.\n","\t-0.1789\t = Validation score   (-log_loss)\n","\t19.84s\t = Training   runtime\n","\t4.34s\t = Validation runtime\n","Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 314.82s of the 14674.6s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.16%)\n","\t-0.1506\t = Validation score   (-log_loss)\n","\t113.99s\t = Training   runtime\n","\t4.9s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 198.58s of the 14558.36s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.23%)\n","\t-0.1625\t = Validation score   (-log_loss)\n","\t157.36s\t = Training   runtime\n","\t4.03s\t = Validation runtime\n","Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 39.13s of the 14398.92s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t36.25s\t = Training   runtime\n","\t0.39s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1.23s of the 14361.01s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n","\tTime limit exceeded... Skipping NeuralNetTorch_r30_BAG_L1.\n","Completed 1/10 k-fold bagging repeats ...\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 717.72s of the 14355.96s of remaining time.\n","\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.28, 'XGBoost_r89_BAG_L1': 0.2, 'XGBoost_BAG_L1': 0.08, 'NeuralNetTorch_r79_BAG_L1': 0.08, 'LightGBM_r131_BAG_L1': 0.08, 'NeuralNetFastAI_r191_BAG_L1': 0.08, 'LightGBM_r96_BAG_L1': 0.08, 'NeuralNetTorch_r22_BAG_L1': 0.08, 'NeuralNetFastAI_r102_BAG_L1': 0.04}\n","\t-0.1483\t = Validation score   (-log_loss)\n","\t1.19s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L2 models ...\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6378.27s of the 14354.51s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.35%)\n","\t-0.1498\t = Validation score   (-log_loss)\n","\t58.8s\t = Training   runtime\n","\t1.03s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L2 ... Training model for up to 6317.59s of the 14293.83s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.35%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t59.58s\t = Training   runtime\n","\t0.82s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 6256.12s of the 14232.35s of remaining time.\n","\t-0.1652\t = Validation score   (-log_loss)\n","\t47.17s\t = Training   runtime\n","\t5.87s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 6202.14s of the 14178.38s of remaining time.\n","\t-0.1631\t = Validation score   (-log_loss)\n","\t47.96s\t = Training   runtime\n","\t5.77s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L2 ... Training model for up to 6147.58s of the 14123.82s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.36%)\n","\t-0.1491\t = Validation score   (-log_loss)\n","\t96.71s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 6049.06s of the 14025.3s of remaining time.\n","\t-0.16\t = Validation score   (-log_loss)\n","\t9.17s\t = Training   runtime\n","\t6.56s\t = Validation runtime\n","Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 6031.96s of the 14008.19s of remaining time.\n","\t-0.1619\t = Validation score   (-log_loss)\n","\t9.77s\t = Training   runtime\n","\t6.48s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6014.31s of the 13990.55s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.56%)\n","\t-0.1505\t = Validation score   (-log_loss)\n","\t1324.31s\t = Training   runtime\n","\t2.16s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L2 ... Training model for up to 4687.81s of the 12664.05s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.47%)\n","\t-0.149\t = Validation score   (-log_loss)\n","\t41.94s\t = Training   runtime\n","\t0.58s\t = Validation runtime\n","Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4643.98s of the 12620.22s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.31%)\n","\t-0.1511\t = Validation score   (-log_loss)\n","\t472.74s\t = Training   runtime\n","\t1.59s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4169.12s of the 12145.35s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.40%)\n","\t-0.1501\t = Validation score   (-log_loss)\n","\t104.49s\t = Training   runtime\n","\t1.42s\t = Validation runtime\n","Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 4062.65s of the 12038.88s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.37%)\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t74.14s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 3986.6s of the 11962.83s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.31%)\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t536.3s\t = Training   runtime\n","\t1.66s\t = Validation runtime\n","Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 3448.37s of the 11424.61s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.36%)\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t142.09s\t = Training   runtime\n","\t4.0s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 3304.02s of the 11280.26s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.56%)\n","\t-0.1497\t = Validation score   (-log_loss)\n","\t1858.22s\t = Training   runtime\n","\t2.16s\t = Validation runtime\n","Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 1443.61s of the 9419.84s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.47%)\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t93.74s\t = Training   runtime\n","\t0.31s\t = Validation runtime\n","Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 1348.05s of the 9324.28s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.34%)\n","\t-0.1492\t = Validation score   (-log_loss)\n","\t105.33s\t = Training   runtime\n","\t3.77s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 1240.57s of the 9216.81s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.31%)\n","\t-0.1499\t = Validation score   (-log_loss)\n","\t546.68s\t = Training   runtime\n","\t1.62s\t = Validation runtime\n","Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 691.85s of the 8668.09s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.71%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t94.39s\t = Training   runtime\n","\t0.89s\t = Validation runtime\n","Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 595.56s of the 8571.79s of remaining time.\n","\t-0.1634\t = Validation score   (-log_loss)\n","\t28.75s\t = Training   runtime\n","\t6.3s\t = Validation runtime\n","Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 559.47s of the 8535.7s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.34%)\n","\t-0.1492\t = Validation score   (-log_loss)\n","\t61.92s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 495.66s of the 8471.89s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.56%)\n","\t-0.1505\t = Validation score   (-log_loss)\n","\t257.33s\t = Training   runtime\n","\t0.57s\t = Validation runtime\n","Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 236.4s of the 8212.64s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.47%)\n","\t-0.1775\t = Validation score   (-log_loss)\n","\t58.96s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 175.63s of the 8151.87s of remaining time.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.68s compared to 17.56s of available time.\n","\tTime limit exceeded... Skipping RandomForest_r195_BAG_L2.\n","Completed 1/10 k-fold bagging repeats ...\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 637.83s of the 7872.34s of remaining time.\n","\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L2': 0.16, 'NeuralNetFastAI_r191_BAG_L2': 0.16, 'XGBoost_r33_BAG_L2': 0.16, 'NeuralNetTorch_r22_BAG_L2': 0.12, 'CatBoost_BAG_L2': 0.08, 'XGBoost_BAG_L2': 0.08, 'CatBoost_r9_BAG_L2': 0.08, 'RandomForestGini_BAG_L2': 0.04, 'RandomForestEntr_BAG_L2': 0.04, 'ExtraTreesGini_BAG_L2': 0.04, 'NeuralNetFastAI_BAG_L2': 0.04}\n","\t-0.1484\t = Validation score   (-log_loss)\n","\t1.07s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L3 models ...\n","Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 5246.15s of the 7871.03s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.32%)\n","\t-0.15\t = Validation score   (-log_loss)\n","\t55.62s\t = Training   runtime\n","\t0.96s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L3 ... Training model for up to 5188.7s of the 7813.59s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.32%)\n","\t-0.1499\t = Validation score   (-log_loss)\n","\t56.5s\t = Training   runtime\n","\t0.79s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 5130.31s of the 7755.2s of remaining time.\n","\t-0.1664\t = Validation score   (-log_loss)\n","\t41.86s\t = Training   runtime\n","\t5.57s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 5082.0s of the 7706.89s of remaining time.\n","\t-0.1637\t = Validation score   (-log_loss)\n","\t44.1s\t = Training   runtime\n","\t5.55s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L3 ... Training model for up to 5031.52s of the 7656.41s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.33%)\n","\t-0.1494\t = Validation score   (-log_loss)\n","\t90.62s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 4938.98s of the 7563.87s of remaining time.\n","\t-0.1625\t = Validation score   (-log_loss)\n","\t9.24s\t = Training   runtime\n","\t5.95s\t = Validation runtime\n","Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 4922.42s of the 7547.31s of remaining time.\n","\t-0.1633\t = Validation score   (-log_loss)\n","\t9.29s\t = Training   runtime\n","\t6.33s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 4905.36s of the 7530.25s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.51%)\n","\t-0.1506\t = Validation score   (-log_loss)\n","\t1387.84s\t = Training   runtime\n","\t2.15s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L3 ... Training model for up to 3515.34s of the 6140.23s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.43%)\n","\t-0.1495\t = Validation score   (-log_loss)\n","\t39.25s\t = Training   runtime\n","\t0.55s\t = Validation runtime\n","Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 3474.28s of the 6099.17s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n","\t-0.1514\t = Validation score   (-log_loss)\n","\t446.24s\t = Training   runtime\n","\t1.45s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 3026.12s of the 5651.0s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.37%)\n","\t-0.1505\t = Validation score   (-log_loss)\n","\t101.0s\t = Training   runtime\n","\t1.43s\t = Validation runtime\n","Fitting model: CatBoost_r177_BAG_L3 ... Training model for up to 2923.17s of the 5548.05s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.33%)\n","\t-0.1495\t = Validation score   (-log_loss)\n","\t69.96s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r79_BAG_L3 ... Training model for up to 2851.46s of the 5476.34s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n","\t-0.1496\t = Validation score   (-log_loss)\n","\t546.12s\t = Training   runtime\n","\t1.49s\t = Validation runtime\n","Fitting model: LightGBM_r131_BAG_L3 ... Training model for up to 2303.29s of the 4928.17s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.33%)\n","\t-0.1497\t = Validation score   (-log_loss)\n","\t148.65s\t = Training   runtime\n","\t4.59s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_r191_BAG_L3 ... Training model for up to 2152.33s of the 4777.22s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.51%)\n","\t-0.1497\t = Validation score   (-log_loss)\n","\t1710.55s\t = Training   runtime\n","\t2.15s\t = Validation runtime\n","Fitting model: CatBoost_r9_BAG_L3 ... Training model for up to 439.62s of the 3064.51s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.43%)\n","\t-0.1496\t = Validation score   (-log_loss)\n","\t68.91s\t = Training   runtime\n","\t0.24s\t = Validation runtime\n","Fitting model: LightGBM_r96_BAG_L3 ... Training model for up to 368.88s of the 2993.77s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.31%)\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t96.76s\t = Training   runtime\n","\t3.13s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r22_BAG_L3 ... Training model for up to 270.08s of the 2894.97s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n","\t-0.1503\t = Validation score   (-log_loss)\n","\t235.45s\t = Training   runtime\n","\t1.45s\t = Validation runtime\n","Fitting model: XGBoost_r33_BAG_L3 ... Training model for up to 32.7s of the 2657.58s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.65%)\n","\t-0.2351\t = Validation score   (-log_loss)\n","\t41.32s\t = Training   runtime\n","\t0.55s\t = Validation runtime\n","Completed 1/10 k-fold bagging repeats ...\n","Fitting model: WeightedEnsemble_L4 ... Training model for up to 524.61s of the 2612.85s of remaining time.\n","\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L3': 0.2, 'NeuralNetFastAI_r191_BAG_L3': 0.2, 'XGBoost_BAG_L3': 0.16, 'CatBoost_r9_BAG_L3': 0.12, 'CatBoost_BAG_L3': 0.08, 'CatBoost_r177_BAG_L3': 0.08, 'NeuralNetTorch_r22_BAG_L3': 0.08, 'NeuralNetFastAI_BAG_L3': 0.04, 'LightGBM_r96_BAG_L3': 0.04}\n","\t-0.1489\t = Validation score   (-log_loss)\n","\t0.98s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L4 models ...\n","Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 2611.77s of the 2611.63s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.29%)\n","\t-0.1507\t = Validation score   (-log_loss)\n","\t55.81s\t = Training   runtime\n","\t1.03s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L4 ... Training model for up to 2554.08s of the 2553.94s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.29%)\n","\t-0.1503\t = Validation score   (-log_loss)\n","\t54.65s\t = Training   runtime\n","\t0.73s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 2497.6s of the 2497.46s of remaining time.\n","\t-0.1663\t = Validation score   (-log_loss)\n","\t40.71s\t = Training   runtime\n","\t5.73s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 2450.26s of the 2450.11s of remaining time.\n","\t-0.1647\t = Validation score   (-log_loss)\n","\t42.27s\t = Training   runtime\n","\t5.43s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L4 ... Training model for up to 2401.75s of the 2401.6s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.30%)\n","\t-0.1498\t = Validation score   (-log_loss)\n","\t92.4s\t = Training   runtime\n","\t0.16s\t = Validation runtime\n","Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 2307.59s of the 2307.45s of remaining time.\n","\t-0.1616\t = Validation score   (-log_loss)\n","\t9.69s\t = Training   runtime\n","\t6.4s\t = Validation runtime\n","Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 2290.01s of the 2289.86s of remaining time.\n","\t-0.1623\t = Validation score   (-log_loss)\n","\t9.17s\t = Training   runtime\n","\t6.25s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 2273.09s of the 2272.94s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.46%)\n","\t-0.1515\t = Validation score   (-log_loss)\n","\t1351.93s\t = Training   runtime\n","\t2.15s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L4 ... Training model for up to 918.96s of the 918.81s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.39%)\n","\t-0.1498\t = Validation score   (-log_loss)\n","\t38.65s\t = Training   runtime\n","\t0.51s\t = Validation runtime\n","Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 878.45s of the 878.31s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.25%)\n","\t-0.1519\t = Validation score   (-log_loss)\n","\t460.1s\t = Training   runtime\n","\t1.29s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 416.46s of the 416.32s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.33%)\n","\t-0.1508\t = Validation score   (-log_loss)\n","\t98.92s\t = Training   runtime\n","\t1.45s\t = Validation runtime\n","Fitting model: CatBoost_r177_BAG_L4 ... Training model for up to 315.5s of the 315.36s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.30%)\n","\t-0.1499\t = Validation score   (-log_loss)\n","\t56.17s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: NeuralNetTorch_r79_BAG_L4 ... Training model for up to 257.59s of the 257.44s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.25%)\n","\t-0.1503\t = Validation score   (-log_loss)\n","\t226.99s\t = Training   runtime\n","\t1.36s\t = Validation runtime\n","Fitting model: LightGBM_r131_BAG_L4 ... Training model for up to 28.67s of the 28.52s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=0.30%)\n","\t-0.2112\t = Validation score   (-log_loss)\n","\t45.74s\t = Training   runtime\n","\t0.48s\t = Validation runtime\n","Completed 1/10 k-fold bagging repeats ...\n","Fitting model: WeightedEnsemble_ALL_L5 ... Training model for up to 360.0s of the -20.84s of remaining time.\n","\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.2, 'XGBoost_r33_BAG_L2': 0.2, 'XGBoost_r89_BAG_L1': 0.16, 'LightGBM_r96_BAG_L1': 0.12, 'NeuralNetTorch_r22_BAG_L2': 0.12, 'NeuralNetTorch_r79_BAG_L2': 0.08, 'NeuralNetFastAI_r191_BAG_L2': 0.08, 'XGBoost_BAG_L2': 0.04}\n","\t-0.1483\t = Validation score   (-log_loss)\n","\t1.19s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L5 ... Training model for up to 360.0s of the -22.17s of remaining time.\n","\tEnsemble Weights: {'XGBoost_BAG_L4': 0.3, 'NeuralNetTorch_r79_BAG_L4': 0.25, 'CatBoost_BAG_L4': 0.2, 'NeuralNetFastAI_BAG_L4': 0.1, 'ExtraTreesGini_BAG_L4': 0.05, 'ExtraTreesEntr_BAG_L4': 0.05, 'CatBoost_r177_BAG_L4': 0.05}\n","\t-0.1493\t = Validation score   (-log_loss)\n","\t0.69s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 21560.68s ... Best model: WeightedEnsemble_ALL_L5 | Estimated inference throughput: 178.4 rows/s (14326 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_8hr_logloss_gpu\")\n"]},{"data":{"text/plain":["<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f0a0f8110f0>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Setting up\n","eval_metric = 'log_loss'\n","label = 'depression'\n","problem_type='binary'\n","hours = 8\n","\n","# Models to exclude\n","excluded_model_types = ['KNN']\n","\n","# Initialize the TabularPredictor\n","predictor = TabularPredictor(label=label, eval_metric=eval_metric, problem_type=problem_type,\n","                             path = os.path.join(base_path, \"Autogluon/202411_ps4s11_8hr_logloss_gpu\"))\n","\n","# Fit the model\n","predictor.fit(train_data=train_data,\n","              time_limit=3600*hours,\n","              presets=\"best_quality\",\n","              excluded_model_types=excluded_model_types,\n","              num_bag_folds=10,\n","              num_bag_sets = 10,\n","              num_stack_levels=3,\n","              full_weighted_ensemble_additionally=True,\n","              ag_args_fit={'num_gpus': 1}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvsNeUB70NGo"},"outputs":[],"source":["predictor = TabularPredictor.load(os.path.join(base_path, \"Autogluon/202411_ps4s11_8hr_logloss_gpu\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1731527065835,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"dK0srrbKxUTl","outputId":"9a0f751a-581d-458b-9f8a-37e8109f7e43"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"leaderboard_test\",\n  \"rows\": 88,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 88,\n        \"samples\": [\n          \"RandomForestEntr_BAG_L4\",\n          \"WeightedEnsemble_ALL_L5\",\n          \"LightGBM_r131_BAG_L3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012664578212208151,\n        \"min\": -0.2350883578901334,\n        \"max\": -0.14825548127557167,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          -0.16474786549813697,\n          -0.14825548127557167,\n          -0.1497337608058815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"log_loss\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73.43206581886602,\n        \"min\": 0.10644316673278809,\n        \"max\": 214.25622153282166,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          202.7502682209015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6807.533002173773,\n        \"min\": 6.576993703842163,\n        \"max\": 20207.870808839798,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          18464.43694448471\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.560834363817346,\n        \"min\": 0.003289937973022461,\n        \"max\": 21.391040325164795,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          5.434172868728638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 428.5827291823893,\n        \"min\": 0.6913657188415527,\n        \"max\": 1993.8779871463776,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          42.26586627960205\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 1,\n        \"max\": 88,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"leaderboard_test"},"text/html":["\n","  <div id=\"df-05c87736-644a-45d8-a06d-7f19206d04f2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_ALL_L5</td>\n","      <td>-0.148255</td>\n","      <td>log_loss</td>\n","      <td>105.585109</td>\n","      <td>10171.116691</td>\n","      <td>0.003628</td>\n","      <td>1.185391</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-0.148289</td>\n","      <td>log_loss</td>\n","      <td>46.990007</td>\n","      <td>4071.147295</td>\n","      <td>0.003508</td>\n","      <td>1.193801</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>-0.148385</td>\n","      <td>log_loss</td>\n","      <td>126.403947</td>\n","      <td>11790.050694</td>\n","      <td>0.003290</td>\n","      <td>1.067314</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>WeightedEnsemble_L4</td>\n","      <td>-0.148872</td>\n","      <td>log_loss</td>\n","      <td>164.148464</td>\n","      <td>17469.321232</td>\n","      <td>0.005054</td>\n","      <td>0.978731</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>XGBoost_BAG_L2</td>\n","      <td>-0.148991</td>\n","      <td>log_loss</td>\n","      <td>99.243326</td>\n","      <td>7134.348668</td>\n","      <td>0.584466</td>\n","      <td>41.935683</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CatBoost_BAG_L2</td>\n","      <td>-0.149090</td>\n","      <td>log_loss</td>\n","      <td>98.804893</td>\n","      <td>7189.119752</td>\n","      <td>0.146032</td>\n","      <td>96.706767</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LightGBM_r96_BAG_L2</td>\n","      <td>-0.149216</td>\n","      <td>log_loss</td>\n","      <td>102.429577</td>\n","      <td>7197.745426</td>\n","      <td>3.770716</td>\n","      <td>105.332442</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>CatBoost_r137_BAG_L2</td>\n","      <td>-0.149249</td>\n","      <td>log_loss</td>\n","      <td>98.787518</td>\n","      <td>7154.330236</td>\n","      <td>0.128657</td>\n","      <td>61.917252</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>LightGBM_r131_BAG_L2</td>\n","      <td>-0.149251</td>\n","      <td>log_loss</td>\n","      <td>102.657257</td>\n","      <td>7234.507014</td>\n","      <td>3.998396</td>\n","      <td>142.094029</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>NeuralNetTorch_r79_BAG_L2</td>\n","      <td>-0.149260</td>\n","      <td>log_loss</td>\n","      <td>100.322798</td>\n","      <td>7628.715830</td>\n","      <td>1.663937</td>\n","      <td>536.302845</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05c87736-644a-45d8-a06d-7f19206d04f2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-05c87736-644a-45d8-a06d-7f19206d04f2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-05c87736-644a-45d8-a06d-7f19206d04f2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-12438465-a9e3-4a90-a461-b3bedce8d78c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12438465-a9e3-4a90-a461-b3bedce8d78c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-12438465-a9e3-4a90-a461-b3bedce8d78c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                       model  score_val eval_metric  pred_time_val  \\\n","0    WeightedEnsemble_ALL_L5  -0.148255    log_loss     105.585109   \n","1        WeightedEnsemble_L2  -0.148289    log_loss      46.990007   \n","2        WeightedEnsemble_L3  -0.148385    log_loss     126.403947   \n","3        WeightedEnsemble_L4  -0.148872    log_loss     164.148464   \n","4             XGBoost_BAG_L2  -0.148991    log_loss      99.243326   \n","5            CatBoost_BAG_L2  -0.149090    log_loss      98.804893   \n","6        LightGBM_r96_BAG_L2  -0.149216    log_loss     102.429577   \n","7       CatBoost_r137_BAG_L2  -0.149249    log_loss      98.787518   \n","8       LightGBM_r131_BAG_L2  -0.149251    log_loss     102.657257   \n","9  NeuralNetTorch_r79_BAG_L2  -0.149260    log_loss     100.322798   \n","\n","       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n","0  10171.116691                0.003628           1.185391            5   \n","1   4071.147295                0.003508           1.193801            2   \n","2  11790.050694                0.003290           1.067314            3   \n","3  17469.321232                0.005054           0.978731            4   \n","4   7134.348668                0.584466          41.935683            2   \n","5   7189.119752                0.146032          96.706767            2   \n","6   7197.745426                3.770716         105.332442            2   \n","7   7154.330236                0.128657          61.917252            2   \n","8   7234.507014                3.998396         142.094029            2   \n","9   7628.715830                1.663937         536.302845            2   \n","\n","   can_infer  fit_order  \n","0       True         87  \n","1       True         28  \n","2       True         52  \n","3       True         72  \n","4       True         37  \n","5       True         33  \n","6       True         45  \n","7       True         49  \n","8       True         42  \n","9       True         41  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["leaderboard_test = predictor.leaderboard()\n","leaderboard_test.head(10)"]},{"cell_type":"markdown","metadata":{"id":"wJMpc1slUigf"},"source":["## **Submission**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472490,"status":"ok","timestamp":1731527642686,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"Ryt12WP8zBLF","outputId":"62fdbb18-dcb7-4477-ec21-40eda383b8af"},"outputs":[{"data":{"text/plain":["0.511"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Calibrate the prediction threshold\n","predictor.calibrate_decision_threshold(train_data, metric='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223049,"status":"ok","timestamp":1731529891592,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"AQgjfRNhkYnO","outputId":"b2850ec5-acd6-4a15-d3b5-5134873d491c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9401072206399732\n"]}],"source":["model = \"WeightedEnsemble_ALL_L5\"\n","suffix = \"m1\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86687,"status":"ok","timestamp":1731531192421,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"nQ8BAIkNNSyv","outputId":"98375784-a8e5-425e-dde4-a92e660f73b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9402398503378567\n"]}],"source":["model = \"WeightedEnsemble_L2\"\n","suffix = \"m2\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278728,"status":"ok","timestamp":1731531508407,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"ECM2oavrS_ZR","outputId":"8c54075f-ad70-48a2-e965-a1b3b1a506c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9401351426816329\n"]}],"source":["model = \"WeightedEnsemble_L3\"\n","suffix = \"m3\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":426938,"status":"ok","timestamp":1731531936845,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"uzo4u7T2Tn1B","outputId":"99a05483-8e22-4017-fbeb-bf9a7924aba1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.940302674931591\n"]}],"source":["model = \"WeightedEnsemble_L4\"\n","suffix = \"m4\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169954,"status":"ok","timestamp":1731532106768,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"oH7zkJthUJ3L","outputId":"da3d4a5c-b7f3-4fc0-bc5c-8bf41edda701"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9401351426816329\n"]}],"source":["model = \"XGBoost_BAG_L2\"\n","suffix = \"m5\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172214,"status":"ok","timestamp":1731532335210,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":-60},"id":"FccmjexYUaWn","outputId":"417387e2-2899-44d4-cb67-a5056f019ff1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.940211928296197\n"]}],"source":["model = \"CatBoost_BAG_L2\"\n","suffix = \"m6\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"kTIVGRZqLLQ8"},"source":["# **Autogluon 20hr training Accuracy**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrcXws_B1zRA","outputId":"b5034d18-88ae-4449-b9d7-6d895d563732"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.1.1\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          8\n","Memory Avail:       48.57 GB / 50.99 GB (95.2%)\n","Disk Space Avail:   174.95 GB / 225.83 GB (77.5%)\n","===================================================\n","Presets specified: ['best_quality']\n","Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=10, num_bag_sets=10\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 18000s of the 72000s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-11-13 23:27:59,220\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=4732)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Beginning AutoGluon training ... Time limit = 17996s\n","\u001b[36m(_dystack pid=4732)\u001b[0m AutoGluon will save models to \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=4732)\u001b[0m Train Data Rows:    127338\n","\u001b[36m(_dystack pid=4732)\u001b[0m Train Data Columns: 17\n","\u001b[36m(_dystack pid=4732)\u001b[0m Label Column:       depression\n","\u001b[36m(_dystack pid=4732)\u001b[0m Problem Type:       binary\n","\u001b[36m(_dystack pid=4732)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","\u001b[36m(_dystack pid=4732)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tAvailable Memory:                    49206.93 MB\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tTrain Data (Original)  Memory Usage: 50.39 MB (0.1% of available memory)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('float', [])  : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('int', [])    : 5 | ['is_female', 'age', 'is_student', 'suicidal_thoughts', 'family_history']\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('object', []) : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('category', [])  : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('float', [])     : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('int', [])       : 1 | ['age']\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t\t('int', ['bool']) : 4 | ['is_female', 'is_student', 'suicidal_thoughts', 'family_history']\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.4s = Fit runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17 features in original data used to generate 17 features in processed data.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tTrain Data (Processed) Memory Usage: 8.87 MB (0.0% of available memory)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Data preprocessing and feature engineering runtime = 0.41s ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=4732)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=4732)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=4732)\u001b[0m {\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=4732)\u001b[0m }\n","\u001b[36m(_dystack pid=4732)\u001b[0m AutoGluon will fit 4 stack levels (L1 to L4) ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting 108 L1 models ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 49.98s of the 17995.86s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L1/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t14.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L1/T2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.61s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.41s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L1/T3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.07s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.74s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L1/T4 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 49.98s of the 17949.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L1/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.64s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.86s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L1/T2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9394\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t10.44s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L1/T3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.64s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.42s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L1/T4 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 49.98s of the 17906.78s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForestGini_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9366\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.11s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 49.98s of the 17894.61s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForestEntr_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9366\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.72s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.19s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 49.98s of the 17882.82s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_BAG_L1/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9375\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.33s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.23s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 49.98s of the 17843.32s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTreesGini_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9362\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t10.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.42s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 49.98s of the 17832.79s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTreesEntr_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.936\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.53s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 49.98s of the 17821.69s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetFastAI_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator          │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                     │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1' in 0.0275s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 3cecdc0e: FileNotFoundError('Could not fetch metrics for 3cecdc0e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/3cecdc0e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - bf358476: FileNotFoundError('Could not fetch metrics for bf358476: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/bf358476')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 488a76d1: FileNotFoundError('Could not fetch metrics for 488a76d1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/488a76d1')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 3fe9dbf8: FileNotFoundError('Could not fetch metrics for 3fe9dbf8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/3fe9dbf8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_BAG_L1/3cecdc0e ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9375\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.25s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.58s\t = Validation runtime\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 49.98s of the 17770.54s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_BAG_L1/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t36.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.93s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 49.98s of the 17733.45s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler           │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                    │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1' in 0.0318s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 210c66a2: FileNotFoundError('Could not fetch metrics for 210c66a2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/210c66a2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ebac3777: FileNotFoundError('Could not fetch metrics for ebac3777: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/ebac3777')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 024a60e9: FileNotFoundError('Could not fetch metrics for 024a60e9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/024a60e9')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - bcce29fa: FileNotFoundError('Could not fetch metrics for bcce29fa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/bcce29fa')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_BAG_L1/210c66a2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9388\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.3s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.61s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 49.98s of the 17683.12s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.84s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.78s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r177_BAG_L1 ... Tuning model for up to 49.98s of the 17666.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r177_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r177_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.53s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.07s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L1 ... Tuning model for up to 49.98s of the 17625.06s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r79_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1' in 0.0359s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 83d5c163: FileNotFoundError('Could not fetch metrics for 83d5c163: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/83d5c163')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f7164f5c: FileNotFoundError('Could not fetch metrics for f7164f5c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/f7164f5c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 361adebc: FileNotFoundError('Could not fetch metrics for 361adebc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/361adebc')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 1e661e5b: FileNotFoundError('Could not fetch metrics for 1e661e5b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/1e661e5b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r79_BAG_L1/83d5c163 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9389\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t40.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.93s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r131_BAG_L1 ... Tuning model for up to 49.98s of the 17574.68s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r131_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1864, in ray._raylet.execute_task\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1866, in ray._raylet.execute_task\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 810, in deserialize_objects\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     context = self.get_serialization_context()\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 679, in get_serialization_context\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     context_map[job_id] = serialization.SerializationContext(self)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 153, in __init__\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     serialization_addons.apply(self)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/util/serialization_addons.py\", line 29, in apply\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     from ray._private.pydantic_compat import register_pydantic_serializers\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/pydantic_compat.py\", line 7, in <module>\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     import pydantic\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pydantic/__init__.py\", line 396, in <module>\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     _getattr_migration = getattr_migration(__name__)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pydantic/_migration.py\", line 260, in getattr_migration\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     from .errors import PydanticImportError\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pydantic/errors.py\", line 7, in <module>\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     from typing_extensions import Literal, Self\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/typing_extensions.py\", line 3394, in <module>\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     class TypeAliasType:\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 873, in sigterm_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     raise_sys_exit_with_custom_error_message(\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 846, in ray._raylet.raise_sys_exit_with_custom_error_message\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m SystemExit: 1\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2177, in ray._raylet.execute_task_with_cancellation_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1832, in ray._raylet.execute_task\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1833, in ray._raylet.execute_task\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1836, in ray._raylet.execute_task\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/traceback.py\", line 183, in format_exc\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/traceback.py\", line 135, in format_exception\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     self.stack = StackSummary.extract(\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     f.line\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     lines = getlines(filename, module_globals)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     return updatecache(filename, module_globals)\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/linecache.py\", line 137, in updatecache\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     lines = fp.readlines()\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     def decode(self, input, final=False):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m KeyboardInterrupt\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2281, in ray._raylet.task_execution_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2212, in ray._raylet.execute_task_with_cancellation_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1094, in ray._raylet.store_task_errors\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/utils.py\", line 178, in push_error_to_driver\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 4879, in ray._raylet.CoreWorker.push_error\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.check_status\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m ray.exceptions.RaySystemError: System error: Broken pipe\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m \n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2320, in ray._raylet.task_execution_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/utils.py\", line 178, in push_error_to_driver\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 4879, in ray._raylet.CoreWorker.push_error\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.check_status\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m ray.exceptions.RaySystemError: System error: Broken pipe\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Exception ignored in: 'ray._raylet.task_execution_handler'\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2320, in ray._raylet.task_execution_handler\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/utils.py\", line 178, in push_error_to_driver\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 4879, in ray._raylet.CoreWorker.push_error\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m   File \"python/ray/_raylet.pyx\", line 589, in ray._raylet.check_status\n","\u001b[36m(bundle_reservation_check_func pid=13672)\u001b[0m ray.exceptions.RaySystemError: System error: Broken pipe\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r131_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L1 ... Tuning model for up to 49.98s of the 17571.05s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r191_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9374\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.93s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.6s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r9_BAG_L1 ... Tuning model for up to 49.98s of the 17529.02s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r9_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r9_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.3s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r96_BAG_L1 ... Tuning model for up to 49.98s of the 17486.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r96_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r96_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L1 ... Tuning model for up to 49.98s of the 17483.21s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r22_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1' in 0.0407s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4fa9e245: FileNotFoundError('Could not fetch metrics for 4fa9e245: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/4fa9e245')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - efa1f7c5: FileNotFoundError('Could not fetch metrics for efa1f7c5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/efa1f7c5')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c2f277a6: FileNotFoundError('Could not fetch metrics for c2f277a6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/c2f277a6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r22_BAG_L1/4fa9e245 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9381\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t37.37s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.48s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r33_BAG_L1 ... Tuning model for up to 49.98s of the 17431.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r33_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.28%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r33_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9308\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.76s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.38s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r42_BAG_L1 ... Tuning model for up to 49.98s of the 17388.9s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r42_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9353\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.03s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r137_BAG_L1 ... Tuning model for up to 49.98s of the 17375.11s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r137_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.13%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r137_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.9s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L1 ... Tuning model for up to 49.98s of the 17333.11s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r102_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.01s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.53s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r13_BAG_L1 ... Tuning model for up to 49.98s of the 17290.02s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r13_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r13_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9383\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.89s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.07s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r195_BAG_L1 ... Tuning model for up to 49.98s of the 17248.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r195_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r195_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.935\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.83s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r188_BAG_L1 ... Tuning model for up to 49.98s of the 17228.1s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r188_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r188_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.2s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L1 ... Tuning model for up to 49.98s of the 17214.81s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r145_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9378\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.96s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r89_BAG_L1 ... Tuning model for up to 49.98s of the 17172.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r89_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r89_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L1 ... Tuning model for up to 49.98s of the 17129.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r30_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1' in 0.0503s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b0294e1d: FileNotFoundError('Could not fetch metrics for b0294e1d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/b0294e1d')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - cbe39d7a: FileNotFoundError('Could not fetch metrics for cbe39d7a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/cbe39d7a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 731eef4b: FileNotFoundError('Could not fetch metrics for 731eef4b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/731eef4b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8c35380c: FileNotFoundError('Could not fetch metrics for 8c35380c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/8c35380c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r30_BAG_L1/b0294e1d ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t40.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.56s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r130_BAG_L1 ... Tuning model for up to 49.98s of the 17079.05s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r130_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r130_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.95s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.39s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L1 ... Tuning model for up to 49.98s of the 17071.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r86_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1' in 0.0444s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ec66ec0f: FileNotFoundError('Could not fetch metrics for ec66ec0f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1/ec66ec0f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 83f73721: FileNotFoundError('Could not fetch metrics for 83f73721: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1/83f73721')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 586f3d29: FileNotFoundError('Could not fetch metrics for 586f3d29: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1/586f3d29')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r86_BAG_L1/ec66ec0f ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.85s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r50_BAG_L1 ... Tuning model for up to 49.98s of the 17020.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r50_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.13%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r50_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t28.37s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L1 ... Tuning model for up to 49.98s of the 16992.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r11_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9367\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.15s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.36s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r194_BAG_L1 ... Tuning model for up to 49.98s of the 16948.81s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r194_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9388\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.66s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.56s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r172_BAG_L1 ... Tuning model for up to 49.98s of the 16936.08s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r172_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9367\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t21.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.88s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r69_BAG_L1 ... Tuning model for up to 49.98s of the 16914.95s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r69_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9394\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L1 ... Tuning model for up to 49.98s of the 16871.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r103_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9377\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.43s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.95s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L1 ... Tuning model for up to 49.98s of the 16825.64s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r14_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1' in 0.0429s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - bba9c128: FileNotFoundError('Could not fetch metrics for bba9c128: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/bba9c128')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ba6f2fcd: FileNotFoundError('Could not fetch metrics for ba6f2fcd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/ba6f2fcd')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 379c6fa3: FileNotFoundError('Could not fetch metrics for 379c6fa3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/379c6fa3')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - fac3afc9: FileNotFoundError('Could not fetch metrics for fac3afc9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/fac3afc9')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r14_BAG_L1/bba9c128 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9393\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.57s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r161_BAG_L1 ... Tuning model for up to 49.98s of the 16775.35s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r161_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r161_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.82s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L1 ... Tuning model for up to 49.98s of the 16771.43s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r143_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.48s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.81s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r70_BAG_L1 ... Tuning model for up to 49.98s of the 16726.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r70_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r70_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.93s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.22s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L1 ... Tuning model for up to 49.98s of the 16684.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r156_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.93s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r196_BAG_L1 ... Tuning model for up to 49.98s of the 16639.83s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r196_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r196_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.9s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r39_BAG_L1 ... Tuning model for up to 49.98s of the 16635.86s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r39_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r39_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9359\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.77s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r167_BAG_L1 ... Tuning model for up to 49.98s of the 16616.07s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r167_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r167_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.49s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.07s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L1 ... Tuning model for up to 49.98s of the 16574.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r95_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9377\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.38s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.54s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L1 ... Tuning model for up to 49.98s of the 16530.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r41_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1' in 0.0274s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 1405e6f6: FileNotFoundError('Could not fetch metrics for 1405e6f6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1/1405e6f6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4fe54cfe: FileNotFoundError('Could not fetch metrics for 4fe54cfe: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1/4fe54cfe')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 78b94c48: FileNotFoundError('Could not fetch metrics for 78b94c48: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1/78b94c48')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r41_BAG_L1/1405e6f6 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.61s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r98_BAG_L1 ... Tuning model for up to 49.98s of the 16479.6s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r98_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r98_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r15_BAG_L1 ... Tuning model for up to 49.98s of the 16473.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r15_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.94\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L1 ... Tuning model for up to 49.98s of the 16460.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r158_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1' in 0.0269s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 38eb365a: FileNotFoundError('Could not fetch metrics for 38eb365a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/38eb365a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 88a57f94: FileNotFoundError('Could not fetch metrics for 88a57f94: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/88a57f94')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8b61024c: FileNotFoundError('Could not fetch metrics for 8b61024c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/8b61024c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r158_BAG_L1/38eb365a ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9366\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.43s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.17s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r86_BAG_L1 ... Tuning model for up to 49.98s of the 16409.64s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r86_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r86_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.75s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L1 ... Tuning model for up to 49.98s of the 16367.81s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r37_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9388\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.37s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.54s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L1 ... Tuning model for up to 49.98s of the 16324.35s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r197_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L1' in 0.0695s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0ef42447: FileNotFoundError('Could not fetch metrics for 0ef42447: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L1/0ef42447')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 5adf9d94: FileNotFoundError('Could not fetch metrics for 5adf9d94: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L1/5adf9d94')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r197_BAG_L1/0ef42447 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.98s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r49_BAG_L1 ... Tuning model for up to 49.98s of the 16273.32s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r49_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r49_BAG_L1 ... Tuning model for up to 49.98s of the 16230.43s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r49_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9362\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.4s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.48s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r143_BAG_L1 ... Tuning model for up to 49.98s of the 16217.95s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r143_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r127_BAG_L1 ... Tuning model for up to 49.98s of the 16214.21s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r127_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9363\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t24.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L1 ... Tuning model for up to 49.98s of the 16189.27s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r134_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9382\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.89s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r34_BAG_L1 ... Tuning model for up to 49.98s of the 16145.3s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r34_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9355\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.38s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r94_BAG_L1 ... Tuning model for up to 49.98s of the 16128.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r94_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_ray_fit pid=32311)\u001b[0m [1000]\tvalid_set's binary_error: 0.0596458\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r94_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.9s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.67s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L1 ... Tuning model for up to 49.98s of the 16111.58s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r143_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1' in 0.0327s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6a191ecc: FileNotFoundError('Could not fetch metrics for 6a191ecc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1/6a191ecc')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8fd87bdb: FileNotFoundError('Could not fetch metrics for 8fd87bdb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1/8fd87bdb')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 178e9c74: FileNotFoundError('Could not fetch metrics for 178e9c74: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1/178e9c74')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d2d2a8c2: FileNotFoundError('Could not fetch metrics for d2d2a8c2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L1/d2d2a8c2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r143_BAG_L1/6a191ecc ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9366\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.43s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r128_BAG_L1 ... Tuning model for up to 49.98s of the 16061.2s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r128_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r128_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.2s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L1 ... Tuning model for up to 49.98s of the 16019.24s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r111_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.4s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.86s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L1 ... Tuning model for up to 49.98s of the 15974.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r31_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L1' in 0.0283s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b39bf32c: FileNotFoundError('Could not fetch metrics for b39bf32c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L1/b39bf32c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 926872b6: FileNotFoundError('Could not fetch metrics for 926872b6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L1/926872b6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 41f0d1a2: FileNotFoundError('Could not fetch metrics for 41f0d1a2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L1/41f0d1a2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r31_BAG_L1/b39bf32c ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.31s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.84s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r4_BAG_L1 ... Tuning model for up to 49.98s of the 15923.47s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r4_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9364\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.6s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L1 ... Tuning model for up to 49.98s of the 15910.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r65_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.67s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.71s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L1 ... Tuning model for up to 49.98s of the 15866.09s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r88_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.939\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.47s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r30_BAG_L1 ... Tuning model for up to 49.98s of the 15821.5s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r30_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r30_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r49_BAG_L1 ... Tuning model for up to 49.98s of the 15817.55s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r49_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9371\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.79s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r5_BAG_L1 ... Tuning model for up to 49.98s of the 15774.86s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r5_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r5_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9398\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.19s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L1 ... Tuning model for up to 49.98s of the 15735.59s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r87_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1' in 0.0329s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e411fa8f: FileNotFoundError('Could not fetch metrics for e411fa8f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1/e411fa8f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b2a8588c: FileNotFoundError('Could not fetch metrics for b2a8588c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1/b2a8588c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f5d12ddc: FileNotFoundError('Could not fetch metrics for f5d12ddc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1/f5d12ddc')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b100a9e1: FileNotFoundError('Could not fetch metrics for b100a9e1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L1/b100a9e1')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r87_BAG_L1/e411fa8f ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9394\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.03s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L1 ... Tuning model for up to 49.98s of the 15683.53s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r71_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L1' in 0.0600s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d6cd2d31: FileNotFoundError('Could not fetch metrics for d6cd2d31: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L1/d6cd2d31')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b1425dbd: FileNotFoundError('Could not fetch metrics for b1425dbd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L1/b1425dbd')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0998c97a: FileNotFoundError('Could not fetch metrics for 0998c97a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L1/0998c97a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r71_BAG_L1/d6cd2d31 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.39s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.53s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r143_BAG_L1 ... Tuning model for up to 49.98s of the 15630.58s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r143_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r178_BAG_L1 ... Tuning model for up to 49.98s of the 15586.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r178_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9368\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.8s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.93s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r166_BAG_L1 ... Tuning model for up to 49.98s of the 15573.69s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r166_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r166_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9366\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.93s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.21s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r31_BAG_L1 ... Tuning model for up to 49.98s of the 15560.68s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r31_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r31_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.2s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.24s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L1 ... Tuning model for up to 49.98s of the 15541.41s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r185_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L1' in 0.0296s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8a23346a: FileNotFoundError('Could not fetch metrics for 8a23346a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L1/8a23346a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 46ec7824: FileNotFoundError('Could not fetch metrics for 46ec7824: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L1/46ec7824')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b1de5353: FileNotFoundError('Could not fetch metrics for b1de5353: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L1/b1de5353')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r185_BAG_L1/8a23346a ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.64s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.06s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L1 ... Tuning model for up to 49.98s of the 15490.43s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r160_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9381\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.75s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r60_BAG_L1 ... Tuning model for up to 49.98s of the 15446.11s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r60_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r60_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r15_BAG_L1 ... Tuning model for up to 49.98s of the 15404.08s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r15_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.936\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.21s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.72s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r135_BAG_L1 ... Tuning model for up to 49.98s of the 15383.8s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r135_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r135_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9388\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.63s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r22_BAG_L1 ... Tuning model for up to 49.98s of the 15375.96s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r22_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r22_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.939\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.38s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.84s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L1 ... Tuning model for up to 49.98s of the 15333.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r69_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9382\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.16s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r6_BAG_L1 ... Tuning model for up to 49.98s of the 15288.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r6_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r6_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t38.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.15s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L1 ... Tuning model for up to 49.98s of the 15249.14s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r138_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9369\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.33s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.25s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r121_BAG_L1 ... Tuning model for up to 49.98s of the 15203.73s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r121_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r121_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.97s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L1 ... Tuning model for up to 49.98s of the 15199.69s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r172_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.938\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.97s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r180_BAG_L1 ... Tuning model for up to 49.98s of the 15155.64s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r180_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r180_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.98s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.2s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L1 ... Tuning model for up to 49.98s of the 15113.58s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r76_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1' in 0.0278s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8304ac35: FileNotFoundError('Could not fetch metrics for 8304ac35: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1/8304ac35')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 5dae2e13: FileNotFoundError('Could not fetch metrics for 5dae2e13: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1/5dae2e13')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 810ae0b9: FileNotFoundError('Could not fetch metrics for 810ae0b9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1/810ae0b9')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9705fa1d: FileNotFoundError('Could not fetch metrics for 9705fa1d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L1/9705fa1d')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r76_BAG_L1/8304ac35 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t40.66s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.74s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r197_BAG_L1 ... Tuning model for up to 49.98s of the 15063.25s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r197_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9354\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.2s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.99s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L1 ... Tuning model for up to 49.98s of the 15046.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r121_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L1' in 0.0753s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a0cf801b: FileNotFoundError('Could not fetch metrics for a0cf801b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L1/a0cf801b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4685b2f6: FileNotFoundError('Could not fetch metrics for 4685b2f6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L1/4685b2f6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r121_BAG_L1/a0cf801b ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9367\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.31s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L1 ... Tuning model for up to 49.98s of the 14995.77s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r127_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.85s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r16_BAG_L1 ... Tuning model for up to 49.98s of the 14949.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r16_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: RandomForest_r16_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9345\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t27.23s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.83s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L1 ... Tuning model for up to 49.98s of the 14921.73s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r194_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.17s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r12_BAG_L1 ... Tuning model for up to 49.98s of the 14878.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r12_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r12_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9398\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L1 ... Tuning model for up to 49.98s of the 14835.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r135_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1' in 0.0334s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - cb69d765: FileNotFoundError('Could not fetch metrics for cb69d765: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1/cb69d765')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b12666aa: FileNotFoundError('Could not fetch metrics for b12666aa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1/b12666aa')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 579aa186: FileNotFoundError('Could not fetch metrics for 579aa186: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1/579aa186')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - eda7ad70: FileNotFoundError('Could not fetch metrics for eda7ad70: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L1/eda7ad70')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r135_BAG_L1/cb69d765 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9383\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.28s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.37s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L1 ... Tuning model for up to 49.98s of the 14784.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r4_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9381\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.69s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.54s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r126_BAG_L1 ... Tuning model for up to 49.98s of the 14739.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r126_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9367\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.75s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.23s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L1 ... Tuning model for up to 49.98s of the 14729.72s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r36_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L1' in 0.0306s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e3feb519: FileNotFoundError('Could not fetch metrics for e3feb519: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L1/e3feb519')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f8ec2877: FileNotFoundError('Could not fetch metrics for f8ec2877: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L1/f8ec2877')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b7164a09: FileNotFoundError('Could not fetch metrics for b7164a09: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L1/b7164a09')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r36_BAG_L1/e3feb519 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.34s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.82s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L1 ... Tuning model for up to 49.98s of the 14678.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r100_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9362\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.44s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r163_BAG_L1 ... Tuning model for up to 49.98s of the 14635.86s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r163_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r163_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.94\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.8s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r198_BAG_L1 ... Tuning model for up to 49.98s of the 14593.99s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r198_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r198_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t41.99s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L1 ... Tuning model for up to 49.98s of the 14551.92s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r187_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9394\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.16s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.88s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L1 ... Tuning model for up to 49.98s of the 14506.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r19_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L1' in 0.0479s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 55ced5fa: FileNotFoundError('Could not fetch metrics for 55ced5fa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L1/55ced5fa')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 10fddd31: FileNotFoundError('Could not fetch metrics for 10fddd31: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L1/10fddd31')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f8337c3d: FileNotFoundError('Could not fetch metrics for f8337c3d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L1/f8337c3d')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r19_BAG_L1/55ced5fa ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t40.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.63s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r95_BAG_L1 ... Tuning model for up to 49.98s of the 14456.27s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r95_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9381\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.52s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.68s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r34_BAG_L1 ... Tuning model for up to 49.98s of the 14413.68s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.28%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r34_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9344\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.59s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.41s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r42_BAG_L1 ... Tuning model for up to 49.98s of the 14371.0s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r42_BAG_L1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9389\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.88s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.86s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L1 ... Tuning model for up to 49.98s of the 14362.04s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭─────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r1_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├─────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                       │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰─────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L1' in 0.0228s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9b7f9998: FileNotFoundError('Could not fetch metrics for 9b7f9998: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L1/9b7f9998')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f155cfd2: FileNotFoundError('Could not fetch metrics for f155cfd2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L1/f155cfd2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r1_BAG_L1/9b7f9998 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9384\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.82s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.96s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L1 ... Tuning model for up to 49.98s of the 14311.77s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r89_BAG_L1   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 49.97602127337307 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1' in 0.0356s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 3adb369e: FileNotFoundError('Could not fetch metrics for 3adb369e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1/3adb369e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 30b43647: FileNotFoundError('Could not fetch metrics for 30b43647: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1/30b43647')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 46a10c5b: FileNotFoundError('Could not fetch metrics for 46a10c5b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1/46a10c5b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2f55e9e1: FileNotFoundError('Could not fetch metrics for 2f55e9e1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L1/2f55e9e1')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r89_BAG_L1/3adb369e ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t39.22s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.51s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 599.71s of the 14259.39s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tEnsemble Weights: {'CatBoost_r143_BAG_L1': 0.261, 'CatBoost_r49_BAG_L1': 0.217, 'LightGBM_r94_BAG_L1': 0.174, 'NeuralNetTorch_r76_BAG_L1/8304ac35': 0.174, 'LightGBMXT_BAG_L1/T1': 0.087, 'NeuralNetTorch_r14_BAG_L1/bba9c128': 0.043, 'NeuralNetFastAI_r187_BAG_L1': 0.043}\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting 108 L2 models ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBMXT_BAG_L2 ... Tuning model for up to 52.78s of the 14254.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.91%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.99%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L2/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t25.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.51s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L2/T2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t22.8s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.43s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 52.78s of the 14204.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.91%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L2/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t29.72s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.46s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestGini_BAG_L2 ... Tuning model for up to 52.78s of the 14174.27s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestGini_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 29.13s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForestGini_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestEntr_BAG_L2 ... Tuning model for up to 52.78s of the 14084.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestEntr_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.71s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForestEntr_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 52.78s of the 14006.78s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.97%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_BAG_L2/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t31.44s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.2s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesGini_BAG_L2 ... Tuning model for up to 52.78s of the 13974.41s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesGini_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTreesGini_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.76s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.98s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesEntr_BAG_L2 ... Tuning model for up to 52.78s of the 13953.95s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTreesEntr_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9398\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_BAG_L2 ... Tuning model for up to 52.78s of the 13933.82s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetFastAI_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator          │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                     │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2' in 0.0292s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 759bc48e: FileNotFoundError('Could not fetch metrics for 759bc48e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/759bc48e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c4c966b3: FileNotFoundError('Could not fetch metrics for c4c966b3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/c4c966b3')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2f47a833: FileNotFoundError('Could not fetch metrics for 2f47a833: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L2/2f47a833')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_BAG_L2/759bc48e ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.07s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.19s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_BAG_L2 ... Tuning model for up to 52.78s of the 13879.22s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_BAG_L2/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t37.93s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.29s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 52.78s of the 13840.36s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler           │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                    │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2' in 0.0327s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 048d6a9c: FileNotFoundError('Could not fetch metrics for 048d6a9c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/048d6a9c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c384d442: FileNotFoundError('Could not fetch metrics for c384d442: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/c384d442')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 364d1050: FileNotFoundError('Could not fetch metrics for 364d1050: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/364d1050')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_BAG_L2/048d6a9c ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.31s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 52.78s of the 13785.16s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.06%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t38.08s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.61s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r177_BAG_L2 ... Tuning model for up to 52.78s of the 13744.2s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r177_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.96%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r177_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.84s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L2 ... Tuning model for up to 52.78s of the 13725.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r79_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=62352)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L2' in 0.0463s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 7212e43c: FileNotFoundError('Could not fetch metrics for 7212e43c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L2/7212e43c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0305a147: FileNotFoundError('Could not fetch metrics for 0305a147: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L2/0305a147')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2c798fbe: FileNotFoundError('Could not fetch metrics for 2c798fbe: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L2/2c798fbe')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r79_BAG_L2... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r131_BAG_L2 ... Tuning model for up to 52.78s of the 13661.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r131_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.52%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r131_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L2 ... Tuning model for up to 52.78s of the 13651.12s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r191_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.54s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.56s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r9_BAG_L2 ... Tuning model for up to 52.78s of the 13603.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r9_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r9_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.9s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.15s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r96_BAG_L2 ... Tuning model for up to 52.78s of the 13559.26s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r96_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r96_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.15s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L2 ... Tuning model for up to 52.78s of the 13550.65s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r22_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L2' in 0.0297s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 003dd4ee: FileNotFoundError('Could not fetch metrics for 003dd4ee: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L2/003dd4ee')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - cbb4dfb8: FileNotFoundError('Could not fetch metrics for cbb4dfb8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L2/cbb4dfb8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - fe3dd590: FileNotFoundError('Could not fetch metrics for fe3dd590: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L2/fe3dd590')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r22_BAG_L2/003dd4ee ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9375\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.8s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.38s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r33_BAG_L2 ... Tuning model for up to 52.78s of the 13495.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r33_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.93%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r33_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9355\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.29s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.41s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r42_BAG_L2 ... Tuning model for up to 52.78s of the 13449.18s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 27.89s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r42_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r137_BAG_L2 ... Tuning model for up to 52.78s of the 13350.53s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r137_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r137_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t15.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L2 ... Tuning model for up to 52.78s of the 13334.6s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r102_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.91s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r13_BAG_L2 ... Tuning model for up to 52.78s of the 13286.06s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r13_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r13_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t32.17s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r195_BAG_L2 ... Tuning model for up to 52.78s of the 13253.21s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r195_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.97s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r195_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r188_BAG_L2 ... Tuning model for up to 52.78s of the 12141.88s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r188_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.06%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r188_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t15.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.68s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L2 ... Tuning model for up to 52.78s of the 12125.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r145_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.82s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.35s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r89_BAG_L2 ... Tuning model for up to 52.78s of the 12077.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r89_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r89_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.97s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.81s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L2 ... Tuning model for up to 52.78s of the 12031.38s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r30_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=73569)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=73636, ip=172.28.0.12)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 208, in _fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     self._train_net(\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 405, in _train_net\n","\u001b[36m(model_trial pid=73569)\u001b[0m     raise AssertionError(\"0 epochs trained!\")\n","\u001b[36m(model_trial pid=73569)\u001b[0m AssertionError: 0 epochs trained!\n","\u001b[36m(model_trial pid=73569)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n","\u001b[36m(model_trial pid=73569)\u001b[0m     model = fit_and_save_model(\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(model_trial pid=73569)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     self._fit_folds(\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n","\u001b[36m(model_trial pid=73569)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n","\u001b[36m(model_trial pid=73569)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n","\u001b[36m(model_trial pid=73569)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n","\u001b[36m(model_trial pid=73569)\u001b[0m     raise processed_exception\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n","\u001b[36m(model_trial pid=73569)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n","\u001b[36m(model_trial pid=73569)\u001b[0m     return fn(*args, **kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n","\u001b[36m(model_trial pid=73569)\u001b[0m     return func(*args, **kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2667, in get\n","\u001b[36m(model_trial pid=73569)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 864, in get_objects\n","\u001b[36m(model_trial pid=73569)\u001b[0m     raise value.as_instanceof_cause()\n","\u001b[36m(model_trial pid=73569)\u001b[0m ray.exceptions.RayTaskError(AssertionError): \u001b[36mray::_ray_fit()\u001b[39m (pid=73636, ip=172.28.0.12)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 208, in _fit\n","\u001b[36m(model_trial pid=73569)\u001b[0m     self._train_net(\n","\u001b[36m(model_trial pid=73569)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 405, in _train_net\n","\u001b[36m(model_trial pid=73569)\u001b[0m     raise AssertionError(\"0 epochs trained!\")\n","\u001b[36m(model_trial pid=73569)\u001b[0m AssertionError: 0 epochs trained!\n","\u001b[36m(model_trial pid=73569)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=73569)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=74192)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(model_trial pid=74192)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2' in 0.0433s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6c40b57e: FileNotFoundError('Could not fetch metrics for 6c40b57e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2/6c40b57e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a4d86449: FileNotFoundError('Could not fetch metrics for a4d86449: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2/a4d86449')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b4a0a08f: FileNotFoundError('Could not fetch metrics for b4a0a08f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2/b4a0a08f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - dc748276: FileNotFoundError('Could not fetch metrics for dc748276: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L2/dc748276')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r30_BAG_L2... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r130_BAG_L2 ... Tuning model for up to 52.78s of the 11969.44s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r130_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.01%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r130_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t15.07s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.43s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L2 ... Tuning model for up to 52.78s of the 11953.62s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r86_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2' in 0.0289s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 7930d96a: FileNotFoundError('Could not fetch metrics for 7930d96a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2/7930d96a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 32a2437f: FileNotFoundError('Could not fetch metrics for 32a2437f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2/32a2437f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d1d2a67d: FileNotFoundError('Could not fetch metrics for d1d2a67d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2/d1d2a67d')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ecd930b8: FileNotFoundError('Could not fetch metrics for ecd930b8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L2/ecd930b8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r86_BAG_L2/7930d96a ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9374\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.15s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r50_BAG_L2 ... Tuning model for up to 52.78s of the 11899.73s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r50_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r50_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t30.05s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L2 ... Tuning model for up to 52.78s of the 11868.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r11_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.03s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.22s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r194_BAG_L2 ... Tuning model for up to 52.78s of the 11826.25s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r194_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.35%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r194_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.21s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.61s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r172_BAG_L2 ... Tuning model for up to 52.78s of the 11781.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.31s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r172_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r69_BAG_L2 ... Tuning model for up to 52.78s of the 11668.4s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r69_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.92%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r69_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t35.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L2 ... Tuning model for up to 52.78s of the 11632.65s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r103_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.53s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.3s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L2 ... Tuning model for up to 52.78s of the 11585.45s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r14_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L2' in 0.0232s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a1f244bd: FileNotFoundError('Could not fetch metrics for a1f244bd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L2/a1f244bd')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f5776637: FileNotFoundError('Could not fetch metrics for f5776637: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L2/f5776637')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6f3f8e7f: FileNotFoundError('Could not fetch metrics for 6f3f8e7f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L2/6f3f8e7f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r14_BAG_L2/a1f244bd ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.24s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r161_BAG_L2 ... Tuning model for up to 52.78s of the 11530.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r161_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r161_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.3s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L2 ... Tuning model for up to 52.78s of the 11520.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r143_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r70_BAG_L2 ... Tuning model for up to 52.78s of the 11472.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r70_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.97%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r70_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.99s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L2 ... Tuning model for up to 52.78s of the 11454.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r156_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.5s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.96s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r196_BAG_L2 ... Tuning model for up to 52.78s of the 11405.91s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r196_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.08%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r196_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.08s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r39_BAG_L2 ... Tuning model for up to 52.78s of the 11397.12s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r39_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.04s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r39_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r167_BAG_L2 ... Tuning model for up to 52.78s of the 10389.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r167_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.06%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r167_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t37.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L2 ... Tuning model for up to 52.78s of the 10351.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r95_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.18s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L2 ... Tuning model for up to 52.78s of the 10307.43s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r41_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L2' in 0.0254s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a436dcc8: FileNotFoundError('Could not fetch metrics for a436dcc8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L2/a436dcc8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f2646e00: FileNotFoundError('Could not fetch metrics for f2646e00: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L2/f2646e00')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ad117aa7: FileNotFoundError('Could not fetch metrics for ad117aa7: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L2/ad117aa7')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r41_BAG_L2/a436dcc8 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.82s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.19s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r98_BAG_L2 ... Tuning model for up to 52.78s of the 10252.45s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r98_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.53%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r98_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.62s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.19s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r15_BAG_L2 ... Tuning model for up to 52.78s of the 10238.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r15_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.90%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r15_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.67s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.61s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L2 ... Tuning model for up to 52.78s of the 10220.81s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r158_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2' in 0.0307s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 04296e5e: FileNotFoundError('Could not fetch metrics for 04296e5e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2/04296e5e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c41f5df6: FileNotFoundError('Could not fetch metrics for c41f5df6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2/c41f5df6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 1881be50: FileNotFoundError('Could not fetch metrics for 1881be50: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2/1881be50')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - aaba2e22: FileNotFoundError('Could not fetch metrics for aaba2e22: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L2/aaba2e22')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r158_BAG_L2/04296e5e ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9338\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.4s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.77s\t = Validation runtime\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r86_BAG_L2 ... Tuning model for up to 52.78s of the 10166.85s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r86_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r86_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t33.11s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L2 ... Tuning model for up to 52.78s of the 10132.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r37_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.42s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.06s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L2 ... Tuning model for up to 52.78s of the 10084.82s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r197_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L2' in 0.0258s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e2611625: FileNotFoundError('Could not fetch metrics for e2611625: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L2/e2611625')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8c4a9caf: FileNotFoundError('Could not fetch metrics for 8c4a9caf: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L2/8c4a9caf')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c0524e64: FileNotFoundError('Could not fetch metrics for c0524e64: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L2/c0524e64')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r197_BAG_L2/e2611625 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r49_BAG_L2 ... Tuning model for up to 52.78s of the 10029.31s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r49_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.06s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r49_BAG_L2 ... Tuning model for up to 52.78s of the 10016.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r49_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.01s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r143_BAG_L2 ... Tuning model for up to 52.78s of the 9995.84s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.14%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r143_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t10.11s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.15s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r127_BAG_L2 ... Tuning model for up to 52.78s of the 9985.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r127_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.81s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r127_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L2 ... Tuning model for up to 52.78s of the 8739.52s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r134_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.52s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.43s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r34_BAG_L2 ... Tuning model for up to 52.78s of the 8692.3s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r34_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.88s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r34_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r94_BAG_L2 ... Tuning model for up to 52.78s of the 8023.97s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r94_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r94_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.0s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.5s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L2 ... Tuning model for up to 52.78s of the 8010.27s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r143_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_ray_fit pid=100085)\u001b[0m \tNot enough time to train first epoch. (Time Required: 8.25s, Time Left: 8.18s)\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=100018)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2' in 0.1468s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - fda29de8: FileNotFoundError('Could not fetch metrics for fda29de8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2/fda29de8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 16ea47ad: FileNotFoundError('Could not fetch metrics for 16ea47ad: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2/16ea47ad')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 5eaddc83: FileNotFoundError('Could not fetch metrics for 5eaddc83: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2/5eaddc83')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c4b6adcf: FileNotFoundError('Could not fetch metrics for c4b6adcf: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L2/c4b6adcf')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r143_BAG_L2... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r128_BAG_L2 ... Tuning model for up to 52.78s of the 7955.58s of remaining time.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=101194)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r128_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.27%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r128_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.73s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L2 ... Tuning model for up to 52.78s of the 7910.84s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.47%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r111_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.91s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.25s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L2 ... Tuning model for up to 52.78s of the 7863.21s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r31_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2' in 0.0315s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2eff4788: FileNotFoundError('Could not fetch metrics for 2eff4788: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2/2eff4788')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - cb23e8be: FileNotFoundError('Could not fetch metrics for cb23e8be: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2/cb23e8be')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - da67b978: FileNotFoundError('Could not fetch metrics for da67b978: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2/da67b978')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 57502aa4: FileNotFoundError('Could not fetch metrics for 57502aa4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L2/57502aa4')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r31_BAG_L2/2eff4788 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.79s\t = Validation runtime\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r4_BAG_L2 ... Tuning model for up to 52.78s of the 7809.29s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.32s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r4_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L2 ... Tuning model for up to 52.78s of the 7715.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.47%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r65_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L2 ... Tuning model for up to 52.78s of the 7667.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.47%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r88_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r30_BAG_L2 ... Tuning model for up to 52.78s of the 7620.13s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r30_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.05%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r30_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.28s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r49_BAG_L2 ... Tuning model for up to 52.78s of the 7611.07s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.33%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r49_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.28s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r5_BAG_L2 ... Tuning model for up to 52.78s of the 7565.09s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r5_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r5_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.13s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L2 ... Tuning model for up to 52.78s of the 7544.22s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r87_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L2' in 0.0282s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 49036f65: FileNotFoundError('Could not fetch metrics for 49036f65: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L2/49036f65')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ab1edd60: FileNotFoundError('Could not fetch metrics for ab1edd60: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L2/ab1edd60')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9f0d2891: FileNotFoundError('Could not fetch metrics for 9f0d2891: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L2/9f0d2891')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r87_BAG_L2/49036f65 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.38s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L2 ... Tuning model for up to 52.78s of the 7489.68s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r71_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L2' in 0.0215s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4472b381: FileNotFoundError('Could not fetch metrics for 4472b381: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L2/4472b381')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ebc63a2f: FileNotFoundError('Could not fetch metrics for ebc63a2f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L2/ebc63a2f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 26c4cae5: FileNotFoundError('Could not fetch metrics for 26c4cae5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L2/26c4cae5')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r71_BAG_L2/4472b381 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.24s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.44s\t = Validation runtime\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r143_BAG_L2 ... Tuning model for up to 52.78s of the 7435.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.07%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r143_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t32.72s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r178_BAG_L2 ... Tuning model for up to 52.78s of the 7402.26s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.1s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r178_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r166_BAG_L2 ... Tuning model for up to 52.78s of the 7318.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r166_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.7s compared to 14.77s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r166_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r31_BAG_L2 ... Tuning model for up to 52.78s of the 7263.72s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r31_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r31_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t24.91s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.73s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L2 ... Tuning model for up to 52.78s of the 7237.93s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r185_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L2' in 0.0356s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 5d0c7630: FileNotFoundError('Could not fetch metrics for 5d0c7630: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L2/5d0c7630')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 96f14d2e: FileNotFoundError('Could not fetch metrics for 96f14d2e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L2/96f14d2e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8399f11f: FileNotFoundError('Could not fetch metrics for 8399f11f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L2/8399f11f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r185_BAG_L2/5d0c7630 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9398\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.62s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L2 ... Tuning model for up to 52.78s of the 7182.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=3.63%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r160_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.94\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.98s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r60_BAG_L2 ... Tuning model for up to 52.78s of the 7134.53s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r60_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.92%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r60_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r15_BAG_L2 ... Tuning model for up to 52.78s of the 7115.82s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r15_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 22.83s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r15_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r135_BAG_L2 ... Tuning model for up to 52.78s of the 6152.27s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r135_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.19%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r135_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.21s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.03s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r22_BAG_L2 ... Tuning model for up to 52.78s of the 6104.38s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r22_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r22_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.16s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L2 ... Tuning model for up to 52.78s of the 6058.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r69_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t42.94s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.8s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r6_BAG_L2 ... Tuning model for up to 52.78s of the 6014.84s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r6_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r6_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t14.28s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L2 ... Tuning model for up to 52.78s of the 5999.8s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r138_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.939\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t48.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.25s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r121_BAG_L2 ... Tuning model for up to 52.78s of the 5950.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r121_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.21%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r121_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L2 ... Tuning model for up to 52.78s of the 5940.94s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r172_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t46.71s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.57s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r180_BAG_L2 ... Tuning model for up to 52.78s of the 5893.5s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r180_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.06%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r180_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t43.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L2 ... Tuning model for up to 52.78s of the 5848.89s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r76_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L2' in 0.0235s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0dce5434: FileNotFoundError('Could not fetch metrics for 0dce5434: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L2/0dce5434')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6940df12: FileNotFoundError('Could not fetch metrics for 6940df12: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L2/6940df12')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b93d4817: FileNotFoundError('Could not fetch metrics for b93d4817: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L2/b93d4817')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r76_BAG_L2/0dce5434 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.94\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.47s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.79s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r197_BAG_L2 ... Tuning model for up to 52.78s of the 5794.09s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 23.38s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r197_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L2 ... Tuning model for up to 52.78s of the 5670.13s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r121_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_ray_fit pid=119404)\u001b[0m \tNot enough time to train first epoch. (Time Required: 7.99s, Time Left: 7.96s)\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=119339)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_ray_fit pid=120000)\u001b[0m \tNot enough time to train first epoch. (Time Required: 7.25s, Time Left: 4.95s)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2' in 0.0249s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 5 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0d4111e5: FileNotFoundError('Could not fetch metrics for 0d4111e5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2/0d4111e5')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 70b23652: FileNotFoundError('Could not fetch metrics for 70b23652: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2/70b23652')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9b06647a: FileNotFoundError('Could not fetch metrics for 9b06647a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2/9b06647a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b5a0131f: FileNotFoundError('Could not fetch metrics for b5a0131f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2/b5a0131f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e30ff804: FileNotFoundError('Could not fetch metrics for e30ff804: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L2/e30ff804')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r121_BAG_L2... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L2 ... Tuning model for up to 52.78s of the 5616.29s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r127_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.4s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r16_BAG_L2 ... Tuning model for up to 52.78s of the 5568.16s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r16_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 30.06s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r16_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L2 ... Tuning model for up to 52.78s of the 4146.12s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r194_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t48.2s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.51s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r12_BAG_L2 ... Tuning model for up to 52.78s of the 4097.23s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r12_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.08%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r12_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t25.16s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L2 ... Tuning model for up to 52.78s of the 4071.36s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r135_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L2' in 0.0319s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 39af69f0: FileNotFoundError('Could not fetch metrics for 39af69f0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L2/39af69f0')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - c3087ae9: FileNotFoundError('Could not fetch metrics for c3087ae9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L2/c3087ae9')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6b532a34: FileNotFoundError('Could not fetch metrics for 6b532a34: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L2/6b532a34')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r135_BAG_L2/39af69f0 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9388\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.76s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.9s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L2 ... Tuning model for up to 52.78s of the 4016.54s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r4_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.95s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.96s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r126_BAG_L2 ... Tuning model for up to 52.78s of the 3967.92s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: ExtraTrees_r126_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.07s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.97s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L2 ... Tuning model for up to 52.78s of the 3948.07s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r36_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L2' in 0.0375s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 3fae45e2: FileNotFoundError('Could not fetch metrics for 3fae45e2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L2/3fae45e2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - bf6bf96a: FileNotFoundError('Could not fetch metrics for bf6bf96a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L2/bf6bf96a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r36_BAG_L2/3fae45e2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t48.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.76s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L2 ... Tuning model for up to 52.78s of the 3892.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r100_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.939\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.14s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r163_BAG_L2 ... Tuning model for up to 52.78s of the 3843.96s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r163_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.92%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r163_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r198_BAG_L2 ... Tuning model for up to 52.78s of the 3826.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r198_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.96%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r198_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t27.63s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L2 ... Tuning model for up to 52.78s of the 3798.45s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r187_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t47.49s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.16s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L2 ... Tuning model for up to 52.78s of the 3750.25s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r19_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L2' in 0.0242s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - dfa6bb85: FileNotFoundError('Could not fetch metrics for dfa6bb85: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L2/dfa6bb85')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2e0a9b7c: FileNotFoundError('Could not fetch metrics for 2e0a9b7c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L2/2e0a9b7c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 71c26292: FileNotFoundError('Could not fetch metrics for 71c26292: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L2/71c26292')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r19_BAG_L2/dfa6bb85 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.5s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.27s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r95_BAG_L2 ... Tuning model for up to 52.78s of the 3695.44s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r95_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.23%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r95_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.98s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r34_BAG_L2 ... Tuning model for up to 52.78s of the 3649.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r34_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.93%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r34_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.939\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t45.53s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.26s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r42_BAG_L2 ... Tuning model for up to 52.78s of the 3603.52s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r42_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.17%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r42_BAG_L2 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.94\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t10.28s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.48s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L2 ... Tuning model for up to 52.78s of the 3592.56s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭─────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r1_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├─────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                       │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰─────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L2' in 0.0282s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 283e4f96: FileNotFoundError('Could not fetch metrics for 283e4f96: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L2/283e4f96')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d342f1b2: FileNotFoundError('Could not fetch metrics for d342f1b2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L2/d342f1b2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 6a57a379: FileNotFoundError('Could not fetch metrics for 6a57a379: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L2/6a57a379')\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetTorch_r1_BAG_L2/283e4f96 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t44.54s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.7s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L2 ... Tuning model for up to 52.78s of the 3538.35s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r89_BAG_L2   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=135633)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 52.782662250640655 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","\u001b[36m(_dystack pid=4732)\u001b[0m You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2' in 0.2108s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 4 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 636b0735: FileNotFoundError('Could not fetch metrics for 636b0735: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2/636b0735')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - cfb7e770: FileNotFoundError('Could not fetch metrics for cfb7e770: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2/cfb7e770')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e3dc1065: FileNotFoundError('Could not fetch metrics for e3dc1065: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2/e3dc1065')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 69a4d6ef: FileNotFoundError('Could not fetch metrics for 69a4d6ef: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L2/69a4d6ef')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r89_BAG_L2... Skipping this model.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=136223)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 633.39s of the 3481.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2/T1': 1.0}\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting 108 L3 models ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBMXT_BAG_L3 ... Tuning model for up to 19.31s of the 3476.53s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBMXT_BAG_L3/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.83s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.41s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_BAG_L3 ... Tuning model for up to 19.31s of the 3455.92s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_BAG_L3/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.34s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestGini_BAG_L3 ... Tuning model for up to 19.31s of the 3435.38s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestGini_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 22.93s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForestGini_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForestEntr_BAG_L3 ... Tuning model for up to 19.31s of the 3362.07s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForestEntr_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 44.66s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForestEntr_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_BAG_L3 ... Tuning model for up to 19.31s of the 3296.12s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.82%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_BAG_L3/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t14.31s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.39s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesGini_BAG_L3 ... Tuning model for up to 19.31s of the 3280.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesGini_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.67s compared to 10.28s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTreesGini_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTreesEntr_BAG_L3 ... Tuning model for up to 19.31s of the 3264.61s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.37s compared to 12.73s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTreesEntr_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_BAG_L3 ... Tuning model for up to 19.31s of the 3251.57s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetFastAI_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator          │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                     │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L3' in 0.0749s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b593218b: FileNotFoundError('Could not fetch metrics for b593218b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L3/b593218b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 154e114a: FileNotFoundError('Could not fetch metrics for 154e114a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L3/154e114a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetFastAI_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_BAG_L3 ... Tuning model for up to 19.31s of the 3221.25s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.03%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tStopping HPO to satisfy time limit...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_BAG_L3/T1 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9333\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.99s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_BAG_L3 ... Tuning model for up to 19.31s of the 3201.64s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler           │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                    │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3' in 0.0314s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 36b6978a: FileNotFoundError('Could not fetch metrics for 36b6978a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/36b6978a')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 7ecc8d86: FileNotFoundError('Could not fetch metrics for 7ecc8d86: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/7ecc8d86')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - dfee685b: FileNotFoundError('Could not fetch metrics for dfee685b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L3/dfee685b')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 19.31s of the 3181.43s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.88%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9389\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.68s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.46s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r177_BAG_L3 ... Tuning model for up to 19.31s of the 3159.29s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r177_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.79%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r177_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t14.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L3 ... Tuning model for up to 19.31s of the 3144.08s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r79_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=141873)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=141873)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=141873)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=141873)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L3' in 0.0304s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a5d28ec6: FileNotFoundError('Could not fetch metrics for a5d28ec6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L3/a5d28ec6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - fc31cec0: FileNotFoundError('Could not fetch metrics for fc31cec0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L3/fc31cec0')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 35744fd4: FileNotFoundError('Could not fetch metrics for 35744fd4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L3/35744fd4')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r79_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r131_BAG_L3 ... Tuning model for up to 19.31s of the 3123.85s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r131_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.78%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r131_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L3 ... Tuning model for up to 19.31s of the 3116.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.21%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r191_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9383\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.79s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.77s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r9_BAG_L3 ... Tuning model for up to 19.31s of the 3096.9s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r9_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.05%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r9_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.79s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r96_BAG_L3 ... Tuning model for up to 19.31s of the 3079.52s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r96_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r96_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L3 ... Tuning model for up to 19.31s of the 3071.78s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r22_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=143705)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L3' in 0.0265s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - acbc37a4: FileNotFoundError('Could not fetch metrics for acbc37a4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L3/acbc37a4')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a61ddcad: FileNotFoundError('Could not fetch metrics for a61ddcad: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L3/a61ddcad')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a471f722: FileNotFoundError('Could not fetch metrics for a471f722: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L3/a471f722')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r22_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r33_BAG_L3 ... Tuning model for up to 19.31s of the 3051.5s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r33_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r33_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8298\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.09s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r42_BAG_L3 ... Tuning model for up to 19.31s of the 3032.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.13s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r42_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r137_BAG_L3 ... Tuning model for up to 19.31s of the 2958.27s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r137_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r137_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9409\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t15.5s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L3 ... Tuning model for up to 19.31s of the 2942.22s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r102_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.3s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.84s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r13_BAG_L3 ... Tuning model for up to 19.31s of the 2921.36s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r13_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.04%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r13_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r195_BAG_L3 ... Tuning model for up to 19.31s of the 2903.35s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r195_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.12s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r195_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r188_BAG_L3 ... Tuning model for up to 19.31s of the 2168.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r188_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.87%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r188_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t12.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.63s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L3 ... Tuning model for up to 19.31s of the 2154.95s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r145_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.85s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.85s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r89_BAG_L3 ... Tuning model for up to 19.31s of the 2134.5s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r89_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.03%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r89_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.13s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.81s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L3 ... Tuning model for up to 19.31s of the 2115.8s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r30_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=149862)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L3' in 0.0193s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d53365da: FileNotFoundError('Could not fetch metrics for d53365da: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L3/d53365da')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 3b29b26e: FileNotFoundError('Could not fetch metrics for 3b29b26e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L3/3b29b26e')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r30_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r130_BAG_L3 ... Tuning model for up to 19.31s of the 2094.92s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r130_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.82%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r130_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.06s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.49s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L3 ... Tuning model for up to 19.31s of the 2081.32s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r86_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=150776)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L3' in 0.0273s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 83fa55f2: FileNotFoundError('Could not fetch metrics for 83fa55f2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L3/83fa55f2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - eb3379eb: FileNotFoundError('Could not fetch metrics for eb3379eb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L3/eb3379eb')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b7a6ffa4: FileNotFoundError('Could not fetch metrics for b7a6ffa4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L3/b7a6ffa4')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r86_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r50_BAG_L3 ... Tuning model for up to 19.31s of the 2061.13s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r50_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r50_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L3 ... Tuning model for up to 19.31s of the 2047.04s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r11_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9384\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t29.89s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.04s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r194_BAG_L3 ... Tuning model for up to 19.31s of the 2016.54s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r194_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.41%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r194_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.0s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r172_BAG_L3 ... Tuning model for up to 19.31s of the 1996.54s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.93s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r172_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r69_BAG_L3 ... Tuning model for up to 19.31s of the 1901.25s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r69_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.75%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r69_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.55s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L3 ... Tuning model for up to 19.31s of the 1887.15s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r103_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9383\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t21.01s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.43s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L3 ... Tuning model for up to 19.31s of the 1865.6s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r14_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=153576)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L3' in 0.0245s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4044d46d: FileNotFoundError('Could not fetch metrics for 4044d46d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L3/4044d46d')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ce371283: FileNotFoundError('Could not fetch metrics for ce371283: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L3/ce371283')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - de1eb5a8: FileNotFoundError('Could not fetch metrics for de1eb5a8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L3/de1eb5a8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r14_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r161_BAG_L3 ... Tuning model for up to 19.31s of the 1845.43s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r161_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.03%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r161_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L3 ... Tuning model for up to 19.31s of the 1836.73s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r143_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.45s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.06s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r70_BAG_L3 ... Tuning model for up to 19.31s of the 1815.7s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r70_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.80%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r70_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.88s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L3 ... Tuning model for up to 19.31s of the 1798.25s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r156_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.37s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.92s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r196_BAG_L3 ... Tuning model for up to 19.31s of the 1777.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r196_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.90%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r196_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t6.99s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r39_BAG_L3 ... Tuning model for up to 19.31s of the 1769.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r39_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.5s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r39_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r167_BAG_L3 ... Tuning model for up to 19.31s of the 1044.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r167_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.87%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r167_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L3 ... Tuning model for up to 19.31s of the 1026.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r95_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9384\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t21.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.89s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L3 ... Tuning model for up to 19.31s of the 1004.31s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r41_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=159373)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L3' in 0.0258s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e7aa4301: FileNotFoundError('Could not fetch metrics for e7aa4301: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L3/e7aa4301')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 918a5b98: FileNotFoundError('Could not fetch metrics for 918a5b98: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L3/918a5b98')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r41_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r98_BAG_L3 ... Tuning model for up to 19.31s of the 983.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r98_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r98_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.77s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.17s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r15_BAG_L3 ... Tuning model for up to 19.31s of the 971.22s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r15_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.74%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r15_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.94s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.82s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L3 ... Tuning model for up to 19.31s of the 951.73s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r158_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=160525)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=160525)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=160525)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=160525)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=160525)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L3' in 0.0254s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 68966569: FileNotFoundError('Could not fetch metrics for 68966569: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L3/68966569')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 1cc05244: FileNotFoundError('Could not fetch metrics for 1cc05244: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L3/1cc05244')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r158_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r86_BAG_L3 ... Tuning model for up to 19.31s of the 930.56s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r86_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.04%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r86_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.99s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L3 ... Tuning model for up to 19.31s of the 913.02s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r37_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.88s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.97s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L3 ... Tuning model for up to 19.31s of the 892.41s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r197_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=161932)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L3' in 0.0215s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 517597b9: FileNotFoundError('Could not fetch metrics for 517597b9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L3/517597b9')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - fe79b6c5: FileNotFoundError('Could not fetch metrics for fe79b6c5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L3/fe79b6c5')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r197_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r49_BAG_L3 ... Tuning model for up to 19.31s of the 871.43s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r49_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r49_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.82s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r49_BAG_L3 ... Tuning model for up to 19.31s of the 861.01s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.34s compared to 12.71s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r49_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r143_BAG_L3 ... Tuning model for up to 19.31s of the 847.96s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r143_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.94%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r143_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.71s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r127_BAG_L3 ... Tuning model for up to 19.31s of the 838.67s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r127_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.64s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r127_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L3 ... Tuning model for up to 19.31s of the -48.35s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r134_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9393\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.18s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.3s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r34_BAG_L3 ... Tuning model for up to 19.31s of the -68.11s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r34_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.71s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r34_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r94_BAG_L3 ... Tuning model for up to 19.31s of the -552.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r94_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r94_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.56s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.39s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L3 ... Tuning model for up to 19.31s of the -562.16s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r143_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=169316)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L3' in 0.0460s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d211847c: FileNotFoundError('Could not fetch metrics for d211847c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L3/d211847c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 0e5b2f87: FileNotFoundError('Could not fetch metrics for 0e5b2f87: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L3/0e5b2f87')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 43cafbe2: FileNotFoundError('Could not fetch metrics for 43cafbe2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r143_BAG_L3/43cafbe2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r143_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r128_BAG_L3 ... Tuning model for up to 19.31s of the -582.61s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r128_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.04%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r128_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.92s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.16s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L3 ... Tuning model for up to 19.31s of the -600.14s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r111_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.7s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.21s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L3 ... Tuning model for up to 19.31s of the -621.47s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r31_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=170715)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L3' in 0.0212s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 8e2ef3d6: FileNotFoundError('Could not fetch metrics for 8e2ef3d6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L3/8e2ef3d6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - bfebdb5f: FileNotFoundError('Could not fetch metrics for bfebdb5f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r31_BAG_L3/bfebdb5f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r31_BAG_L3... Skipping this model.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r4_BAG_L3 ... Tuning model for up to 19.31s of the -641.89s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 27.38s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r4_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L3 ... Tuning model for up to 19.31s of the -724.99s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r65_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9383\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.27s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L3 ... Tuning model for up to 19.31s of the -745.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.22%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r88_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t21.17s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.05s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r30_BAG_L3 ... Tuning model for up to 19.31s of the -767.65s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r30_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.86%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r30_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t7.47s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r49_BAG_L3 ... Tuning model for up to 19.31s of the -775.68s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r49_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.09%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r49_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9289\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.34s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.85s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r5_BAG_L3 ... Tuning model for up to 19.31s of the -794.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r5_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.73%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r5_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t13.96s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L3 ... Tuning model for up to 19.31s of the -809.19s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r87_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L3' in 0.0316s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9e3cde59: FileNotFoundError('Could not fetch metrics for 9e3cde59: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L3/9e3cde59')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 03c51124: FileNotFoundError('Could not fetch metrics for 03c51124: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r87_BAG_L3/03c51124')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r87_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L3 ... Tuning model for up to 19.31s of the -830.05s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r71_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L3' in 0.0421s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - dbff34f1: FileNotFoundError('Could not fetch metrics for dbff34f1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L3/dbff34f1')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - d8b73af4: FileNotFoundError('Could not fetch metrics for d8b73af4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r71_BAG_L3/d8b73af4')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r71_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r143_BAG_L3 ... Tuning model for up to 19.31s of the -851.03s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r143_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.88%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r143_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.03s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r178_BAG_L3 ... Tuning model for up to 19.31s of the -868.66s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 25.99s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r178_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r166_BAG_L3 ... Tuning model for up to 19.31s of the -940.89s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r166_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.86s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r166_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r31_BAG_L3 ... Tuning model for up to 19.31s of the -983.58s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r31_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.01%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r31_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.23s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.72s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L3 ... Tuning model for up to 19.31s of the -1002.41s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r185_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=175774)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L3' in 0.0299s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - def1e1d6: FileNotFoundError('Could not fetch metrics for def1e1d6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L3/def1e1d6')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 932c99b8: FileNotFoundError('Could not fetch metrics for 932c99b8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L3/932c99b8')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 99613f3f: FileNotFoundError('Could not fetch metrics for 99613f3f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r185_BAG_L3/99613f3f')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r185_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L3 ... Tuning model for up to 19.31s of the -1022.67s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.21%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r160_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9395\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t22.12s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r60_BAG_L3 ... Tuning model for up to 19.31s of the -1045.36s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r60_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.76%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r60_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t16.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r15_BAG_L3 ... Tuning model for up to 19.31s of the -1062.83s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r15_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 31.43s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r15_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r135_BAG_L3 ... Tuning model for up to 19.31s of the -1762.63s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r135_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.98%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r135_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9403\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.36s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.91s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r22_BAG_L3 ... Tuning model for up to 19.31s of the -1782.57s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r22_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.01%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r22_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.17s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.91s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L3 ... Tuning model for up to 19.31s of the -1801.3s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r69_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9397\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.12s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.99s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r6_BAG_L3 ... Tuning model for up to 19.31s of the -1822.02s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r6_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.74%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r6_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.9s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L3 ... Tuning model for up to 19.31s of the -1834.47s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r138_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9382\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t26.02s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t5.87s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r121_BAG_L3 ... Tuning model for up to 19.31s of the -1861.1s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r121_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.00%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r121_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.8183\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t8.21s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L3 ... Tuning model for up to 19.31s of the -1869.9s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r172_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9392\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.85s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.51s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r180_BAG_L3 ... Tuning model for up to 19.31s of the -1889.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r180_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.89%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r180_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.941\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.11s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.13s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L3 ... Tuning model for up to 19.31s of the -1907.1s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r76_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=182591)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L3' in 0.0251s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 1a8293da: FileNotFoundError('Could not fetch metrics for 1a8293da: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L3/1a8293da')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 7ff97ab7: FileNotFoundError('Could not fetch metrics for 7ff97ab7: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r76_BAG_L3/7ff97ab7')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r76_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r197_BAG_L3 ... Tuning model for up to 19.31s of the -1927.54s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.94s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r197_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L3 ... Tuning model for up to 19.31s of the -2037.13s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r121_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=183684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L3' in 0.0232s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a49ce650: FileNotFoundError('Could not fetch metrics for a49ce650: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L3/a49ce650')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ad1b6cda: FileNotFoundError('Could not fetch metrics for ad1b6cda: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r121_BAG_L3/ad1b6cda')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r121_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L3 ... Tuning model for up to 19.31s of the -2057.42s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r127_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.46s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.1s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: RandomForest_r16_BAG_L3 ... Tuning model for up to 19.31s of the -2078.45s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r16_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 26.52s compared to 10s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused RandomForest_r16_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L3 ... Tuning model for up to 19.31s of the -3101.21s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r194_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t21.71s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.97s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r12_BAG_L3 ... Tuning model for up to 19.31s of the -3123.49s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r12_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.88%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r12_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9407\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.38s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L3 ... Tuning model for up to 19.31s of the -3141.42s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r135_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler                │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                         │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=189557)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=189557)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=189557)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=189557)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L3' in 0.0237s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 9b14548c: FileNotFoundError('Could not fetch metrics for 9b14548c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L3/9b14548c')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 66df36b2: FileNotFoundError('Could not fetch metrics for 66df36b2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r135_BAG_L3/66df36b2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r135_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L3 ... Tuning model for up to 19.31s of the -3161.71s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r4_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.52s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.36s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: ExtraTrees_r126_BAG_L3 ... Tuning model for up to 19.31s of the -3182.83s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.36s compared to 12.59s of available time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Warning: Exception caused ExtraTrees_r126_BAG_L3 to fail during hyperparameter tuning... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m During handling of the above exception, another exception occurred:\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","\u001b[36m(_dystack pid=4732)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","\u001b[36m(_dystack pid=4732)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","\u001b[36m(_dystack pid=4732)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","\u001b[36m(_dystack pid=4732)\u001b[0m     self._fit_single(\n","\u001b[36m(_dystack pid=4732)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","\u001b[36m(_dystack pid=4732)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L3 ... Tuning model for up to 19.31s of the -3196.06s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r36_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L3' in 0.0521s.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 3 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - ad834852: FileNotFoundError('Could not fetch metrics for ad834852: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L3/ad834852')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a21f81aa: FileNotFoundError('Could not fetch metrics for a21f81aa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L3/a21f81aa')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - e64f97df: FileNotFoundError('Could not fetch metrics for e64f97df: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r36_BAG_L3/e64f97df')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r36_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L3 ... Tuning model for up to 19.31s of the -3216.36s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r100_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t19.0s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t2.3s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r163_BAG_L3 ... Tuning model for up to 19.31s of the -3235.99s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r163_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.76%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r163_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9408\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t11.87s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.08s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: CatBoost_r198_BAG_L3 ... Tuning model for up to 19.31s of the -3248.52s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r198_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.79%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: CatBoost_r198_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9409\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t17.25s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.09s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L3 ... Tuning model for up to 19.31s of the -3266.33s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.20%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: NeuralNetFastAI_r187_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9402\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t20.97s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t1.17s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L3 ... Tuning model for up to 19.31s of the -3287.87s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r19_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=192725)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L3' in 0.0456s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 2fa0c2f7: FileNotFoundError('Could not fetch metrics for 2fa0c2f7: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L3/2fa0c2f7')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - 4b167464: FileNotFoundError('Could not fetch metrics for 4b167464: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r19_BAG_L3/4b167464')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r19_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r95_BAG_L3 ... Tuning model for up to 19.31s of the -3308.75s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r95_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.01%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r95_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9391\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.26s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.79s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: XGBoost_r34_BAG_L3 ... Tuning model for up to 19.31s of the -3327.58s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r34_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: XGBoost_r34_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9062\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t18.67s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.91s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: LightGBM_r42_BAG_L3 ... Tuning model for up to 19.31s of the -3346.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r42_BAG_L3. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.96%)\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitted model: LightGBM_r42_BAG_L3 ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t9.29s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.45s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L3 ... Tuning model for up to 19.31s of the -3356.78s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭─────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r1_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├─────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator            │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler              │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                       │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰─────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=194228, ip=172.28.0.12)\n","\u001b[36m(model_trial pid=194162)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n","\u001b[36m(model_trial pid=194162)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(model_trial pid=194162)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","\u001b[36m(model_trial pid=194162)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(model_trial pid=194162)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 205, in _fit\n","\u001b[36m(model_trial pid=194162)\u001b[0m     raise TimeLimitExceeded\n","\u001b[36m(model_trial pid=194162)\u001b[0m autogluon.core.utils.exceptions.TimeLimitExceeded\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(model_trial pid=194162)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L3' in 0.0207s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - b76ad6fa: FileNotFoundError('Could not fetch metrics for b76ad6fa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L3/b76ad6fa')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a565c666: FileNotFoundError('Could not fetch metrics for a565c666: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r1_BAG_L3/a565c666')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r1_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L3 ... Tuning model for up to 19.31s of the -3377.87s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r89_BAG_L3   │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Search algorithm                 SearchGenerator             │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Scheduler                        FIFOScheduler               │\n","\u001b[36m(_dystack pid=4732)\u001b[0m │ Number of trials                 1000                        │\n","\u001b[36m(_dystack pid=4732)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n","\u001b[36m(_dystack pid=4732)\u001b[0m \n","\u001b[36m(_dystack pid=4732)\u001b[0m View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(model_trial pid=194830)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_dystack pid=4732)\u001b[0m Reached timeout of 19.312792567332583 seconds. Stopping all trials.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L3' in 0.0285s.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\u001b[36m(_dystack pid=4732)\u001b[0m Failed to fetch metrics for 2 trial(s):\n","\u001b[36m(_dystack pid=4732)\u001b[0m - f63d75e2: FileNotFoundError('Could not fetch metrics for f63d75e2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L3/f63d75e2')\n","\u001b[36m(_dystack pid=4732)\u001b[0m - a4545a72: FileNotFoundError('Could not fetch metrics for a4545a72: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r89_BAG_L3/a4545a72')\n","\u001b[36m(_dystack pid=4732)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r89_BAG_L3... Skipping this model.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.0s of the -3399.14s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tEnsemble Weights: {'CatBoost_r180_BAG_L3': 0.95, 'CatBoost_r50_BAG_L3': 0.05}\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.941\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t3.65s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(model_trial pid=194830)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting 108 L4 models ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Completed 1/10 k-fold bagging repeats ...\n","\u001b[36m(_dystack pid=4732)\u001b[0m Fitting model: WeightedEnsemble_ALL_L5 ... Training model for up to 360.0s of the -3407.37s of remaining time.\n","\u001b[36m(_dystack pid=4732)\u001b[0m \tEnsemble Weights: {'CatBoost_r180_BAG_L3': 1.0}\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.941\t = Validation score   (accuracy)\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t4.6s\t = Training   runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m \t0.01s\t = Validation runtime\n","\u001b[36m(_dystack pid=4732)\u001b[0m No base models to train on, skipping auxiliary stack level 5...\n","\u001b[36m(_dystack pid=4732)\u001b[0m AutoGluon training complete, total runtime = 21408.44s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 56.3 rows/s (12734 batch size)\n","\u001b[36m(_dystack pid=4732)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/ds_sub_fit/sub_fit_ho\")\n","\u001b[36m(_dystack pid=4732)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n","Leaderboard on holdout data (DyStack):\n","                                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0            NeuralNetFastAI_r156_BAG_L3       0.940633   0.939924    accuracy      258.555114     370.462150  6634.020886                 0.527282                0.920788          20.365808            3       True        233\n","1                   CatBoost_r177_BAG_L3       0.940382   0.940740    accuracy      258.106280     369.626000  6628.301109                 0.078448                0.084638          14.646031            3       True        212\n","2            NeuralNetFastAI_r100_BAG_L3       0.940382   0.938738    accuracy      259.007859     371.842413  6632.657121                 0.980026                2.301051          19.002042            3       True        268\n","3                   CatBoost_r128_BAG_L1       0.940319   0.939476    accuracy        0.204901       0.200213    41.874897                 0.204901                0.200213          41.874897            1       True         67\n","4                    CatBoost_r50_BAG_L1       0.940319   0.939649    accuracy        0.222182       0.143771    28.366065                 0.222182                0.143771          28.366065            1       True         37\n","5            NeuralNetFastAI_r172_BAG_L2       0.940256   0.940301    accuracy      121.680949     172.602840  3553.888412                 1.012426                1.568800          46.708963            2       True        187\n","6                   LightGBMLarge_BAG_L1       0.940193   0.939484    accuracy        1.164750       2.775606    13.837572                 1.164750                2.775606          13.837572            1       True         17\n","7                   CatBoost_r198_BAG_L2       0.940193   0.940466    accuracy      120.761041     171.127368  3534.808230                 0.092518                0.093328          27.628781            2       True        199\n","8            NeuralNetFastAI_r134_BAG_L2       0.940193   0.940057    accuracy      121.834106     173.465134  3553.698441                 1.165583                2.431094          46.518992            2       True        164\n","9                     CatBoost_r5_BAG_L2       0.940131   0.940513    accuracy      120.753999     171.139835  3527.309774                 0.085475                0.105795          20.130325            2       True        173\n","10                  CatBoost_r177_BAG_L2       0.940131   0.940348    accuracy      120.757654     171.128403  3525.021601                 0.089131                0.094363          17.842152            2       True        126\n","11           NeuralNetFastAI_r111_BAG_L2       0.940131   0.940418    accuracy      121.469522     172.287999  3554.090386                 0.800999                1.253959          46.910937            2       True        167\n","12           NeuralNetFastAI_r191_BAG_L2       0.940131   0.939209    accuracy      122.494507     174.598654  3553.716836                 1.825984                3.564614          46.537387            2       True        128\n","13    NeuralNetTorch_r87_BAG_L2/49036f65       0.940131   0.940144    accuracy      125.638539     177.411690  3552.047512                 4.970016                6.377650          44.868063            2       True        174\n","14            NeuralNetFastAI_r37_BAG_L3       0.940131   0.940238    accuracy      259.188433     371.514625  6633.539688                 1.160601                1.973263          19.884609            3       True        240\n","15                   CatBoost_r70_BAG_L1       0.940068   0.939515    accuracy        0.177063       0.224365    41.933054                 0.177063                0.224365          41.933054            1       True         46\n","16                    LightGBM_BAG_L1/T2       0.940068   0.939413    accuracy        0.404361       1.106961    10.435827                 0.404361                1.106961          10.435827            1       True          6\n","17                   CatBoost_r13_BAG_L2       0.940068   0.940324    accuracy      120.751908     171.129181  3539.351250                 0.083385                0.095141          32.171801            2       True        135\n","18           NeuralNetFastAI_r187_BAG_L2       0.940068   0.940599    accuracy      121.455226     172.189675  3554.667194                 0.786703                1.155635          47.487745            2       True        200\n","19                   CatBoost_r86_BAG_L3       0.940068   0.940811    accuracy      258.104172     369.644353  6630.644852                 0.076340                0.102990          16.989774            3       True        239\n","20                  CatBoost_r137_BAG_L3       0.940068   0.940874    accuracy      258.105850     369.623502  6629.151488                 0.078018                0.082139          15.496409            3       True        218\n","21                    CatBoost_r6_BAG_L3       0.940068   0.940842    accuracy      258.107968     369.631727  6625.553647                 0.080136                0.090364          11.898568            3       True        259\n","22                  CatBoost_r163_BAG_L3       0.940068   0.940795    accuracy      258.110854     369.625907  6625.528110                 0.083022                0.084545          11.873031            3       True        269\n","23                   CatBoost_r13_BAG_L3       0.940068   0.940717    accuracy      258.118376     369.642491  6631.101366                 0.090544                0.101129          17.446287            3       True        220\n","24                    LightGBM_BAG_L1/T1       0.940005   0.939939    accuracy        0.721255       1.861489    13.637803                 0.721255                1.861489          13.637803            1       True          5\n","25                  LightGBM_r130_BAG_L1       0.940005   0.939735    accuracy        0.882677       2.392741     7.953721                 0.882677                2.392741           7.953721            1       True         35\n","26                   CatBoost_r69_BAG_L2       0.940005   0.940466    accuracy      120.765414     171.122385  3542.266255                 0.096891                0.088345          35.086806            2       True        144\n","27                  LightGBM_r188_BAG_L2       0.940005   0.940348    accuracy      120.923273     171.709798  3522.912391                 0.254750                0.675758          15.732942            2       True        136\n","28                   CatBoost_r49_BAG_L3       0.940005   0.940827    accuracy      258.096682     369.620198  6623.474947                 0.068850                0.078836           9.819869            3       True        241\n","29                   CatBoost_r12_BAG_L3       0.940005   0.940717    accuracy      258.112342     369.635550  6631.038926                 0.084510                0.094187          17.383848            3       True        266\n","30                   CatBoost_r60_BAG_L3       0.940005   0.940623    accuracy      258.112950     369.640177  6630.526620                 0.085118                0.098814          16.871542            3       True        255\n","31                  CatBoost_r180_BAG_L3       0.940005   0.940984    accuracy      258.128122     369.668683  6630.760195                 0.100290                0.127320          17.105117            3       True        263\n","32               WeightedEnsemble_ALL_L5       0.940005   0.940984    accuracy      258.135045     369.676795  6635.362875                 0.006923                0.008112           4.602680            5       True        276\n","33                   WeightedEnsemble_L4       0.940005   0.941000    accuracy      258.219946     369.762449  6647.956520                 0.008620                0.010163           3.650559            4       True        275\n","34           NeuralNetFastAI_r187_BAG_L3       0.940005   0.940238    accuracy      258.726656     370.713006  6634.624367                 0.698824                1.171643          20.969288            3       True        271\n","35           NeuralNetFastAI_r143_BAG_L3       0.940005   0.940442    accuracy      258.802941     370.604439  6634.104801                 0.775109                1.063076          20.449723            3       True        231\n","36                    CatBoost_r9_BAG_L1       0.939942   0.939193    accuracy        0.247375       0.304245    42.089916                 0.247375                0.304245          42.089916            1       True         22\n","37                   CatBoost_r70_BAG_L2       0.939942   0.940411    accuracy      120.763275     171.142628  3525.171356                 0.094752                0.108588          17.991907            2       True        149\n","38            NeuralNetFastAI_r37_BAG_L2       0.939942   0.940301    accuracy      121.886580     173.095660  3554.597335                 1.218057                2.061620          47.417886            2       True        159\n","39                   CatBoost_r69_BAG_L3       0.939942   0.940748    accuracy      258.096462     369.627224  6627.203283                 0.068630                0.085861          13.548204            3       True        228\n","40                  CatBoost_r128_BAG_L3       0.939942   0.940780    accuracy      258.122657     369.705058  6630.576255                 0.094825                0.163696          16.921176            3       True        245\n","41                  CatBoost_r198_BAG_L3       0.939942   0.940858    accuracy      258.128948     369.629431  6630.903789                 0.101116                0.088069          17.248710            3       True        270\n","42           NeuralNetFastAI_r102_BAG_L3       0.939942   0.940340    accuracy      258.568869     370.377127  6633.950270                 0.541037                0.835764          20.295191            3       True        219\n","43                  CatBoost_r180_BAG_L1       0.939879   0.939649    accuracy        0.174599       0.204097    41.983991                 0.174599                0.204097          41.983991            1       True         93\n","44                    XGBoost_r22_BAG_L1       0.939879   0.939036    accuracy        0.331029       0.838440    42.381588                 0.331029                0.838440          42.381588            1       True         87\n","45                  CatBoost_r163_BAG_L2       0.939879   0.940489    accuracy      120.749794     171.125592  3523.629823                 0.081271                0.091552          16.450374            2       True        198\n","46                   CatBoost_r50_BAG_L2       0.939879   0.940623    accuracy      120.771356     171.170521  3537.231185                 0.102833                0.136481          30.051736            2       True        141\n","47           NeuralNetFastAI_r100_BAG_L2       0.939879   0.939028    accuracy      121.684447     173.173362  3554.883905                 1.015924                2.139322          47.704456            2       True        197\n","48            NeuralNetFastAI_r69_BAG_L2       0.939879   0.940301    accuracy      123.085096     174.835222  3550.120202                 2.416573                3.801183          42.940753            2       True        183\n","49    NeuralNetTorch_r41_BAG_L2/a436dcc8       0.939879   0.940096    accuracy      125.496366     176.225472  3552.003308                 4.827843                5.191432          44.823859            2       True        154\n","50   NeuralNetTorch_r185_BAG_L2/5d0c7630       0.939879   0.939751    accuracy      125.727758     176.649903  3550.526528                 5.059235                5.615863          43.347079            2       True        178\n","51                    CatBoost_r5_BAG_L3       0.939879   0.940709    accuracy      258.097851     369.619032  6627.619616                 0.070019                0.077669          13.964538            3       True        251\n","52                  CatBoost_r143_BAG_L3       0.939879   0.940733    accuracy      258.100517     369.639802  6630.684248                 0.072685                0.098440          17.029169            3       True        252\n","53                   CatBoost_r70_BAG_L3       0.939879   0.940733    accuracy      258.116165     369.663866  6630.531068                 0.088333                0.122504          16.875989            3       True        232\n","54                    CatBoost_r9_BAG_L2       0.939817   0.940693    accuracy      120.773585     171.184973  3551.080147                 0.105062                0.150933          43.900698            2       True        129\n","55                    CatBoost_BAG_L2/T1       0.939817   0.940835    accuracy      120.799021     171.238864  3538.618958                 0.130497                0.204824          31.439508            2       True        119\n","56                   WeightedEnsemble_L3       0.939817   0.940835    accuracy      120.806501     171.246647  3543.082088                 0.007481                0.007783           4.463130            3       True        206\n","57                   LightGBM_r94_BAG_L2       0.939817   0.940206    accuracy      120.848759     171.538351  3520.179149                 0.180236                0.504311          12.999700            2       True        165\n","58             NeuralNetFastAI_r4_BAG_L2       0.939817   0.940222    accuracy      122.090849     172.992354  3555.127942                 1.422326                1.958314          47.948493            2       True        194\n","59                 ExtraTreesEntr_BAG_L2       0.939817   0.939837    accuracy      122.602220     176.935377  3526.636665                 1.933697                5.901337          19.457216            2       True        121\n","60           NeuralNetFastAI_r160_BAG_L2       0.939817   0.940034    accuracy      123.681866     175.172699  3554.157354                 3.013343                4.138659          46.977905            2       True        179\n","61    NeuralNetTorch_r36_BAG_L2/3fae45e2       0.939817   0.939924    accuracy      125.503121     178.794987  3556.099274                 4.834598                7.760947          48.919825            2       True        196\n","62                   CatBoost_r50_BAG_L3       0.939817   0.940835    accuracy      258.111037     369.624966  6627.200844                 0.083205                0.083604          13.545765            3       True        225\n","63            NeuralNetFastAI_r11_BAG_L3       0.939817   0.938424    accuracy      261.276684     377.578206  6643.540134                 3.248852                8.036844          29.885056            3       True        226\n","64                   CatBoost_r12_BAG_L1       0.939754   0.939806    accuracy        0.094134       0.082150    41.962647                 0.094134                0.082150          41.962647            1       True        100\n","65                    LightGBM_BAG_L1/T3       0.939754   0.939672    accuracy        0.559803       1.423605    11.638124                 0.559803                1.423605          11.638124            1       True          7\n","66                   CatBoost_r86_BAG_L2       0.939754   0.940316    accuracy      120.750392     171.134068  3540.289994                 0.081869                0.100028          33.110545            2       True        158\n","67                    CatBoost_r6_BAG_L2       0.939754   0.940371    accuracy      120.750574     171.136640  3521.463692                 0.082051                0.102600          14.284243            2       True        184\n","68                  CatBoost_r167_BAG_L2       0.939754   0.940544    accuracy      120.768231     171.139371  3544.264694                 0.099708                0.105331          37.085245            2       True        152\n","69                  CatBoost_r143_BAG_L2       0.939754   0.940678    accuracy      120.780715     171.140806  3539.898330                 0.112192                0.106766          32.718881            2       True        176\n","70           NeuralNetFastAI_r143_BAG_L2       0.939754   0.940693    accuracy      121.365216     172.177943  3554.415975                 0.696693                1.143903          47.236526            2       True        148\n","71       NeuralNetFastAI_BAG_L2/759bc48e       0.939754   0.939672    accuracy      123.697984     174.224273  3552.249363                 3.029461                3.190233          45.069914            2       True        122\n","72    NeuralNetTorch_r31_BAG_L2/2eff4788       0.939754   0.939570    accuracy      125.688980     176.820095  3551.532981                 5.020457                5.786055          44.353532            2       True        168\n","73                  CatBoost_r167_BAG_L3       0.939754   0.940835    accuracy      258.111127     369.623475  6631.001253                 0.083295                0.082113          17.346174            3       True        235\n","74                  LightGBMXT_BAG_L3/T1       0.939754   0.940513    accuracy      258.269872     369.951484  6633.481768                 0.242040                0.410122          19.826689            3       True        207\n","75                    XGBoost_r22_BAG_L3       0.939754   0.939932    accuracy      258.511958     370.447340  6631.824866                 0.484126                0.905978          18.169788            3       True        257\n","76           NeuralNetFastAI_r111_BAG_L3       0.939754   0.940277    accuracy      258.643471     370.749771  6634.351606                 0.615639                1.208409          20.696527            3       True        246\n","77           NeuralNetFastAI_r103_BAG_L3       0.939754   0.938306    accuracy      259.594961     371.975697  6634.663375                 1.567129                2.434335          21.008296            3       True        229\n","78            NeuralNetFastAI_r69_BAG_L3       0.939754   0.939696    accuracy      260.486989     373.526663  6633.774309                 2.459157                3.985301          20.119230            3       True        258\n","79            NeuralNetFastAI_r95_BAG_L3       0.939754   0.938416    accuracy      260.802872     373.431986  6635.511688                 2.775040                3.890624          21.856609            3       True        236\n","80                  CatBoost_r198_BAG_L1       0.939691   0.939908    accuracy        0.089256       0.093646    41.991374                 0.089256                0.093646          41.991374            1       True        107\n","81                  CatBoost_r177_BAG_L1       0.939691   0.939877    accuracy        0.116992       0.067851    41.533118                 0.116992                0.067851          41.533118            1       True         18\n","82                    CatBoost_r6_BAG_L1       0.939691   0.939704    accuracy        0.130494       0.152138    38.920067                 0.130494                0.152138          38.920067            1       True         89\n","83                     XGBoost_BAG_L1/T1       0.939691   0.939657    accuracy        0.923864       0.928846    36.959544                 0.923864                0.928846          36.959544            1       True         15\n","84                  CatBoost_r180_BAG_L2       0.939691   0.940630    accuracy      120.770749     171.165527  3551.007862                 0.102226                0.131487          43.828413            2       True        188\n","85                  CatBoost_r128_BAG_L2       0.939691   0.940434    accuracy      120.789526     171.176436  3550.905340                 0.121003                0.142396          43.725891            2       True        166\n","86                  LightGBMXT_BAG_L2/T2       0.939691   0.940214    accuracy      121.023014     171.462334  3529.982804                 0.354491                0.428294          22.803355            2       True        117\n","87            NeuralNetFastAI_r65_BAG_L2       0.939691   0.940308    accuracy      121.344359     172.129272  3554.738521                 0.675836                1.095232          47.559072            2       True        169\n","88           NeuralNetFastAI_r127_BAG_L2       0.939691   0.940638    accuracy      121.477594     172.164726  3554.580211                 0.809071                1.130687          47.400762            2       True        190\n","89           NeuralNetFastAI_r145_BAG_L2       0.939691   0.940096    accuracy      123.288973     175.382164  3555.003606                 2.620450                4.348125          47.824157            2       True        137\n","90            NeuralNetFastAI_r11_BAG_L2       0.939691   0.939617    accuracy      123.548370     176.251795  3549.213759                 2.879847                5.217755          42.034310            2       True        142\n","91    NeuralNetTorch_r76_BAG_L2/0dce5434       0.939691   0.939994    accuracy      125.499323     176.819121  3552.645790                 4.830800                5.785081          45.466341            2       True        189\n","92                    CatBoost_r9_BAG_L3       0.939691   0.940717    accuracy      258.133829     369.672467  6630.447919                 0.105997                0.131105          16.792841            3       True        215\n","93           NeuralNetFastAI_r194_BAG_L3       0.939691   0.940206    accuracy      259.793077     372.514058  6635.361888                 1.765245                2.972696          21.706810            3       True        265\n","94                   CatBoost_r69_BAG_L1       0.939628   0.939405    accuracy        0.096973       0.100773    43.695107                 0.096973                0.100773          43.695107            1       True         41\n","95           NeuralNetFastAI_r111_BAG_L1       0.939628   0.939146    accuracy        0.552438       0.858061    44.403655                 0.552438                0.858061          44.403655            1       True         68\n","96    NeuralNetTorch_r30_BAG_L1/b0294e1d       0.939628   0.938542    accuracy        2.391128       1.558797    40.345050                 2.391128                1.558797          40.345050            1       True         34\n","97                   CatBoost_r12_BAG_L2       0.939628   0.940371    accuracy      120.765569     171.120553  3532.343747                 0.097046                0.086513          25.164298            2       True        192\n","98           NeuralNetFastAI_r102_BAG_L2       0.939628   0.940473    accuracy      121.224502     171.946428  3555.053601                 0.555979                0.912388          47.874152            2       True        134\n","99            NeuralNetFastAI_r95_BAG_L2       0.939628   0.940104    accuracy      123.474811     175.211216  3551.010222                 2.806288                4.177176          43.830773            2       True        153\n","100          NeuralNetFastAI_r138_BAG_L2       0.939628   0.939028    accuracy      123.563826     176.287877  3555.636865                 2.895303                5.253837          48.457416            2       True        185\n","101   NeuralNetTorch_r19_BAG_L2/dfa6bb85       0.939628   0.939452    accuracy      125.411964     177.299619  3552.682073                 4.743441                6.265579          45.502624            2       True        201\n","102                  LightGBM_r94_BAG_L3       0.939628   0.940332    accuracy      258.165483     369.934928  6623.210508                 0.137651                0.393566           9.555430            3       True        244\n","103           NeuralNetFastAI_r88_BAG_L3       0.939628   0.940136    accuracy      258.650545     370.589170  6634.826934                 0.622713                1.047808          21.171855            3       True        248\n","104          NeuralNetFastAI_r127_BAG_L3       0.939628   0.940395    accuracy      258.717012     370.637976  6634.110718                 0.689180                1.096614          20.455639            3       True        264\n","105          NeuralNetFastAI_r172_BAG_L3       0.939628   0.939225    accuracy      258.996017     371.056080  6632.505044                 0.968185                1.514717          18.849966            3       True        262\n","106                  CatBoost_r49_BAG_L1       0.939565   0.940065    accuracy        0.071451       0.090439    42.766867                 0.071451                0.090439          42.766867            1       True         59\n","107                 LightGBM_r135_BAG_L1       0.939565   0.938816    accuracy        0.451595       1.626229     7.770729                 0.451595                1.626229           7.770729            1       True         86\n","108                 LightGBMXT_BAG_L1/T1       0.939565   0.940136    accuracy        1.159896       2.098243    14.088969                 1.159896                2.098243          14.088969            1       True          1\n","109          NeuralNetFastAI_r194_BAG_L1       0.939565   0.938691    accuracy        1.736423       2.165815    43.630805                 1.736423                2.165815          43.630805            1       True         99\n","110                  CatBoost_r49_BAG_L2       0.939565   0.940591    accuracy      120.750211     171.124496  3519.244092                 0.081688                0.090456          12.064643            2       True        161\n","111                  LightGBM_r42_BAG_L2       0.939565   0.939979    accuracy      120.873634     171.515740  3517.459729                 0.205111                0.481700          10.280280            2       True        204\n","112                   LightGBM_BAG_L2/T1       0.939565   0.940269    accuracy      120.993399     171.497786  3536.895330                 0.324876                0.463746          29.715881            2       True        118\n","113                   XGBoost_r89_BAG_L2       0.939565   0.940363    accuracy      121.604538     171.840513  3552.150425                 0.936015                0.806473          44.970976            2       True        138\n","114          NeuralNetFastAI_r194_BAG_L2       0.939565   0.940489    accuracy      122.443967     173.544319  3555.379528                 1.775444                2.510279          48.200079            2       True        191\n","115  NeuralNetTorch_r197_BAG_L2/e2611625       0.939565   0.939539    accuracy      125.423478     177.073902  3552.950266                 4.754955                6.039862          45.770817            2       True        160\n","116                   CatBoost_BAG_L3/T1       0.939565   0.939201    accuracy      258.137053     369.929607  6627.964806                 0.109221                0.388245          14.309728            3       True        209\n","117                   LightGBM_BAG_L3/T1       0.939565   0.940151    accuracy      258.233790     369.877645  6633.422245                 0.205958                0.336283          19.767166            3       True        208\n","118            NeuralNetFastAI_r4_BAG_L3       0.939565   0.940144    accuracy      259.302133     371.900043  6634.173124                 1.274301                2.358681          20.518045            3       True        267\n","119                 CatBoost_r143_BAG_L1       0.939502   0.940089    accuracy        0.082563       0.080197    43.920108                 0.082563                0.080197          43.920108            1       True         78\n","120                 CatBoost_r167_BAG_L1       0.939502   0.939861    accuracy        0.106017       0.073163    41.488713                 0.106017                0.073163          41.488713            1       True         50\n","121                 LightGBMXT_BAG_L1/T2       0.939502   0.939625    accuracy        0.575938       1.410352    11.605049                 0.575938                1.410352          11.605049            1       True          2\n","122                 LightGBM_r188_BAG_L1       0.939502   0.939641    accuracy        1.441592       3.702803    13.204478                 1.441592                3.702803          13.204478            1       True         31\n","123                 CatBoost_r137_BAG_L2       0.939502   0.940575    accuracy      120.746599     171.124953  3522.417361                 0.078076                0.090913          15.237911            2       True        133\n","124          NeuralNetFastAI_r156_BAG_L2       0.939502   0.940206    accuracy      121.312474     171.996818  3554.682321                 0.643951                0.962778          47.502872            2       True        150\n","125   NeuralNetTorch_r71_BAG_L2/4472b381       0.939502   0.939531    accuracy      125.393867     176.472588  3551.421315                 4.725344                5.438548          44.241866            2       True        175\n","126    NeuralNetTorch_r1_BAG_L2/283e4f96       0.939502   0.939201    accuracy      125.842494     177.738365  3551.715634                 5.173971                6.704325          44.536185            2       True        205\n","127          NeuralNetFastAI_r138_BAG_L3       0.939502   0.938204    accuracy      260.930202     375.410217  6639.674596                 2.902370                5.868855          26.019517            3       True        260\n","128                 CatBoost_r163_BAG_L1       0.939440   0.940002    accuracy        0.081515       0.054604    41.795002                 0.081515                0.054604          41.795002            1       True        106\n","129           NeuralNetFastAI_r65_BAG_L1       0.939440   0.939555    accuracy        0.559502       0.713015    44.674327                 0.559502                0.713015          44.674327            1       True         71\n","130   NeuralNetTorch_r36_BAG_L1/e3feb519       0.939440   0.939107    accuracy        0.633240       0.824188    42.341719                 0.633240                0.824188          42.341719            1       True        104\n","131                  LightGBM_r15_BAG_L1       0.939440   0.939963    accuracy        1.028339       5.126521    13.558040                 1.028339                5.126521          13.558040            1       True         54\n","132      NeuralNetFastAI_BAG_L1/3cecdc0e       0.939440   0.937458    accuracy        4.651935       2.579392    41.247355                 4.651935                2.579392          41.247355            1       True         14\n","133           NeuralNetFastAI_r88_BAG_L2       0.939440   0.940253    accuracy      121.333661     172.046345  3553.639077                 0.665138                1.012305          46.459628            2       True        170\n","134               ExtraTrees_r126_BAG_L2       0.939440   0.939916    accuracy      122.524192     177.008834  3526.252784                 1.855669                5.974794          19.073334            2       True        195\n","135   NeuralNetTorch_r86_BAG_L2/7930d96a       0.939440   0.937442    accuracy      125.835436     176.731329  3550.327965                 5.166913                5.697289          43.148516            2       True        140\n","136                 LightGBM_r135_BAG_L3       0.939440   0.940285    accuracy      258.351818     370.447435  6633.019111                 0.323986                0.906073          19.364032            3       True        256\n","137                  CatBoost_r86_BAG_L1       0.939377   0.939083    accuracy        0.107425       0.086414    41.748996                 0.107425                0.086414          41.748996            1       True         56\n","138  NeuralNetTorch_r135_BAG_L1/cb69d765       0.939377   0.938298    accuracy        0.983464       1.372728    39.281824                 0.983464                1.372728          39.281824            1       True        101\n","139       NeuralNetTorch_BAG_L2/048d6a9c       0.939377   0.939083    accuracy      125.527253     177.172326  3552.485492                 4.858730                6.138286          45.306043            2       True        124\n","140                   XGBoost_r89_BAG_L3       0.939377   0.939932    accuracy      258.480553     370.348835  6631.788603                 0.452721                0.807472          18.133524            3       True        223\n","141                   XGBoost_r95_BAG_L3       0.939377   0.939146    accuracy      258.734181     370.328005  6631.915291                 0.706349                0.786643          18.260212            3       True        272\n","142           NeuralNetFastAI_r65_BAG_L3       0.939377   0.938306    accuracy      258.760892     370.545291  6633.921742                 0.733060                1.003928          20.266664            3       True        247\n","143          NeuralNetFastAI_r145_BAG_L3       0.939377   0.939719    accuracy      260.633778     373.391084  6633.507940                 2.605946                3.849722          19.852861            3       True        222\n","144                   CatBoost_r5_BAG_L1       0.939314   0.939751    accuracy        0.080401       0.078266    39.191190                 0.080401                0.078266          39.191190            1       True         75\n","145                  CatBoost_r60_BAG_L1       0.939314   0.939523    accuracy        0.099954       0.103312    41.918584                 0.099954                0.103312          41.918584            1       True         84\n","146                 CatBoost_r137_BAG_L1       0.939314   0.939531    accuracy        0.139830       0.095016    41.899967                 0.139830                0.095016          41.899967            1       True         27\n","147   NeuralNetTorch_r19_BAG_L1/55ced5fa       0.939314   0.939138    accuracy        0.590251       0.625888    40.830096                 0.590251                0.625888          40.830096            1       True        109\n","148                  CatBoost_r60_BAG_L2       0.939314   0.940654    accuracy      120.756716     171.134219  3525.194455                 0.088193                0.100179          18.015006            2       True        180\n","149                  LightGBM_r15_BAG_L2       0.939314   0.940261    accuracy      120.874383     171.646293  3523.852336                 0.205860                0.612253          16.672887            2       True        156\n","150                   XGBoost_r22_BAG_L2       0.939314   0.940261    accuracy      121.238208     172.139843  3552.340903                 0.569685                1.105803          45.161454            2       True        182\n","151                   XGBoost_r49_BAG_L2       0.939314   0.939924    accuracy      121.302430     172.148041  3552.459774                 0.633907                1.114001          45.280324            2       True        172\n","152          NeuralNetFastAI_r103_BAG_L2       0.939314   0.940104    accuracy      122.348750     173.331059  3553.706789                 1.680227                2.297019          46.527340            2       True        145\n","153   NeuralNetTorch_r89_BAG_L1/3adb369e       0.939251   0.938683    accuracy        1.001813       1.509941    39.219268                 1.001813                1.509941          39.219268            1       True        114\n","154                 LightGBMXT_BAG_L2/T1       0.939251   0.940308    accuracy      120.958633     171.544464  3532.528246                 0.290110                0.510424          25.348797            2       True        116\n","155   NeuralNetTorch_r14_BAG_L2/a1f244bd       0.939251   0.939649    accuracy      125.393560     176.271961  3551.912048                 4.725037                5.237921          44.732599            2       True        146\n","156          NeuralNetFastAI_r134_BAG_L3       0.939251   0.939256    accuracy      258.878579     371.846011  6632.831014                 0.850747                2.304649          19.175936            3       True        243\n","157          NeuralNetFastAI_r160_BAG_L3       0.939251   0.939468    accuracy      260.603460     373.648402  6635.776299                 2.575628                4.107040          22.121220            3       True        254\n","158                  LightGBM_r42_BAG_L1       0.939188   0.938895    accuracy        0.606324       2.857542     8.880119                 0.606324                2.857542           8.880119            1       True        112\n","159                 LightGBMXT_BAG_L1/T3       0.939188   0.939947    accuracy        0.737645       1.742537    12.073287                 0.737645                1.742537          12.073287            1       True          3\n","160    NeuralNetTorch_r1_BAG_L1/9b7f9998       0.939188   0.938416    accuracy        1.056173       1.959269    46.818229                 1.056173                1.959269          46.818229            1       True        113\n","161                  XGBoost_r194_BAG_L2       0.939188   0.939719    accuracy      120.940014     171.644522  3551.386644                 0.271491                0.610482          44.207195            2       True        143\n","162                ExtraTreesGini_BAG_L2       0.939188   0.940136    accuracy      122.780819     177.013676  3526.941710                 2.112296                5.979636          19.762261            2       True        120\n","163                ExtraTrees_r49_BAG_L2       0.939188   0.940136    accuracy      123.079381     176.922493  3527.192520                 2.410858                5.888453          20.013071            2       True        162\n","164  NeuralNetTorch_r135_BAG_L2/39af69f0       0.939188   0.938824    accuracy      125.866987     177.933157  3551.936608                 5.198464                6.899117          44.757159            2       True        193\n","165   NeuralNetTorch_r22_BAG_L2/003dd4ee       0.939188   0.937521    accuracy      126.141700     178.409176  3552.975228                 5.473177                7.375136          45.795779            2       True        131\n","166                 LightGBM_r130_BAG_L2       0.939126   0.940120    accuracy      120.848644     171.466456  3522.246654                 0.180121                0.432416          15.067204            2       True        139\n","167                    XGBoost_BAG_L2/T1       0.939126   0.940442    accuracy      122.306625     172.325748  3545.108534                 1.638102                1.291708          37.929085            2       True        123\n","168                  LightGBM_r15_BAG_L3       0.939126   0.940630    accuracy      258.254500     370.358983  6632.590535                 0.226668                0.817621          18.935457            3       True        238\n","169          NeuralNetFastAI_r191_BAG_L3       0.939126   0.938275    accuracy      259.907306     373.309820  6632.440601                 1.879474                3.768458          18.785522            3       True        214\n","170                 LightGBM_r130_BAG_L3       0.939063   0.940568    accuracy      258.195079     370.026979  6626.710321                 0.167247                0.485616          13.055242            3       True        224\n","171                  LightGBM_r42_BAG_L3       0.939063   0.940096    accuracy      258.222415     369.996321  6622.947829                 0.194583                0.454959           9.292750            3       True        274\n","172                  CatBoost_r13_BAG_L1       0.939000   0.938306    accuracy        0.166267       0.071757    41.893331                 0.166267                0.071757          41.893331            1       True         29\n","173                  XGBoost_r194_BAG_L1       0.939000   0.938769    accuracy        0.453216       0.562632    12.664851                 0.453216                0.562632          12.664851            1       True         39\n","174           NeuralNetFastAI_r88_BAG_L1       0.939000   0.938966    accuracy        0.539381       0.804920    44.468250                 0.539381                0.804920          44.468250            1       True         72\n","175   NeuralNetTorch_r41_BAG_L1/1405e6f6       0.939000   0.939146    accuracy        0.626466       0.611868    41.695104                 0.626466                0.611868          41.695104            1       True         52\n","176   NeuralNetTorch_r31_BAG_L1/b39bf32c       0.939000   0.939099    accuracy        0.894518       0.837138    42.307582                 0.894518                0.837138          42.307582            1       True         69\n","177   NeuralNetTorch_r79_BAG_L1/83d5c163       0.939000   0.938856    accuracy        0.962348       0.933194    40.137050                 0.962348                0.933194          40.137050            1       True         19\n","178  NeuralNetTorch_r121_BAG_L1/a0cf801b       0.939000   0.936712    accuracy        1.569633       2.312672    42.015718                 1.569633                2.312672          42.015718            1       True         96\n","179                 LightGBM_r135_BAG_L2       0.939000   0.940418    accuracy      121.247235     173.065982  3554.387336                 0.578712                2.031942          47.207887            2       True        181\n","180                   XGBoost_r95_BAG_L2       0.939000   0.940489    accuracy      121.552899     171.924510  3552.159048                 0.884376                0.890470          44.979599            2       True        202\n","181          NeuralNetFastAI_r156_BAG_L1       0.938937   0.939052    accuracy        0.390326       0.656249    44.928493                 0.390326                0.656249          44.928493            1       True         47\n","182                   XGBoost_r89_BAG_L1       0.938937   0.938549    accuracy        0.615891       0.698648    42.564461                 0.615891                0.698648          42.564461            1       True         33\n","183               ExtraTrees_r172_BAG_L1       0.938937   0.936720    accuracy        1.748831       2.876045    21.024152                 1.748831                2.876045          21.024152            1       True         40\n","184           NeuralNetFastAI_r11_BAG_L1       0.938937   0.936672    accuracy        6.441288       4.357285    43.147826                 6.441288                4.357285          43.147826            1       True         38\n","185                 LightGBMLarge_BAG_L2       0.938937   0.940112    accuracy      121.127535     171.643223  3545.255192                 0.459012                0.609183          38.075743            2       True        125\n","186                 LightGBM_r188_BAG_L3       0.938937   0.940261    accuracy      258.256297     370.175943  6626.106496                 0.228465                0.634580          12.451417            3       True        221\n","187                 LightGBMLarge_BAG_L3       0.938937   0.938887    accuracy      258.351511     369.999035  6633.336010                 0.323679                0.457673          19.680931            3       True        211\n","188   NeuralNetTorch_r87_BAG_L1/e411fa8f       0.938874   0.939437    accuracy        0.781797       1.028167    39.858767                 0.781797                1.028167          39.858767            1       True         76\n","189                   XGBoost_r34_BAG_L2       0.938874   0.938997    accuracy      121.329656     172.296098  3552.705956                 0.661133                1.262058          45.526506            2       True        203\n","190          NeuralNetFastAI_r172_BAG_L1       0.938811   0.938008    accuracy        0.678624       1.008609    43.973395                 0.678624                1.008609          43.973395            1       True         92\n","191  NeuralNetTorch_r185_BAG_L1/8a23346a       0.938811   0.938526    accuracy        0.958258       1.064867    41.644309                 0.958258                1.064867          41.644309            1       True         82\n","192                ExtraTrees_r42_BAG_L1       0.938811   0.935275    accuracy        3.460970       3.032679    13.650357                 3.460970                3.032679          13.650357            1       True         26\n","193                  WeightedEnsemble_L2       0.938811   0.940693    accuracy        4.160158      10.139032   249.082208                 0.011242                0.007446           4.447046            2       True        115\n","194          NeuralNetFastAI_r145_BAG_L1       0.938811   0.937827    accuracy        5.801834       3.964000    42.728944                 5.801834                3.964000          42.728944            1       True         32\n","195          NeuralNetFastAI_r143_BAG_L1       0.938749   0.938683    accuracy        0.567845       0.807355    44.481814                 0.567845                0.807355          44.481814            1       True         45\n","196          NeuralNetFastAI_r127_BAG_L1       0.938749   0.939233    accuracy        0.632991       0.848321    46.626251                 0.632991                0.848321          46.626251            1       True         97\n","197          NeuralNetFastAI_r160_BAG_L1       0.938749   0.938133    accuracy        2.436906       3.745600    44.242282                 2.436906                3.745600          44.242282            1       True         83\n","198          NeuralNetFastAI_r187_BAG_L1       0.938686   0.939358    accuracy        0.632048       0.878532    45.155924                 0.632048                0.878532          45.155924            1       True        108\n","199          NeuralNetFastAI_r102_BAG_L1       0.938686   0.938699    accuracy        0.921217       0.533736    43.008258                 0.921217                0.533736          43.008258            1       True         28\n","200                  LightGBM_r94_BAG_L1       0.938686   0.940206    accuracy        1.071673       5.673462    16.902123                 1.071673                5.673462          16.902123            1       True         65\n","201  NeuralNetTorch_r158_BAG_L1/38eb365a       0.938686   0.936586    accuracy        1.202414       1.165662    41.432930                 1.202414                1.165662          41.432930            1       True         55\n","202          NeuralNetFastAI_r191_BAG_L1       0.938623   0.937387    accuracy        1.794753       4.598969    41.930685                 1.794753                4.598969          41.930685            1       True         21\n","203           NeuralNetFastAI_r69_BAG_L1       0.938623   0.938188    accuracy        2.202990       3.163473    45.241813                 2.202990                3.163473          45.241813            1       True         88\n","204               ExtraTrees_r178_BAG_L1       0.938560   0.936822    accuracy        1.390746       2.932221    12.801103                 1.390746                2.932221          12.801103            1       True         79\n","205   NeuralNetTorch_r76_BAG_L1/8304ac35       0.938497   0.939217    accuracy        0.546971       0.738674    40.661391                 0.546971                0.738674          40.661391            1       True         94\n","206            NeuralNetFastAI_r4_BAG_L1       0.938497   0.938078    accuracy        1.169281       1.538732    44.689910                 1.169281                1.538732          44.689910            1       True        102\n","207   NeuralNetTorch_r14_BAG_L1/bba9c128       0.938434   0.939264    accuracy        0.584313       0.572037    41.139781                 0.584313                0.572037          41.139781            1       True         43\n","208          NeuralNetFastAI_r134_BAG_L1       0.938434   0.938196    accuracy        0.787520       1.886714    43.893181                 0.787520                1.886714          43.893181            1       True         63\n","209          NeuralNetFastAI_r103_BAG_L1       0.938434   0.937701    accuracy        1.429966       1.948287    45.429610                 1.429966                1.948287          45.429610            1       True         42\n","210   NeuralNetTorch_r22_BAG_L1/4fa9e245       0.938434   0.938055    accuracy        1.440146       1.477870    37.372478                 1.440146                1.477870          37.372478            1       True         24\n","211           NeuralNetFastAI_r37_BAG_L1       0.938372   0.938754    accuracy        0.974268       1.544729    43.366727                 0.974268                1.544729          43.366727            1       True         57\n","212  NeuralNetTorch_r143_BAG_L1/6a191ecc       0.938246   0.936633    accuracy        1.361496       1.903609    41.433811                 1.361496                1.903609          41.433811            1       True         66\n","213                  XGBoost_r194_BAG_L3       0.938246   0.940356    accuracy      258.233480     370.434753  6632.650270                 0.205648                0.893390          18.995192            3       True        227\n","214           NeuralNetFastAI_r95_BAG_L1       0.938183   0.937748    accuracy        2.330976       3.541245    44.383948                 2.330976                3.541245          44.383948            1       True         51\n","215       NeuralNetTorch_BAG_L1/210c66a2       0.938120   0.938754    accuracy        0.641373       0.611103    41.301295                 0.641373                0.611103          41.301295            1       True         16\n","216  NeuralNetTorch_r158_BAG_L2/04296e5e       0.938120   0.933751    accuracy      126.047650     176.804694  3550.584411                 5.379127                5.770654          43.404962            2       True        157\n","217               ExtraTrees_r197_BAG_L1       0.937932   0.935400    accuracy        2.434799       2.990062    16.202792                 2.434799                2.990062          16.202792            1       True         95\n","218                   CatBoost_BAG_L1/T1       0.937806   0.937536    accuracy        0.357763       0.226749    39.334683                 0.357763                0.226749          39.334683            1       True         11\n","219   NeuralNetTorch_r86_BAG_L1/ec66ec0f       0.937806   0.938479    accuracy        1.773352       1.101604    39.847555                 1.773352                1.101604          39.847555            1       True         36\n","220                   XGBoost_r95_BAG_L1       0.937681   0.938117    accuracy        0.304866       0.684327    42.515629                 0.304866                0.684327          42.515629            1       True        110\n","221                 ExtraTrees_r4_BAG_L1       0.937681   0.936366    accuracy        0.410957       2.601196    12.547508                 0.410957                2.601196          12.547508            1       True         70\n","222          NeuralNetFastAI_r138_BAG_L1       0.937681   0.936853    accuracy        2.582382       5.251459    45.328186                 2.582382                5.251459          45.328186            1       True         90\n","223                   XGBoost_r33_BAG_L2       0.937681   0.935549    accuracy      121.471225     172.441304  3552.469524                 0.802701                1.407264          45.290075            2       True        132\n","224  NeuralNetTorch_r197_BAG_L1/0ef42447       0.937618   0.938542    accuracy        0.561114       0.978242    41.963210                 0.561114                0.978242          41.963210            1       True         58\n","225             RandomForest_r127_BAG_L1       0.937618   0.936280    accuracy        0.804801       2.702256    24.833440                 0.804801                2.702256          24.833440            1       True         62\n","226                   XGBoost_r49_BAG_L1       0.937555   0.937144    accuracy        0.340453       0.786065    42.625179                 0.340453                0.786065          42.625179            1       True         74\n","227              RandomForestGini_BAG_L1       0.937492   0.936602    accuracy        2.225011       3.095324    12.107881                 2.225011                3.095324          12.107881            1       True          9\n","228             RandomForest_r166_BAG_L1       0.937492   0.936602    accuracy        2.724665       3.208997    12.932643                 2.724665                3.208997          12.932643            1       True         80\n","229              RandomForest_r15_BAG_L1       0.937429   0.935981    accuracy        1.076824       2.715040    20.209542                 1.076824                2.715040          20.209542            1       True         85\n","230   NeuralNetTorch_r71_BAG_L1/d6cd2d31       0.937304   0.938675    accuracy        0.563732       0.533914    41.390135                 0.563732                0.533914          41.390135            1       True         77\n","231          NeuralNetFastAI_r100_BAG_L1       0.937304   0.936233    accuracy        0.749071       1.699670    42.435204                 0.749071                1.699670          42.435204            1       True        105\n","232               ExtraTrees_r126_BAG_L1       0.937115   0.936696    accuracy        2.333935       3.230108     9.753258                 2.333935                3.230108           9.753258            1       True        103\n","233                ExtraTreesGini_BAG_L1       0.937115   0.936162    accuracy        3.947883       3.421863    10.454776                 3.947883                3.421863          10.454776            1       True         12\n","234                ExtraTrees_r49_BAG_L1       0.937115   0.936162    accuracy        4.552542       3.479233    12.399245                 4.552542                3.479233          12.399245            1       True         60\n","235              RandomForestEntr_BAG_L1       0.936990   0.936570    accuracy        2.155821       3.191642    11.716874                 2.155821                3.191642          11.716874            1       True         10\n","236                ExtraTreesEntr_BAG_L1       0.936990   0.936005    accuracy        4.472613       3.529949    11.022064                 4.472613                3.529949          11.022064            1       True         13\n","237              RandomForest_r34_BAG_L1       0.936864   0.935479    accuracy        0.317597       2.383875    16.653274                 0.317597                2.383875          16.653274            1       True         64\n","238              RandomForest_r39_BAG_L1       0.936864   0.935887    accuracy        1.866541       2.770078    19.704888                 1.866541                2.770078          19.704888            1       True         49\n","239                    XGBoost_BAG_L3/T1       0.936801   0.933272    accuracy      259.113254     370.530716  6632.523825                 1.085422                0.989354          18.868746            3       True        210\n","240             RandomForest_r195_BAG_L1       0.935984   0.935047    accuracy        2.045100       2.834630    19.863405                 2.045100                2.834630          19.863405            1       True         30\n","241                   XGBoost_r34_BAG_L1       0.935922   0.934442    accuracy        0.709537       1.410893    42.587009                 0.709537                1.410893          42.587009            1       True        111\n","242              RandomForest_r16_BAG_L1       0.934288   0.934466    accuracy        1.604559       2.827788    27.225301                 1.604559                2.827788          27.225301            1       True         98\n","243                   XGBoost_r33_BAG_L1       0.932529   0.930775    accuracy        0.844801       1.379097    42.760926                 0.844801                1.379097          42.760926            1       True         25\n","244                   XGBoost_r49_BAG_L3       0.931524   0.928859    accuracy      258.473581     370.389244  6631.998051                 0.445749                0.847881          18.342973            3       True        250\n","245                   XGBoost_r34_BAG_L3       0.912175   0.906202    accuracy      258.539698     370.448682  6632.324330                 0.511866                0.907320          18.669252            3       True        273\n","246                 LightGBM_r131_BAG_L1       0.818382   0.818350    accuracy        0.046735       0.044475     3.554259                 0.046735                0.044475           3.554259            1       True         20\n","247                 LightGBM_r196_BAG_L1       0.818382   0.818350    accuracy        0.052204       0.049190     3.904946                 0.052204                0.049190           3.904946            1       True         48\n","248                 LightGBM_r121_BAG_L1       0.818382   0.818350    accuracy        0.052984       0.045523     3.966262                 0.052984                0.045523           3.966262            1       True         91\n","249                  LightGBM_r30_BAG_L1       0.818382   0.818350    accuracy        0.053356       0.043520     3.857620                 0.053356                0.043520           3.857620            1       True         73\n","250                 LightGBM_r143_BAG_L1       0.818382   0.818350    accuracy        0.055121       0.043944     3.647445                 0.055121                0.043944           3.647445            1       True         61\n","251                 LightGBM_r161_BAG_L1       0.818382   0.818350    accuracy        0.056187       0.051877     3.821935                 0.056187                0.051877           3.821935            1       True         44\n","252                  LightGBM_r96_BAG_L1       0.818382   0.818350    accuracy        0.079674       0.042653     3.556678                 0.079674                0.042653           3.556678            1       True         23\n","253                   LightGBM_BAG_L1/T4       0.818382   0.818350    accuracy        0.093753       0.081329     6.870286                 0.093753                0.081329           6.870286            1       True          8\n","254                 LightGBMXT_BAG_L1/T4       0.818382   0.818350    accuracy        0.108754       0.081880     6.726705                 0.108754                0.081880           6.726705            1       True          4\n","255                   XGBoost_r98_BAG_L1       0.818382   0.818350    accuracy        0.149928       0.054328     5.562835                 0.149928                0.054328           5.562835            1       True         53\n","256                   XGBoost_r31_BAG_L1       0.818382   0.818350    accuracy        0.481001       0.236531    19.201123                 0.481001                0.236531          19.201123            1       True         81\n","257                 LightGBM_r143_BAG_L2       0.818382   0.818350    accuracy      120.756100     171.186575  3517.286819                 0.087577                0.152535          10.107370            2       True        163\n","258                 LightGBM_r121_BAG_L2       0.818382   0.818350    accuracy      120.756353     171.174320  3516.201266                 0.087830                0.140280           9.021817            2       True        186\n","259                  LightGBM_r96_BAG_L2       0.818382   0.818350    accuracy      120.756604     171.182519  3515.097333                 0.088081                0.148479           7.917884            2       True        130\n","260                  LightGBM_r30_BAG_L2       0.818382   0.818350    accuracy      120.758367     171.168916  3515.459049                 0.089844                0.134876           8.279600            2       True        171\n","261                 LightGBM_r161_BAG_L2       0.818382   0.818350    accuracy      120.758550     171.158741  3516.478033                 0.090027                0.124701           9.298584            2       True        147\n","262                 LightGBM_r196_BAG_L2       0.818382   0.818350    accuracy      120.777643     171.164685  3515.264251                 0.109120                0.130645           8.084801            2       True        151\n","263                 LightGBM_r131_BAG_L2       0.818382   0.818350    accuracy      120.784213     171.170360  3516.824648                 0.115690                0.136320           9.645199            2       True        127\n","264                   XGBoost_r98_BAG_L2       0.818382   0.818350    accuracy      120.852164     171.226437  3520.801891                 0.183641                0.192397          13.622442            2       True        155\n","265                   XGBoost_r31_BAG_L2       0.818382   0.818350    accuracy      121.373232     171.763942  3532.086679                 0.704709                0.729902          24.907230            2       True        177\n","266                  LightGBM_r30_BAG_L3       0.818382   0.818350    accuracy      258.104781     369.671881  6621.126915                 0.076949                0.130519           7.471837            3       True        249\n","267                 LightGBM_r121_BAG_L3       0.818382   0.818350    accuracy      258.107140     369.653411  6621.865535                 0.079308                0.112049           8.210456            3       True        261\n","268                 LightGBM_r131_BAG_L3       0.818382   0.818350    accuracy      258.109459     369.645432  6620.617340                 0.081627                0.104070           6.962261            3       True        213\n","269                 LightGBM_r196_BAG_L3       0.818382   0.818350    accuracy      258.110532     369.647843  6620.643591                 0.082700                0.106480           6.988512            3       True        234\n","270                  LightGBM_r96_BAG_L3       0.818382   0.818350    accuracy      258.114871     369.663107  6620.790678                 0.087039                0.121744           7.135599            3       True        216\n","271                 LightGBM_r143_BAG_L3       0.818382   0.818350    accuracy      258.115709     369.658057  6622.365372                 0.087877                0.116695           8.710294            3       True        242\n","272                 LightGBM_r161_BAG_L3       0.818382   0.818350    accuracy      258.126563     369.664905  6621.796850                 0.098731                0.123543           8.141771            3       True        230\n","273                   XGBoost_r98_BAG_L3       0.818382   0.818350    accuracy      258.193590     369.715236  6625.429936                 0.165758                0.173874          11.774857            3       True        237\n","274                   XGBoost_r31_BAG_L3       0.818382   0.818350    accuracy      258.713768     370.257746  6631.887987                 0.685936                0.716383          18.232908            3       True        253\n","275                   XGBoost_r33_BAG_L3       0.818382   0.829776    accuracy      258.762316     370.203978  6631.745911                 0.734484                0.662615          18.090832            3       True        217\n","\t3\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t21735s\t = DyStack   runtime |\t50265s\t = Remaining runtime\n","Starting main fit with num_stack_levels=3.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=3)`\n","Beginning AutoGluon training ... Time limit = 50265s\n","AutoGluon will save models to \"/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy\"\n","Train Data Rows:    143256\n","Train Data Columns: 17\n","Label Column:       depression\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    48872.63 MB\n","\tTrain Data (Original)  Memory Usage: 56.67 MB (0.1% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])  : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\t\t('int', [])    : 5 | ['is_female', 'age', 'is_student', 'suicidal_thoughts', 'family_history']\n","\t\t('object', []) : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  : 5 | ['city', 'profession', 'sleep_duration', 'dietary_habits', 'degree']\n","\t\t('float', [])     : 7 | ['academic_pressure', 'work_pressure', 'cgpa', 'study_satisfaction', 'job_satisfaction', ...]\n","\t\t('int', [])       : 1 | ['age']\n","\t\t('int', ['bool']) : 4 | ['is_female', 'is_student', 'suicidal_thoughts', 'family_history']\n","\t0.7s = Fit runtime\n","\t17 features in original data used to generate 17 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 9.98 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.91s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","AutoGluon will fit 4 stack levels (L1 to L4) ...\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L1 models ...\n","Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 139.59s of the 50263.86s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: LightGBMXT_BAG_L1/T1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t16.45s\t = Training   runtime\n","\t1.91s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T2 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t12.32s\t = Training   runtime\n","\t1.26s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T3 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t16.22s\t = Training   runtime\n","\t2.8s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T4 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.43s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T5 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t13.07s\t = Training   runtime\n","\t1.29s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T6 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t8.14s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T7 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t11.98s\t = Training   runtime\n","\t1.19s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T8 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t12.04s\t = Training   runtime\n","\t1.57s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T9 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.56s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T10 ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t10.95s\t = Training   runtime\n","\t1.02s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T11 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.61s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L1/T12 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t8.05s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 139.59s of the 50128.23s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: LightGBM_BAG_L1/T1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t14.16s\t = Training   runtime\n","\t2.11s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T2 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t13.89s\t = Training   runtime\n","\t1.49s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T3 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t16.2s\t = Training   runtime\n","\t2.2s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T4 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.85s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T5 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t11.46s\t = Training   runtime\n","\t0.89s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T6 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t8.14s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T7 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t12.05s\t = Training   runtime\n","\t0.92s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T8 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t12.25s\t = Training   runtime\n","\t1.15s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T9 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.92s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T10 ...\n","\t0.9391\t = Validation score   (accuracy)\n","\t11.23s\t = Training   runtime\n","\t0.74s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T11 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.58s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L1/T12 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t8.07s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Hyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 139.59s of the 49996.51s of remaining time.\n","\tNo hyperparameter search space specified for RandomForestGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForestGini_BAG_L1 ...\n","\t0.9366\t = Validation score   (accuracy)\n","\t16.11s\t = Training   runtime\n","\t4.24s\t = Validation runtime\n","Hyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 139.59s of the 49980.16s of remaining time.\n","\tNo hyperparameter search space specified for RandomForestEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForestEntr_BAG_L1 ...\n","\t0.9368\t = Validation score   (accuracy)\n","\t16.61s\t = Training   runtime\n","\t4.45s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 139.59s of the 49963.45s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: CatBoost_BAG_L1/T1 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t113.25s\t = Training   runtime\n","\t0.3s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 139.59s of the 49849.84s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTreesGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTreesGini_BAG_L1 ...\n","\t0.9365\t = Validation score   (accuracy)\n","\t16.48s\t = Training   runtime\n","\t4.71s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 139.59s of the 49833.26s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTreesEntr_BAG_L1 ...\n","\t0.9363\t = Validation score   (accuracy)\n","\t17.44s\t = Training   runtime\n","\t4.91s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 139.59s of the 49815.72s of remaining time.\n","2024-11-14 05:37:41,437\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------+\n","| Configuration for experiment     NeuralNetFastAI_BAG_L1   |\n","+-----------------------------------------------------------+\n","| Search algorithm                 SearchGenerator          |\n","| Scheduler                        FIFOScheduler            |\n","| Number of trials                 1000                     |\n","+-----------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 05:40:01,215\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 05:40:01,256\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L1' in 0.0351s.\n","2024-11-14 05:40:03,579\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- a961d4e0: FileNotFoundError('Could not fetch metrics for a961d4e0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L1/a961d4e0')\n","- d3003a45: FileNotFoundError('Could not fetch metrics for d3003a45: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L1/d3003a45')\n","- 7bf9c91e: FileNotFoundError('Could not fetch metrics for 7bf9c91e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L1/7bf9c91e')\n","Fitted model: NeuralNetFastAI_BAG_L1/a961d4e0 ...\n","\t0.9388\t = Validation score   (accuracy)\n","\t110.17s\t = Training   runtime\n","\t3.43s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 139.59s of the 49673.0s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: XGBoost_BAG_L1/T1 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t57.91s\t = Training   runtime\n","\t1.13s\t = Validation runtime\n","Fitted model: XGBoost_BAG_L1/T2 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t66.2s\t = Training   runtime\n","\t1.47s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 139.59s of the 49548.56s of remaining time.\n","2024-11-14 05:42:08,188\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_BAG_L1   |\n","+----------------------------------------------------------+\n","| Search algorithm                 SearchGenerator         |\n","| Scheduler                        FIFOScheduler           |\n","| Number of trials                 1000                    |\n","+----------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 05:44:28,192\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 05:44:28,230\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L1' in 0.0331s.\n","2024-11-14 05:44:28,252\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 5b86853e: FileNotFoundError('Could not fetch metrics for 5b86853e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L1/5b86853e')\n","- e1a2cd1a: FileNotFoundError('Could not fetch metrics for e1a2cd1a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L1/e1a2cd1a')\n","- 752a5fe3: FileNotFoundError('Could not fetch metrics for 752a5fe3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L1/752a5fe3')\n","Fitted model: NeuralNetTorch_BAG_L1/5b86853e ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t105.64s\t = Training   runtime\n","\t0.95s\t = Validation runtime\n","Fitted model: NeuralNetTorch_BAG_L1/e1a2cd1a ...\n","\t0.9378\t = Validation score   (accuracy)\n","\t27.11s\t = Training   runtime\n","\t0.88s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 139.59s of the 49408.32s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\t0.9398\t = Validation score   (accuracy)\n","\t20.88s\t = Training   runtime\n","\t3.68s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r177_BAG_L1 ... Tuning model for up to 139.59s of the 49383.99s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r177_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","Fitted model: CatBoost_r177_BAG_L1 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t69.74s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L1 ... Tuning model for up to 139.59s of the 49314.13s of remaining time.\n","2024-11-14 05:46:02,600\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r79_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 05:48:22,349\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 05:48:22,386\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1' in 0.0328s.\n","2024-11-14 05:48:22,399\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 1d23343b: FileNotFoundError('Could not fetch metrics for 1d23343b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1/1d23343b')\n","- dcf6d772: FileNotFoundError('Could not fetch metrics for dcf6d772: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1/dcf6d772')\n","- a9595317: FileNotFoundError('Could not fetch metrics for a9595317: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1/a9595317')\n","- 17b161d8: FileNotFoundError('Could not fetch metrics for 17b161d8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1/17b161d8')\n","- 56af6b08: FileNotFoundError('Could not fetch metrics for 56af6b08: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L1/56af6b08')\n","Fitted model: NeuralNetTorch_r79_BAG_L1/1d23343b ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t111.01s\t = Training   runtime\n","\t1.57s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r131_BAG_L1 ... Tuning model for up to 139.59s of the 49174.17s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r131_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: LightGBM_r131_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t3.54s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L1 ... Tuning model for up to 139.59s of the 49170.54s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r191_BAG_L1 ...\n","\t0.9385\t = Validation score   (accuracy)\n","\t112.94s\t = Training   runtime\n","\t4.0s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r9_BAG_L1 ... Tuning model for up to 139.59s of the 49057.46s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r9_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","Fitted model: CatBoost_r9_BAG_L1 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t113.58s\t = Training   runtime\n","\t0.32s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r96_BAG_L1 ... Tuning model for up to 139.59s of the 48943.77s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r96_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: LightGBM_r96_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t3.78s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L1 ... Tuning model for up to 139.59s of the 48939.88s of remaining time.\n","2024-11-14 05:52:16,876\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r22_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 05:54:36,668\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 05:54:36,703\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1' in 0.0317s.\n","2024-11-14 05:54:37,562\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 680420a5: FileNotFoundError('Could not fetch metrics for 680420a5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1/680420a5')\n","- df57e77f: FileNotFoundError('Could not fetch metrics for df57e77f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1/df57e77f')\n","- 1fd16813: FileNotFoundError('Could not fetch metrics for 1fd16813: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1/1fd16813')\n","- 3ac04063: FileNotFoundError('Could not fetch metrics for 3ac04063: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L1/3ac04063')\n","Fitted model: NeuralNetTorch_r22_BAG_L1/680420a5 ...\n","\t0.939\t = Validation score   (accuracy)\n","\t110.77s\t = Training   runtime\n","\t1.9s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r33_BAG_L1 ... Tuning model for up to 139.59s of the 48799.03s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r33_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.28%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: XGBoost_r33_BAG_L1 ...\n","\t0.9379\t = Validation score   (accuracy)\n","\t115.27s\t = Training   runtime\n","\t5.0s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r42_BAG_L1 ... Tuning model for up to 139.59s of the 48683.66s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r42_BAG_L1 ...\n","\t0.9359\t = Validation score   (accuracy)\n","\t21.77s\t = Training   runtime\n","\t4.2s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r137_BAG_L1 ... Tuning model for up to 139.59s of the 48661.78s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r137_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r137_BAG_L1 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t107.89s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L1 ... Tuning model for up to 139.59s of the 48553.8s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r102_BAG_L1 ...\n","\t0.9386\t = Validation score   (accuracy)\n","\t56.39s\t = Training   runtime\n","\t0.68s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r13_BAG_L1 ... Tuning model for up to 139.59s of the 48497.31s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r13_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","Fitted model: CatBoost_r13_BAG_L1 ...\n","\t0.9371\t = Validation score   (accuracy)\n","\t113.87s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r195_BAG_L1 ... Tuning model for up to 139.59s of the 48383.3s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r195_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r195_BAG_L1 ...\n","\t0.9349\t = Validation score   (accuracy)\n","\t27.59s\t = Training   runtime\n","\t4.08s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r188_BAG_L1 ... Tuning model for up to 139.59s of the 48355.6s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r188_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: LightGBM_r188_BAG_L1 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t12.25s\t = Training   runtime\n","\t4.29s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L1 ... Tuning model for up to 139.59s of the 48343.24s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r145_BAG_L1 ...\n","\t0.9389\t = Validation score   (accuracy)\n","\t117.33s\t = Training   runtime\n","\t5.52s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r89_BAG_L1 ... Tuning model for up to 139.59s of the 48225.79s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r89_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","Fitted model: XGBoost_r89_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t114.47s\t = Training   runtime\n","\t1.07s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L1 ... Tuning model for up to 139.59s of the 48111.18s of remaining time.\n","2024-11-14 06:06:05,577\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r30_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:08:25,335\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:08:25,409\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1' in 0.0685s.\n","2024-11-14 06:08:25,720\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 27cbb32f: FileNotFoundError('Could not fetch metrics for 27cbb32f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1/27cbb32f')\n","- 22d356f8: FileNotFoundError('Could not fetch metrics for 22d356f8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1/22d356f8')\n","- d43ee970: FileNotFoundError('Could not fetch metrics for d43ee970: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1/d43ee970')\n","- 737486a0: FileNotFoundError('Could not fetch metrics for 737486a0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L1/737486a0')\n","Fitted model: NeuralNetTorch_r30_BAG_L1/27cbb32f ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t115.12s\t = Training   runtime\n","\t2.09s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r130_BAG_L1 ... Tuning model for up to 139.59s of the 47970.84s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r130_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","Fitted model: LightGBM_r130_BAG_L1 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t11.57s\t = Training   runtime\n","\t3.67s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L1 ... Tuning model for up to 139.59s of the 47959.11s of remaining time.\n","2024-11-14 06:08:37,626\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r86_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:10:57,444\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:10:57,483\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1' in 0.0344s.\n","2024-11-14 06:10:57,500\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 7a868604: FileNotFoundError('Could not fetch metrics for 7a868604: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1/7a868604')\n","- dff255d1: FileNotFoundError('Could not fetch metrics for dff255d1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1/dff255d1')\n","- 97c05d84: FileNotFoundError('Could not fetch metrics for 97c05d84: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1/97c05d84')\n","- b5dcbbef: FileNotFoundError('Could not fetch metrics for b5dcbbef: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L1/b5dcbbef')\n","Fitted model: NeuralNetTorch_r86_BAG_L1/7a868604 ...\n","\t0.9388\t = Validation score   (accuracy)\n","\t112.15s\t = Training   runtime\n","\t1.66s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r50_BAG_L1 ... Tuning model for up to 139.59s of the 47819.08s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r50_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: CatBoost_r50_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t113.34s\t = Training   runtime\n","\t0.38s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L1 ... Tuning model for up to 139.59s of the 47705.65s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r11_BAG_L1 ...\n","\t0.9369\t = Validation score   (accuracy)\n","\t114.3s\t = Training   runtime\n","\t6.22s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r194_BAG_L1 ... Tuning model for up to 139.59s of the 47591.22s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.20%)\n","Fitted model: XGBoost_r194_BAG_L1 ...\n","\t0.939\t = Validation score   (accuracy)\n","\t16.41s\t = Training   runtime\n","\t0.59s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r172_BAG_L1 ... Tuning model for up to 139.59s of the 47574.71s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r172_BAG_L1 ...\n","\t0.9369\t = Validation score   (accuracy)\n","\t23.59s\t = Training   runtime\n","\t4.13s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r69_BAG_L1 ... Tuning model for up to 139.59s of the 47550.99s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r69_BAG_L1 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t113.9s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L1 ... Tuning model for up to 139.59s of the 47436.99s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r103_BAG_L1 ...\n","\t0.9387\t = Validation score   (accuracy)\n","\t116.65s\t = Training   runtime\n","\t3.15s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L1 ... Tuning model for up to 139.59s of the 47320.23s of remaining time.\n","2024-11-14 06:19:16,525\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r14_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:21:36,301\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:21:36,337\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L1' in 0.0309s.\n","2024-11-14 06:21:36,352\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 8a437fd2: FileNotFoundError('Could not fetch metrics for 8a437fd2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L1/8a437fd2')\n","- 99c1b2b6: FileNotFoundError('Could not fetch metrics for 99c1b2b6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L1/99c1b2b6')\n","- 01959df9: FileNotFoundError('Could not fetch metrics for 01959df9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L1/01959df9')\n","Fitted model: NeuralNetTorch_r14_BAG_L1/8a437fd2 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t101.87s\t = Training   runtime\n","\t0.96s\t = Validation runtime\n","Fitted model: NeuralNetTorch_r14_BAG_L1/99c1b2b6 ...\n","\t0.9385\t = Validation score   (accuracy)\n","\t30.26s\t = Training   runtime\n","\t1.15s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r161_BAG_L1 ... Tuning model for up to 139.59s of the 47180.22s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r161_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: LightGBM_r161_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t4.47s\t = Training   runtime\n","\t0.07s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L1 ... Tuning model for up to 139.59s of the 47175.62s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r143_BAG_L1 ...\n","\t0.9393\t = Validation score   (accuracy)\n","\t109.3s\t = Training   runtime\n","\t1.01s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r70_BAG_L1 ... Tuning model for up to 139.59s of the 47066.19s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r70_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","Fitted model: CatBoost_r70_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t102.59s\t = Training   runtime\n","\t0.35s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L1 ... Tuning model for up to 139.59s of the 46963.49s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r156_BAG_L1 ...\n","\t0.9391\t = Validation score   (accuracy)\n","\t82.04s\t = Training   runtime\n","\t0.71s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r196_BAG_L1 ... Tuning model for up to 139.59s of the 46881.35s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r196_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: LightGBM_r196_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t4.19s\t = Training   runtime\n","\t0.06s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r39_BAG_L1 ... Tuning model for up to 139.59s of the 46877.03s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r39_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r39_BAG_L1 ...\n","\t0.9357\t = Validation score   (accuracy)\n","\t28.29s\t = Training   runtime\n","\t3.98s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r167_BAG_L1 ... Tuning model for up to 139.59s of the 46848.63s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r167_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: CatBoost_r167_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t57.63s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L1 ... Tuning model for up to 139.59s of the 46790.9s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r95_BAG_L1 ...\n","\t0.9385\t = Validation score   (accuracy)\n","\t114.48s\t = Training   runtime\n","\t5.64s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L1 ... Tuning model for up to 139.59s of the 46676.28s of remaining time.\n","2024-11-14 06:30:00,457\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r41_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:32:20,238\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:32:20,275\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1' in 0.0336s.\n","2024-11-14 06:32:22,238\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- ad5d969d: FileNotFoundError('Could not fetch metrics for ad5d969d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1/ad5d969d')\n","- 88d0d46e: FileNotFoundError('Could not fetch metrics for 88d0d46e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1/88d0d46e')\n","- f83845ad: FileNotFoundError('Could not fetch metrics for f83845ad: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1/f83845ad')\n","- 65c56de9: FileNotFoundError('Could not fetch metrics for 65c56de9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L1/65c56de9')\n","Fitted model: NeuralNetTorch_r41_BAG_L1/ad5d969d ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t111.99s\t = Training   runtime\n","\t0.8s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r98_BAG_L1 ... Tuning model for up to 139.59s of the 46534.35s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r98_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: XGBoost_r98_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t7.42s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r15_BAG_L1 ... Tuning model for up to 139.59s of the 46526.79s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: LightGBM_r15_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t3.92s\t = Training   runtime\n","\t0.07s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L1 ... Tuning model for up to 139.59s of the 46522.76s of remaining time.\n","2024-11-14 06:32:34,013\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r158_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:34:53,846\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:34:53,888\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1' in 0.0375s.\n","2024-11-14 06:34:53,907\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 8749afe6: FileNotFoundError('Could not fetch metrics for 8749afe6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1/8749afe6')\n","- bd8d31eb: FileNotFoundError('Could not fetch metrics for bd8d31eb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1/bd8d31eb')\n","- b3e06959: FileNotFoundError('Could not fetch metrics for b3e06959: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1/b3e06959')\n","- 6224ac96: FileNotFoundError('Could not fetch metrics for 6224ac96: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1/6224ac96')\n","- 0792c1c9: FileNotFoundError('Could not fetch metrics for 0792c1c9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L1/0792c1c9')\n","Fitted model: NeuralNetTorch_r158_BAG_L1/8749afe6 ...\n","\t0.9381\t = Validation score   (accuracy)\n","\t110.9s\t = Training   runtime\n","\t1.78s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r86_BAG_L1 ... Tuning model for up to 139.59s of the 46382.68s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r86_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: CatBoost_r86_BAG_L1 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t113.85s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L1 ... Tuning model for up to 139.59s of the 46268.73s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r37_BAG_L1 ...\n","\t0.9389\t = Validation score   (accuracy)\n","\t117.38s\t = Training   runtime\n","\t2.27s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L1 ... Tuning model for up to 139.59s of the 46151.24s of remaining time.\n","2024-11-14 06:38:45,548\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r197_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:41:05,366\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:41:05,408\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L1' in 0.0363s.\n","2024-11-14 06:41:06,913\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 32e95aed: FileNotFoundError('Could not fetch metrics for 32e95aed: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L1/32e95aed')\n","- 3f0b6f24: FileNotFoundError('Could not fetch metrics for 3f0b6f24: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L1/3f0b6f24')\n","- eb19a6eb: FileNotFoundError('Could not fetch metrics for eb19a6eb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L1/eb19a6eb')\n","Fitted model: NeuralNetTorch_r197_BAG_L1/32e95aed ...\n","\t0.9389\t = Validation score   (accuracy)\n","\t114.13s\t = Training   runtime\n","\t0.85s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r49_BAG_L1 ... Tuning model for up to 139.59s of the 46009.67s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: CatBoost_r49_BAG_L1 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t60.83s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r49_BAG_L1 ... Tuning model for up to 139.59s of the 45948.69s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r49_BAG_L1 ...\n","\t0.9364\t = Validation score   (accuracy)\n","\t15.74s\t = Training   runtime\n","\t4.77s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r143_BAG_L1 ... Tuning model for up to 139.59s of the 45932.8s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","Fitted model: LightGBM_r143_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t4.04s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r127_BAG_L1 ... Tuning model for up to 139.59s of the 45928.64s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r127_BAG_L1 ...\n","\t0.9365\t = Validation score   (accuracy)\n","\t44.55s\t = Training   runtime\n","\t4.09s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L1 ... Tuning model for up to 139.59s of the 45883.96s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r134_BAG_L1 ...\n","\t0.9391\t = Validation score   (accuracy)\n","\t116.72s\t = Training   runtime\n","\t2.3s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r34_BAG_L1 ... Tuning model for up to 139.59s of the 45767.11s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r34_BAG_L1 ...\n","\t0.9361\t = Validation score   (accuracy)\n","\t24.9s\t = Training   runtime\n","\t3.51s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r94_BAG_L1 ... Tuning model for up to 139.59s of the 45742.04s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r94_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: LightGBM_r94_BAG_L1 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t12.23s\t = Training   runtime\n","\t3.59s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L1 ... Tuning model for up to 139.59s of the 45729.7s of remaining time.\n","2024-11-14 06:45:47,067\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r143_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:48:06,885\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:48:06,946\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1' in 0.0560s.\n","2024-11-14 06:48:06,970\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 6 trial(s):\n","- 91521b8e: FileNotFoundError('Could not fetch metrics for 91521b8e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/91521b8e')\n","- 51ca4c44: FileNotFoundError('Could not fetch metrics for 51ca4c44: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/51ca4c44')\n","- 12de59d1: FileNotFoundError('Could not fetch metrics for 12de59d1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/12de59d1')\n","- f8f3b4cb: FileNotFoundError('Could not fetch metrics for f8f3b4cb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/f8f3b4cb')\n","- 09b687a3: FileNotFoundError('Could not fetch metrics for 09b687a3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/09b687a3')\n","- ee94ecec: FileNotFoundError('Could not fetch metrics for ee94ecec: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L1/ee94ecec')\n","Fitted model: NeuralNetTorch_r143_BAG_L1/91521b8e ...\n","\t0.9388\t = Validation score   (accuracy)\n","\t106.82s\t = Training   runtime\n","\t2.87s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r128_BAG_L1 ... Tuning model for up to 139.59s of the 45589.62s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r128_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: CatBoost_r128_BAG_L1 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t86.24s\t = Training   runtime\n","\t0.22s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L1 ... Tuning model for up to 139.59s of the 45503.27s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r111_BAG_L1 ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t70.01s\t = Training   runtime\n","\t1.14s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L1 ... Tuning model for up to 139.59s of the 45433.15s of remaining time.\n","2024-11-14 06:50:43,605\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r31_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 06:53:03,387\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 06:53:03,426\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1' in 0.0363s.\n","2024-11-14 06:53:04,833\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- c77753aa: FileNotFoundError('Could not fetch metrics for c77753aa: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1/c77753aa')\n","- 817a8b77: FileNotFoundError('Could not fetch metrics for 817a8b77: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1/817a8b77')\n","- da115e27: FileNotFoundError('Could not fetch metrics for da115e27: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1/da115e27')\n","- 1acbd761: FileNotFoundError('Could not fetch metrics for 1acbd761: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L1/1acbd761')\n","Fitted model: NeuralNetTorch_r31_BAG_L1/c77753aa ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t111.74s\t = Training   runtime\n","\t1.15s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r4_BAG_L1 ... Tuning model for up to 139.59s of the 45291.76s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: ExtraTrees_r4_BAG_L1 ...\n","\t0.9368\t = Validation score   (accuracy)\n","\t21.65s\t = Training   runtime\n","\t3.77s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L1 ... Tuning model for up to 139.59s of the 45269.97s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r65_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t97.23s\t = Training   runtime\n","\t1.01s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L1 ... Tuning model for up to 139.59s of the 45172.62s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r88_BAG_L1 ...\n","\t0.939\t = Validation score   (accuracy)\n","\t116.29s\t = Training   runtime\n","\t1.0s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r30_BAG_L1 ... Tuning model for up to 139.59s of the 45056.2s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r30_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: LightGBM_r30_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t4.19s\t = Training   runtime\n","\t0.06s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r49_BAG_L1 ... Tuning model for up to 139.59s of the 45051.9s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r49_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.20%)\n","Fitted model: XGBoost_r49_BAG_L1 ...\n","\t0.9391\t = Validation score   (accuracy)\n","\t114.92s\t = Training   runtime\n","\t2.3s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r5_BAG_L1 ... Tuning model for up to 139.59s of the 44936.87s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r5_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r5_BAG_L1 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t80.0s\t = Training   runtime\n","\t0.08s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L1 ... Tuning model for up to 139.59s of the 44856.74s of remaining time.\n","2024-11-14 07:00:20,000\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r87_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:02:39,734\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:02:39,776\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1' in 0.0372s.\n","2024-11-14 07:02:39,796\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- a9259f67: FileNotFoundError('Could not fetch metrics for a9259f67: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1/a9259f67')\n","- bcb21cbc: FileNotFoundError('Could not fetch metrics for bcb21cbc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1/bcb21cbc')\n","- 62d26275: FileNotFoundError('Could not fetch metrics for 62d26275: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1/62d26275')\n","- 6ecc4256: FileNotFoundError('Could not fetch metrics for 6ecc4256: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L1/6ecc4256')\n","Fitted model: NeuralNetTorch_r87_BAG_L1/a9259f67 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t112.76s\t = Training   runtime\n","\t0.82s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L1 ... Tuning model for up to 139.59s of the 44716.78s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:02:40,002\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r71_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:04:59,829\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:04:59,867\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L1' in 0.0356s.\n","2024-11-14 07:04:59,964\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 38b3d852: FileNotFoundError('Could not fetch metrics for 38b3d852: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L1/38b3d852')\n","- be70a84e: FileNotFoundError('Could not fetch metrics for be70a84e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L1/be70a84e')\n","- 5faded0f: FileNotFoundError('Could not fetch metrics for 5faded0f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L1/5faded0f')\n","Fitted model: NeuralNetTorch_r71_BAG_L1/38b3d852 ...\n","\t0.9386\t = Validation score   (accuracy)\n","\t93.95s\t = Training   runtime\n","\t0.73s\t = Validation runtime\n","Fitted model: NeuralNetTorch_r71_BAG_L1/be70a84e ...\n","\t0.9387\t = Validation score   (accuracy)\n","\t35.8s\t = Training   runtime\n","\t1.54s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r143_BAG_L1 ... Tuning model for up to 139.59s of the 44576.61s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: CatBoost_r143_BAG_L1 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t48.38s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r178_BAG_L1 ... Tuning model for up to 139.59s of the 44528.09s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r178_BAG_L1 ...\n","\t0.9373\t = Validation score   (accuracy)\n","\t19.15s\t = Training   runtime\n","\t4.07s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r166_BAG_L1 ... Tuning model for up to 139.59s of the 44508.81s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r166_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r166_BAG_L1 ...\n","\t0.9366\t = Validation score   (accuracy)\n","\t17.28s\t = Training   runtime\n","\t4.53s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r31_BAG_L1 ... Tuning model for up to 139.59s of the 44491.43s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r31_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","Fitted model: XGBoost_r31_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t23.22s\t = Training   runtime\n","\t0.28s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L1 ... Tuning model for up to 139.59s of the 44468.09s of remaining time.\n","2024-11-14 07:06:48,660\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r185_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:09:08,451\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:09:08,502\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1' in 0.0361s.\n","2024-11-14 07:09:10,622\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 62f1223f: FileNotFoundError('Could not fetch metrics for 62f1223f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1/62f1223f')\n","- b8af838b: FileNotFoundError('Could not fetch metrics for b8af838b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1/b8af838b')\n","- 63a9845e: FileNotFoundError('Could not fetch metrics for 63a9845e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1/63a9845e')\n","- 16533f53: FileNotFoundError('Could not fetch metrics for 16533f53: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L1/16533f53')\n","Fitted model: NeuralNetTorch_r185_BAG_L1/62f1223f ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t115.48s\t = Training   runtime\n","\t3.4s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L1 ... Tuning model for up to 139.59s of the 44325.94s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r160_BAG_L1 ...\n","\t0.9383\t = Validation score   (accuracy)\n","\t117.02s\t = Training   runtime\n","\t5.89s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r60_BAG_L1 ... Tuning model for up to 139.59s of the 44208.76s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r60_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r60_BAG_L1 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t113.88s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r15_BAG_L1 ... Tuning model for up to 139.59s of the 44094.78s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r15_BAG_L1 ...\n","\t0.9361\t = Validation score   (accuracy)\n","\t27.53s\t = Training   runtime\n","\t3.95s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r135_BAG_L1 ... Tuning model for up to 139.59s of the 44067.15s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r135_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","Fitted model: LightGBM_r135_BAG_L1 ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t14.58s\t = Training   runtime\n","\t3.71s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r22_BAG_L1 ... Tuning model for up to 139.59s of the 44052.44s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r22_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n","Fitted model: XGBoost_r22_BAG_L1 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t116.01s\t = Training   runtime\n","\t1.55s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L1 ... Tuning model for up to 139.59s of the 43936.28s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r69_BAG_L1 ...\n","\t0.9386\t = Validation score   (accuracy)\n","\t117.07s\t = Training   runtime\n","\t5.13s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r6_BAG_L1 ... Tuning model for up to 139.59s of the 43819.1s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r6_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r6_BAG_L1 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t59.0s\t = Training   runtime\n","\t0.22s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L1 ... Tuning model for up to 139.59s of the 43759.98s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.25%)\n","Fitted model: NeuralNetFastAI_r138_BAG_L1 ...\n","\t0.9381\t = Validation score   (accuracy)\n","\t117.23s\t = Training   runtime\n","\t6.93s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r121_BAG_L1 ... Tuning model for up to 139.59s of the 43642.65s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r121_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.18%)\n","Fitted model: LightGBM_r121_BAG_L1 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t4.25s\t = Training   runtime\n","\t0.05s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L1 ... Tuning model for up to 139.59s of the 43638.29s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r172_BAG_L1 ...\n","\t0.9388\t = Validation score   (accuracy)\n","\t116.64s\t = Training   runtime\n","\t1.58s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r180_BAG_L1 ... Tuning model for up to 139.59s of the 43521.51s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r180_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: CatBoost_r180_BAG_L1 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t65.6s\t = Training   runtime\n","\t0.24s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L1 ... Tuning model for up to 139.59s of the 43455.78s of remaining time.\n","2024-11-14 07:23:40,962\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r76_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:26:00,698\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:26:00,742\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L1' in 0.0374s.\n","2024-11-14 07:26:01,032\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 2ae87a8a: FileNotFoundError('Could not fetch metrics for 2ae87a8a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L1/2ae87a8a')\n","- bd2c9c97: FileNotFoundError('Could not fetch metrics for bd2c9c97: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L1/bd2c9c97')\n","- fa011ab2: FileNotFoundError('Could not fetch metrics for fa011ab2: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L1/fa011ab2')\n","Fitted model: NeuralNetTorch_r76_BAG_L1/2ae87a8a ...\n","\t0.94\t = Validation score   (accuracy)\n","\t110.71s\t = Training   runtime\n","\t0.75s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r197_BAG_L1 ... Tuning model for up to 139.59s of the 43315.55s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: ExtraTrees_r197_BAG_L1 ...\n","\t0.9353\t = Validation score   (accuracy)\n","\t24.68s\t = Training   runtime\n","\t4.2s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L1 ... Tuning model for up to 139.59s of the 43290.74s of remaining time.\n","2024-11-14 07:26:25,996\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r121_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:28:45,799\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:28:45,830\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1' in 0.0281s.\n","2024-11-14 07:28:46,457\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 93b5ea6c: FileNotFoundError('Could not fetch metrics for 93b5ea6c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1/93b5ea6c')\n","- 51fb84f8: FileNotFoundError('Could not fetch metrics for 51fb84f8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1/51fb84f8')\n","- 1e3d0e2a: FileNotFoundError('Could not fetch metrics for 1e3d0e2a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1/1e3d0e2a')\n","- 53c170d3: FileNotFoundError('Could not fetch metrics for 53c170d3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L1/53c170d3')\n","Fitted model: NeuralNetTorch_r121_BAG_L1/93b5ea6c ...\n","\t0.9386\t = Validation score   (accuracy)\n","\t110.47s\t = Training   runtime\n","\t2.76s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L1 ... Tuning model for up to 139.59s of the 43150.13s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: NeuralNetFastAI_r127_BAG_L1 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t64.53s\t = Training   runtime\n","\t1.05s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r16_BAG_L1 ... Tuning model for up to 139.59s of the 43085.49s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r16_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r16_BAG_L1 ...\n","\t0.9344\t = Validation score   (accuracy)\n","\t35.0s\t = Training   runtime\n","\t4.02s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L1 ... Tuning model for up to 139.59s of the 43050.38s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r194_BAG_L1 ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t116.72s\t = Training   runtime\n","\t3.12s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r12_BAG_L1 ... Tuning model for up to 139.59s of the 42933.56s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r12_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.16%)\n","Fitted model: CatBoost_r12_BAG_L1 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t113.84s\t = Training   runtime\n","\t0.14s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L1 ... Tuning model for up to 139.59s of the 42819.61s of remaining time.\n","2024-11-14 07:34:17,155\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r135_BAG_L1   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:36:36,912\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:36:36,950\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1' in 0.0351s.\n","2024-11-14 07:36:37,359\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 58b31ab4: FileNotFoundError('Could not fetch metrics for 58b31ab4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1/58b31ab4')\n","- 8a790497: FileNotFoundError('Could not fetch metrics for 8a790497: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1/8a790497')\n","- d186da70: FileNotFoundError('Could not fetch metrics for d186da70: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1/d186da70')\n","- 1252c16e: FileNotFoundError('Could not fetch metrics for 1252c16e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1/1252c16e')\n","- 639ffc97: FileNotFoundError('Could not fetch metrics for 639ffc97: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L1/639ffc97')\n","Fitted model: NeuralNetTorch_r135_BAG_L1/58b31ab4 ...\n","\t0.9393\t = Validation score   (accuracy)\n","\t114.99s\t = Training   runtime\n","\t2.93s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L1 ... Tuning model for up to 139.59s of the 42679.23s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: NeuralNetFastAI_r4_BAG_L1 ...\n","\t0.9387\t = Validation score   (accuracy)\n","\t117.22s\t = Training   runtime\n","\t2.46s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r126_BAG_L1 ... Tuning model for up to 139.59s of the 42561.89s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r126_BAG_L1 ...\n","\t0.9368\t = Validation score   (accuracy)\n","\t13.22s\t = Training   runtime\n","\t4.49s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L1 ... Tuning model for up to 139.59s of the 42548.56s of remaining time.\n","2024-11-14 07:38:48,179\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r36_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:41:08,004\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:41:08,057\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1' in 0.0423s.\n","2024-11-14 07:41:08,078\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- f18f157f: FileNotFoundError('Could not fetch metrics for f18f157f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1/f18f157f')\n","- edeb2bce: FileNotFoundError('Could not fetch metrics for edeb2bce: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1/edeb2bce')\n","- 8d2e46b6: FileNotFoundError('Could not fetch metrics for 8d2e46b6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1/8d2e46b6')\n","- 93706b34: FileNotFoundError('Could not fetch metrics for 93706b34: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L1/93706b34')\n","Fitted model: NeuralNetTorch_r36_BAG_L1/f18f157f ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t112.78s\t = Training   runtime\n","\t0.98s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L1 ... Tuning model for up to 139.59s of the 42408.5s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: NeuralNetFastAI_r100_BAG_L1 ...\n","\t0.938\t = Validation score   (accuracy)\n","\t114.54s\t = Training   runtime\n","\t2.46s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r163_BAG_L1 ... Tuning model for up to 139.59s of the 42293.83s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r163_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.14%)\n","Fitted model: CatBoost_r163_BAG_L1 ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t31.42s\t = Training   runtime\n","\t0.06s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r198_BAG_L1 ... Tuning model for up to 139.59s of the 42262.32s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r198_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.15%)\n","Fitted model: CatBoost_r198_BAG_L1 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t95.75s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L1 ... Tuning model for up to 139.59s of the 42166.46s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.23%)\n","Fitted model: NeuralNetFastAI_r187_BAG_L1 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t116.75s\t = Training   runtime\n","\t1.14s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L1 ... Tuning model for up to 139.59s of the 42049.58s of remaining time.\n","2024-11-14 07:47:07,158\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r19_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:49:26,993\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:49:27,025\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L1' in 0.0279s.\n","2024-11-14 07:49:27,039\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- c906acd6: FileNotFoundError('Could not fetch metrics for c906acd6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L1/c906acd6')\n","- c4c5b02d: FileNotFoundError('Could not fetch metrics for c4c5b02d: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L1/c4c5b02d')\n","- c3ad412b: FileNotFoundError('Could not fetch metrics for c3ad412b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L1/c3ad412b')\n","Fitted model: NeuralNetTorch_r19_BAG_L1/c906acd6 ...\n","\t0.9395\t = Validation score   (accuracy)\n","\t102.54s\t = Training   runtime\n","\t0.91s\t = Validation runtime\n","Fitted model: NeuralNetTorch_r19_BAG_L1/c4c5b02d ...\n","\t0.9384\t = Validation score   (accuracy)\n","\t30.13s\t = Training   runtime\n","\t0.84s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r95_BAG_L1 ... Tuning model for up to 139.59s of the 41909.54s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.19%)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitted model: XGBoost_r95_BAG_L1 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t114.71s\t = Training   runtime\n","\t1.48s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r34_BAG_L1 ... Tuning model for up to 139.59s of the 41794.74s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r34_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.28%)\n","Fitted model: XGBoost_r34_BAG_L1 ...\n","\t0.9388\t = Validation score   (accuracy)\n","\t115.43s\t = Training   runtime\n","\t4.45s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r42_BAG_L1 ... Tuning model for up to 139.59s of the 41679.17s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=0.17%)\n","Fitted model: LightGBM_r42_BAG_L1 ...\n","\t0.9394\t = Validation score   (accuracy)\n","\t10.93s\t = Training   runtime\n","\t4.3s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L1 ... Tuning model for up to 139.59s of the 41668.1s of remaining time.\n","2024-11-14 07:53:28,647\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+-------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r1_BAG_L1   |\n","+-------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator            |\n","| Scheduler                        FIFOScheduler              |\n","| Number of trials                 1000                       |\n","+-------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:55:48,378\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:55:48,415\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1' in 0.0327s.\n","2024-11-14 07:55:48,432\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 4b3a80fb: FileNotFoundError('Could not fetch metrics for 4b3a80fb: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1/4b3a80fb')\n","- bd06379b: FileNotFoundError('Could not fetch metrics for bd06379b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1/bd06379b')\n","- c1f09ef7: FileNotFoundError('Could not fetch metrics for c1f09ef7: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1/c1f09ef7')\n","- d351148a: FileNotFoundError('Could not fetch metrics for d351148a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1/d351148a')\n","- 67c4afb3: FileNotFoundError('Could not fetch metrics for 67c4afb3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L1/67c4afb3')\n","Fitted model: NeuralNetTorch_r1_BAG_L1/4b3a80fb ...\n","\t0.9397\t = Validation score   (accuracy)\n","\t109.95s\t = Training   runtime\n","\t1.76s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L1 ... Tuning model for up to 139.59s of the 41528.16s of remaining time.\n","2024-11-14 07:55:48,573\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r89_BAG_L1   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 07:58:08,340\tINFO timeout.py:54 -- Reached timeout of 139.58697639466425 seconds. Stopping all trials.\n","2024-11-14 07:58:08,396\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1' in 0.0527s.\n","2024-11-14 07:58:08,416\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 293bc186: FileNotFoundError('Could not fetch metrics for 293bc186: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1/293bc186')\n","- fbda318f: FileNotFoundError('Could not fetch metrics for fbda318f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1/fbda318f')\n","- ec2e31d9: FileNotFoundError('Could not fetch metrics for ec2e31d9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1/ec2e31d9')\n","- 0af40ec0: FileNotFoundError('Could not fetch metrics for 0af40ec0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1/0af40ec0')\n","- 136ad5bd: FileNotFoundError('Could not fetch metrics for 136ad5bd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L1/136ad5bd')\n","Fitted model: NeuralNetTorch_r89_BAG_L1/293bc186 ...\n","\t0.9392\t = Validation score   (accuracy)\n","\t110.81s\t = Training   runtime\n","\t1.7s\t = Validation runtime\n","Completed 1/10 k-fold bagging repeats ...\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Fitting model: WeightedEnsemble_L2 ... Training model for up to 1675.04s of the 41386.53s of remaining time.\n","\tEnsemble Weights: {'NeuralNetTorch_r76_BAG_L1/2ae87a8a': 0.24, 'LightGBMXT_BAG_L1/T3': 0.12, 'LightGBM_BAG_L1/T8': 0.08, 'LightGBMLarge_BAG_L1': 0.08, 'CatBoost_r69_BAG_L1': 0.08, 'CatBoost_r5_BAG_L1': 0.08, 'CatBoost_r12_BAG_L1': 0.08, 'NeuralNetTorch_r1_BAG_L1/4b3a80fb': 0.08, 'LightGBM_r94_BAG_L1': 0.04, 'CatBoost_r60_BAG_L1': 0.04, 'XGBoost_r22_BAG_L1': 0.04, 'NeuralNetFastAI_r194_BAG_L1': 0.04}\n","\t0.9405\t = Validation score   (accuracy)\n","\t5.3s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L2 models ...\n","Hyperparameter tuning model: LightGBMXT_BAG_L2 ... Tuning model for up to 153.23s of the 41380.0s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.27%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.22%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.26%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.22%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: LightGBMXT_BAG_L2/T1 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t33.74s\t = Training   runtime\n","\t0.59s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L2/T2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t29.9s\t = Training   runtime\n","\t0.52s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L2/T3 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t34.73s\t = Training   runtime\n","\t0.77s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L2/T4 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t23.23s\t = Training   runtime\n","\t0.31s\t = Validation runtime\n","Fitted model: LightGBMXT_BAG_L2/T5 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t25.23s\t = Training   runtime\n","\t0.45s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 153.23s of the 41230.93s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.27%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.22%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: LightGBM_BAG_L2/T1 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t40.45s\t = Training   runtime\n","\t0.59s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L2/T2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t35.29s\t = Training   runtime\n","\t0.57s\t = Validation runtime\n","Fitted model: LightGBM_BAG_L2/T3 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t41.29s\t = Training   runtime\n","\t0.66s\t = Validation runtime\n","Hyperparameter tuning model: RandomForestGini_BAG_L2 ... Tuning model for up to 153.23s of the 41112.21s of remaining time.\n","\tNo hyperparameter search space specified for RandomForestGini_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForestGini_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t137.89s\t = Training   runtime\n","\t8.88s\t = Validation runtime\n","Hyperparameter tuning model: RandomForestEntr_BAG_L2 ... Tuning model for up to 153.23s of the 40973.31s of remaining time.\n","\tNo hyperparameter search space specified for RandomForestEntr_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForestEntr_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t114.99s\t = Training   runtime\n","\t8.49s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_BAG_L2 ... Tuning model for up to 153.23s of the 40857.22s of remaining time.\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.24%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: CatBoost_BAG_L2/T1 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t62.58s\t = Training   runtime\n","\t0.32s\t = Validation runtime\n","Fitted model: CatBoost_BAG_L2/T2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t41.95s\t = Training   runtime\n","\t0.23s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTreesGini_BAG_L2 ... Tuning model for up to 153.23s of the 40751.09s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTreesGini_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTreesGini_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t29.76s\t = Training   runtime\n","\t9.46s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTreesEntr_BAG_L2 ... Tuning model for up to 153.23s of the 40720.34s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTreesEntr_BAG_L2 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t28.81s\t = Training   runtime\n","\t9.02s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_BAG_L2 ... Tuning model for up to 153.23s of the 40690.57s of remaining time.\n","2024-11-14 08:09:47,275\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------+\n","| Configuration for experiment     NeuralNetFastAI_BAG_L2   |\n","+-----------------------------------------------------------+\n","| Search algorithm                 SearchGenerator          |\n","| Scheduler                        FIFOScheduler            |\n","| Number of trials                 1000                     |\n","+-----------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 08:12:20,648\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 08:12:20,660\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 08:12:20,691\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2' in 0.0378s.\n","2024-11-14 08:12:24,097\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 0d6ee21f: FileNotFoundError('Could not fetch metrics for 0d6ee21f: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2/0d6ee21f')\n","- 8c9de33b: FileNotFoundError('Could not fetch metrics for 8c9de33b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2/8c9de33b')\n","- ea11e077: FileNotFoundError('Could not fetch metrics for ea11e077: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2/ea11e077')\n","- a20335c8: FileNotFoundError('Could not fetch metrics for a20335c8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetFastAI_BAG_L2/a20335c8')\n","Fitted model: NeuralNetFastAI_BAG_L2/0d6ee21f ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t124.59s\t = Training   runtime\n","\t4.46s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_BAG_L2 ... Tuning model for up to 153.23s of the 40532.42s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.59%)\n","\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.59%)\n","\tStopping HPO to satisfy time limit...\n","Fitted model: XGBoost_BAG_L2/T1 ...\n","\t0.9411\t = Validation score   (accuracy)\n","\t54.51s\t = Training   runtime\n","\t1.54s\t = Validation runtime\n","Fitted model: XGBoost_BAG_L2/T2 ...\n","\t0.9411\t = Validation score   (accuracy)\n","\t59.74s\t = Training   runtime\n","\t1.66s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ... Tuning model for up to 153.23s of the 40416.36s of remaining time.\n","2024-11-14 08:14:21,432\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_BAG_L2   |\n","+----------------------------------------------------------+\n","| Search algorithm                 SearchGenerator         |\n","| Scheduler                        FIFOScheduler           |\n","| Number of trials                 1000                    |\n","+----------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 08:16:54,889\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 08:16:54,902\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 08:16:54,926\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2' in 0.0335s.\n","2024-11-14 08:16:56,283\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 73d6b2cc: FileNotFoundError('Could not fetch metrics for 73d6b2cc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2/73d6b2cc')\n","- 65789797: FileNotFoundError('Could not fetch metrics for 65789797: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2/65789797')\n","- 138190a5: FileNotFoundError('Could not fetch metrics for 138190a5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2/138190a5')\n","- 11fc254c: FileNotFoundError('Could not fetch metrics for 11fc254c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_BAG_L2/11fc254c')\n","Fitted model: NeuralNetTorch_BAG_L2/73d6b2cc ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t124.72s\t = Training   runtime\n","\t8.29s\t = Validation runtime\n","Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 153.23s of the 40260.25s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tFitting 10 child models (S1F1 - S1F10) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.36%)\n","\t0.9407\t = Validation score   (accuracy)\n","\t48.48s\t = Training   runtime\n","\t0.75s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r177_BAG_L2 ... Tuning model for up to 153.23s of the 40208.33s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r177_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.24%)\n","Fitted model: CatBoost_r177_BAG_L2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t45.99s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L2 ... Tuning model for up to 153.23s of the 40161.23s of remaining time.\n","2024-11-14 08:18:36,552\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r79_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 08:21:09,958\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 08:21:09,981\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 08:21:10,006\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L2' in 0.0406s.\n","2024-11-14 08:21:16,045\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- c4a022e6: FileNotFoundError('Could not fetch metrics for c4a022e6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L2/c4a022e6')\n","- 34130d8b: FileNotFoundError('Could not fetch metrics for 34130d8b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L2/34130d8b')\n","- 5ec92588: FileNotFoundError('Could not fetch metrics for 5ec92588: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r79_BAG_L2/5ec92588')\n","Fitted model: NeuralNetTorch_r79_BAG_L2/c4a022e6 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t124.83s\t = Training   runtime\n","\t8.96s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r131_BAG_L2 ... Tuning model for up to 153.23s of the 40000.42s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for LightGBM_r131_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=2.69%)\n","Fitted model: LightGBM_r131_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t15.33s\t = Training   runtime\n","\t0.22s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L2 ... Tuning model for up to 153.23s of the 39983.41s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r191_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t128.77s\t = Training   runtime\n","\t5.03s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r9_BAG_L2 ... Tuning model for up to 153.23s of the 39853.57s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r9_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","Fitted model: CatBoost_r9_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t46.81s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r96_BAG_L2 ... Tuning model for up to 153.23s of the 39805.69s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r96_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.15%)\n","Fitted model: LightGBM_r96_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t10.33s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L2 ... Tuning model for up to 153.23s of the 39794.37s of remaining time.\n","2024-11-14 08:24:43,513\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r22_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 08:27:17,882\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 08:27:17,892\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 08:27:17,919\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L2' in 0.0347s.\n","2024-11-14 08:27:18,659\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 28806ea7: FileNotFoundError('Could not fetch metrics for 28806ea7: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L2/28806ea7')\n","- 2ba42eb8: FileNotFoundError('Could not fetch metrics for 2ba42eb8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L2/2ba42eb8')\n","- d39cba8b: FileNotFoundError('Could not fetch metrics for d39cba8b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r22_BAG_L2/d39cba8b')\n","Fitted model: NeuralNetTorch_r22_BAG_L2/28806ea7 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t127.57s\t = Training   runtime\n","\t9.14s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r33_BAG_L2 ... Tuning model for up to 153.23s of the 39637.89s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for XGBoost_r33_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=2.41%)\n","Fitted model: XGBoost_r33_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t126.64s\t = Training   runtime\n","\t2.78s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r42_BAG_L2 ... Tuning model for up to 153.23s of the 39510.18s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 75.68s compared to 36.59s of available time.\n","Warning: Exception caused ExtraTrees_r42_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: CatBoost_r137_BAG_L2 ... Tuning model for up to 153.23s of the 39346.19s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r137_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=2.84%)\n","Fitted model: CatBoost_r137_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t26.75s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L2 ... Tuning model for up to 153.23s of the 39317.87s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r102_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t81.35s\t = Training   runtime\n","\t1.2s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r13_BAG_L2 ... Tuning model for up to 153.23s of the 39235.54s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r13_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","Fitted model: CatBoost_r13_BAG_L2 ...\n","\t0.9407\t = Validation score   (accuracy)\n","\t124.89s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r195_BAG_L2 ... Tuning model for up to 153.23s of the 39109.57s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r195_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 36.29s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r195_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: LightGBM_r188_BAG_L2 ... Tuning model for up to 153.23s of the 37511.86s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r188_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.36%)\n","Fitted model: LightGBM_r188_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t19.74s\t = Training   runtime\n","\t0.75s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L2 ... Tuning model for up to 153.23s of the 37491.14s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r145_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t122.06s\t = Training   runtime\n","\t6.9s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r89_BAG_L2 ... Tuning model for up to 153.23s of the 37368.07s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r89_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","Fitted model: XGBoost_r89_BAG_L2 ...\n","\t0.9407\t = Validation score   (accuracy)\n","\t97.07s\t = Training   runtime\n","\t1.17s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L2 ... Tuning model for up to 153.23s of the 37269.89s of remaining time.\n","2024-11-14 09:06:47,802\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r30_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 09:09:21,243\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 09:09:21,257\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 09:09:21,286\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2' in 0.0370s.\n","2024-11-14 09:09:21,312\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- ef058f73: FileNotFoundError('Could not fetch metrics for ef058f73: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2/ef058f73')\n","- db648aed: FileNotFoundError('Could not fetch metrics for db648aed: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2/db648aed')\n","- 73ef1188: FileNotFoundError('Could not fetch metrics for 73ef1188: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2/73ef1188')\n","- 5b42549c: FileNotFoundError('Could not fetch metrics for 5b42549c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r30_BAG_L2/5b42549c')\n","Fitted model: NeuralNetTorch_r30_BAG_L2/ef058f73 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t124.06s\t = Training   runtime\n","\t10.62s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r130_BAG_L2 ... Tuning model for up to 153.23s of the 37115.22s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for LightGBM_r130_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.29%)\n","Fitted model: LightGBM_r130_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t23.27s\t = Training   runtime\n","\t0.59s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L2 ... Tuning model for up to 153.23s of the 37090.67s of remaining time.\n","2024-11-14 09:09:47,196\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r86_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 09:12:20,655\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 09:12:20,667\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 09:12:20,700\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2' in 0.0396s.\n","2024-11-14 09:12:20,722\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 7d750af6: FileNotFoundError('Could not fetch metrics for 7d750af6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2/7d750af6')\n","- 8eb138b1: FileNotFoundError('Could not fetch metrics for 8eb138b1: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2/8eb138b1')\n","- 54a946f3: FileNotFoundError('Could not fetch metrics for 54a946f3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2/54a946f3')\n","- 7bc6d7b0: FileNotFoundError('Could not fetch metrics for 7bc6d7b0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r86_BAG_L2/7bc6d7b0')\n","Fitted model: NeuralNetTorch_r86_BAG_L2/7d750af6 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t125.54s\t = Training   runtime\n","\t7.3s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r50_BAG_L2 ... Tuning model for up to 153.23s of the 36935.81s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for CatBoost_r50_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.15%)\n","Fitted model: CatBoost_r50_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t29.62s\t = Training   runtime\n","\t0.15s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L2 ... Tuning model for up to 153.23s of the 36905.15s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r11_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t126.81s\t = Training   runtime\n","\t8.75s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r194_BAG_L2 ... Tuning model for up to 153.23s of the 36777.25s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r194_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.70%)\n","Fitted model: XGBoost_r194_BAG_L2 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t37.65s\t = Training   runtime\n","\t0.65s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r172_BAG_L2 ... Tuning model for up to 153.23s of the 36738.55s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 43.82s compared to 15.32s of available time.\n","Warning: Exception caused ExtraTrees_r172_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: CatBoost_r69_BAG_L2 ... Tuning model for up to 153.23s of the 36549.18s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r69_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.18%)\n","Fitted model: CatBoost_r69_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t16.2s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L2 ... Tuning model for up to 153.23s of the 36531.88s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r103_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t127.78s\t = Training   runtime\n","\t3.91s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L2 ... Tuning model for up to 153.23s of the 36402.95s of remaining time.\n","2024-11-14 09:21:14,920\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r14_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 09:23:48,314\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 09:23:48,343\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 09:23:48,370\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L2' in 0.0372s.\n","2024-11-14 09:23:49,742\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 4a9ad7b6: FileNotFoundError('Could not fetch metrics for 4a9ad7b6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L2/4a9ad7b6')\n","- 6aabd662: FileNotFoundError('Could not fetch metrics for 6aabd662: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L2/6aabd662')\n","- 6ca51450: FileNotFoundError('Could not fetch metrics for 6ca51450: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r14_BAG_L2/6ca51450')\n","Fitted model: NeuralNetTorch_r14_BAG_L2/4a9ad7b6 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t126.54s\t = Training   runtime\n","\t7.1s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r161_BAG_L2 ... Tuning model for up to 153.23s of the 36246.76s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for LightGBM_r161_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","Fitted model: LightGBM_r161_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t12.48s\t = Training   runtime\n","\t0.22s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L2 ... Tuning model for up to 153.23s of the 36233.25s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r143_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t126.75s\t = Training   runtime\n","\t1.6s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r70_BAG_L2 ... Tuning model for up to 153.23s of the 36105.46s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r70_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.24%)\n","Fitted model: CatBoost_r70_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t33.53s\t = Training   runtime\n","\t0.19s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L2 ... Tuning model for up to 153.23s of the 36070.73s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.90%)\n","Fitted model: NeuralNetFastAI_r156_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t95.65s\t = Training   runtime\n","\t1.23s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r196_BAG_L2 ... Tuning model for up to 153.23s of the 35973.96s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r196_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.37%)\n","Fitted model: LightGBM_r196_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t10.07s\t = Training   runtime\n","\t0.24s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r39_BAG_L2 ... Tuning model for up to 153.23s of the 35962.86s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r39_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 36.54s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r39_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: CatBoost_r167_BAG_L2 ... Tuning model for up to 153.23s of the 34447.46s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r167_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.36%)\n","Fitted model: CatBoost_r167_BAG_L2 ...\n","\t0.9407\t = Validation score   (accuracy)\n","\t76.5s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L2 ... Tuning model for up to 153.23s of the 34369.97s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r95_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t126.14s\t = Training   runtime\n","\t6.18s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L2 ... Tuning model for up to 153.23s of the 34242.79s of remaining time.\n","2024-11-14 09:57:15,207\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r41_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 09:59:48,620\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 09:59:48,633\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 09:59:48,657\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L2' in 0.0329s.\n","2024-11-14 09:59:48,672\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 63314d36: FileNotFoundError('Could not fetch metrics for 63314d36: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L2/63314d36')\n","- abb197e6: FileNotFoundError('Could not fetch metrics for abb197e6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L2/abb197e6')\n","- ac9da2f8: FileNotFoundError('Could not fetch metrics for ac9da2f8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r41_BAG_L2/ac9da2f8')\n","Fitted model: NeuralNetTorch_r41_BAG_L2/63314d36 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t126.22s\t = Training   runtime\n","\t7.06s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r98_BAG_L2 ... Tuning model for up to 153.23s of the 34087.87s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for XGBoost_r98_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.95%)\n","Fitted model: XGBoost_r98_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t17.82s\t = Training   runtime\n","\t0.31s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r15_BAG_L2 ... Tuning model for up to 153.23s of the 34068.86s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r15_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.17%)\n","Fitted model: LightGBM_r15_BAG_L2 ...\n","\t0.843\t = Validation score   (accuracy)\n","\t20.14s\t = Training   runtime\n","\t0.32s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L2 ... Tuning model for up to 153.23s of the 34047.62s of remaining time.\n","2024-11-14 10:00:30,156\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r158_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 10:03:03,557\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 10:03:03,568\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 10:03:03,598\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L2' in 0.0381s.\n","2024-11-14 10:03:04,636\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- b1aa9e49: FileNotFoundError('Could not fetch metrics for b1aa9e49: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L2/b1aa9e49')\n","- c75ac9f8: FileNotFoundError('Could not fetch metrics for c75ac9f8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L2/c75ac9f8')\n","- 8d583e52: FileNotFoundError('Could not fetch metrics for 8d583e52: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r158_BAG_L2/8d583e52')\n","Fitted model: NeuralNetTorch_r158_BAG_L2/b1aa9e49 ...\n","\t0.9373\t = Validation score   (accuracy)\n","\t124.67s\t = Training   runtime\n","\t9.2s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r86_BAG_L2 ... Tuning model for up to 153.23s of the 33891.9s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for CatBoost_r86_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.59%)\n","Fitted model: CatBoost_r86_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t32.97s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L2 ... Tuning model for up to 153.23s of the 33857.8s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r37_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t125.99s\t = Training   runtime\n","\t2.71s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L2 ... Tuning model for up to 153.23s of the 33730.78s of remaining time.\n","2024-11-14 10:05:47,050\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r197_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 10:08:20,506\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 10:08:20,514\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 10:08:20,534\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L2' in 0.0260s.\n","2024-11-14 10:08:20,677\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 22735104: FileNotFoundError('Could not fetch metrics for 22735104: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L2/22735104')\n","- 50c21dcf: FileNotFoundError('Could not fetch metrics for 50c21dcf: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L2/50c21dcf')\n","- d2f48b34: FileNotFoundError('Could not fetch metrics for d2f48b34: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r197_BAG_L2/d2f48b34')\n","Fitted model: NeuralNetTorch_r197_BAG_L2/22735104 ...\n","\t0.9398\t = Validation score   (accuracy)\n","\t125.38s\t = Training   runtime\n","\t7.51s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r49_BAG_L2 ... Tuning model for up to 153.23s of the 33575.86s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for CatBoost_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.15%)\n","Fitted model: CatBoost_r49_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t17.92s\t = Training   runtime\n","\t0.1s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r49_BAG_L2 ... Tuning model for up to 153.23s of the 33556.75s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r49_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t29.15s\t = Training   runtime\n","\t9.34s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r143_BAG_L2 ... Tuning model for up to 153.23s of the 33526.63s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.46%)\n","Fitted model: LightGBM_r143_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t13.88s\t = Training   runtime\n","\t0.2s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r127_BAG_L2 ... Tuning model for up to 153.23s of the 33511.76s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r127_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 35.69s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r127_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: NeuralNetFastAI_r134_BAG_L2 ... Tuning model for up to 153.23s of the 31636.48s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r134_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r134_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t127.41s\t = Training   runtime\n","\t3.12s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r34_BAG_L2 ... Tuning model for up to 153.23s of the 31508.04s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r34_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 39.65s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r34_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: LightGBM_r94_BAG_L2 ... Tuning model for up to 153.23s of the 30506.92s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r94_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.16%)\n","Fitted model: LightGBM_r94_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t13.82s\t = Training   runtime\n","\t0.47s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r143_BAG_L2 ... Tuning model for up to 153.23s of the 30492.09s of remaining time.\n","2024-11-14 10:59:45,842\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r143_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:02:19,211\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 11:02:19,221\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 11:02:19,250\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2' in 0.0347s.\n","2024-11-14 11:02:19,267\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 5 trial(s):\n","- 6038bd8a: FileNotFoundError('Could not fetch metrics for 6038bd8a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2/6038bd8a')\n","- 7f2c7bb6: FileNotFoundError('Could not fetch metrics for 7f2c7bb6: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2/7f2c7bb6')\n","- 85bc1cee: FileNotFoundError('Could not fetch metrics for 85bc1cee: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2/85bc1cee')\n","- d95816e9: FileNotFoundError('Could not fetch metrics for d95816e9: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2/d95816e9')\n","- f860a458: FileNotFoundError('Could not fetch metrics for f860a458: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r143_BAG_L2/f860a458')\n","Fitted model: NeuralNetTorch_r143_BAG_L2/6038bd8a ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t121.44s\t = Training   runtime\n","\t9.38s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r128_BAG_L2 ... Tuning model for up to 153.23s of the 30337.26s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for CatBoost_r128_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.60%)\n","Fitted model: CatBoost_r128_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t46.0s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r111_BAG_L2 ... Tuning model for up to 153.23s of the 30290.18s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r111_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r111_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t92.89s\t = Training   runtime\n","\t1.69s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r31_BAG_L2 ... Tuning model for up to 153.23s of the 30196.16s of remaining time.\n","2024-11-14 11:04:41,621\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r31_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:07:15,085\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 11:07:15,096\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 11:07:15,145\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2' in 0.0563s.\n","2024-11-14 11:07:15,161\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 3cab5bcd: FileNotFoundError('Could not fetch metrics for 3cab5bcd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2/3cab5bcd')\n","- 6fa12bfc: FileNotFoundError('Could not fetch metrics for 6fa12bfc: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2/6fa12bfc')\n","- e21fd417: FileNotFoundError('Could not fetch metrics for e21fd417: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2/e21fd417')\n","- 832270f4: FileNotFoundError('Could not fetch metrics for 832270f4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r31_BAG_L2/832270f4')\n","Fitted model: NeuralNetTorch_r31_BAG_L2/3cab5bcd ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t126.21s\t = Training   runtime\n","\t8.99s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r4_BAG_L2 ... Tuning model for up to 153.23s of the 30041.38s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for ExtraTrees_r4_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r4_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t155.43s\t = Training   runtime\n","\t8.35s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r65_BAG_L2 ... Tuning model for up to 153.23s of the 29884.94s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r65_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r65_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t126.21s\t = Training   runtime\n","\t1.52s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r88_BAG_L2 ... Tuning model for up to 153.23s of the 29757.69s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r88_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r88_BAG_L2 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t118.67s\t = Training   runtime\n","\t1.59s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r30_BAG_L2 ... Tuning model for up to 153.23s of the 29637.94s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r30_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.34%)\n","Fitted model: LightGBM_r30_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t11.4s\t = Training   runtime\n","\t0.23s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r49_BAG_L2 ... Tuning model for up to 153.23s of the 29625.52s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r49_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.72%)\n","Fitted model: XGBoost_r49_BAG_L2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t119.58s\t = Training   runtime\n","\t1.75s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r5_BAG_L2 ... Tuning model for up to 153.23s of the 29504.9s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r5_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.16%)\n","Fitted model: CatBoost_r5_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t23.09s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r87_BAG_L2 ... Tuning model for up to 153.23s of the 29480.79s of remaining time.\n","2024-11-14 11:16:37,075\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r87_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:19:10,456\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 11:19:10,466\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 11:19:10,512\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2' in 0.0513s.\n","2024-11-14 11:19:10,686\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- d827a9ee: FileNotFoundError('Could not fetch metrics for d827a9ee: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2/d827a9ee')\n","- 5674a396: FileNotFoundError('Could not fetch metrics for 5674a396: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2/5674a396')\n","- 128320da: FileNotFoundError('Could not fetch metrics for 128320da: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2/128320da')\n","- 3a34d74a: FileNotFoundError('Could not fetch metrics for 3a34d74a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r87_BAG_L2/3a34d74a')\n","Fitted model: NeuralNetTorch_r87_BAG_L2/d827a9ee ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t124.93s\t = Training   runtime\n","\t9.45s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r71_BAG_L2 ... Tuning model for up to 153.23s of the 29325.86s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:19:11,935\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r71_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:21:45,336\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 11:21:45,349\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 11:21:45,375\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2' in 0.0338s.\n","2024-11-14 11:21:45,392\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 2406ced0: FileNotFoundError('Could not fetch metrics for 2406ced0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2/2406ced0')\n","- 3922e38b: FileNotFoundError('Could not fetch metrics for 3922e38b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2/3922e38b')\n","- 58f15492: FileNotFoundError('Could not fetch metrics for 58f15492: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2/58f15492')\n","- 5447d486: FileNotFoundError('Could not fetch metrics for 5447d486: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r71_BAG_L2/5447d486')\n","Fitted model: NeuralNetTorch_r71_BAG_L2/2406ced0 ...\n","\t0.94\t = Validation score   (accuracy)\n","\t125.27s\t = Training   runtime\n","\t8.08s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r143_BAG_L2 ... Tuning model for up to 153.23s of the 29171.14s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for CatBoost_r143_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.37%)\n","Fitted model: CatBoost_r143_BAG_L2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t78.15s\t = Training   runtime\n","\t0.14s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r178_BAG_L2 ... Tuning model for up to 153.23s of the 29091.97s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r178_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r178_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t143.75s\t = Training   runtime\n","\t9.04s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r166_BAG_L2 ... Tuning model for up to 153.23s of the 28947.04s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r166_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: RandomForest_r166_BAG_L2 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t80.1s\t = Training   runtime\n","\t9.04s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r31_BAG_L2 ... Tuning model for up to 153.23s of the 28865.86s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r31_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.60%)\n","Fitted model: XGBoost_r31_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t35.22s\t = Training   runtime\n","\t1.74s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r185_BAG_L2 ... Tuning model for up to 153.23s of the 28829.5s of remaining time.\n","2024-11-14 11:27:29,277\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r185_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 11:30:02,705\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 11:30:02,716\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 11:30:02,737\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L2' in 0.0283s.\n","2024-11-14 11:30:03,354\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 24eaa11c: FileNotFoundError('Could not fetch metrics for 24eaa11c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L2/24eaa11c')\n","- 42af69c8: FileNotFoundError('Could not fetch metrics for 42af69c8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L2/42af69c8')\n","- 9be7c7fd: FileNotFoundError('Could not fetch metrics for 9be7c7fd: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r185_BAG_L2/9be7c7fd')\n","Fitted model: NeuralNetTorch_r185_BAG_L2/24eaa11c ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t127.5s\t = Training   runtime\n","\t9.99s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r160_BAG_L2 ... Tuning model for up to 153.23s of the 28673.18s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for NeuralNetFastAI_r160_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r160_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t127.83s\t = Training   runtime\n","\t6.89s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r60_BAG_L2 ... Tuning model for up to 153.23s of the 28544.32s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r60_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.19%)\n","Fitted model: CatBoost_r60_BAG_L2 ...\n","\t0.9407\t = Validation score   (accuracy)\n","\t108.72s\t = Training   runtime\n","\t0.14s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r15_BAG_L2 ... Tuning model for up to 153.23s of the 28434.45s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r15_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 39.36s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r15_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: LightGBM_r135_BAG_L2 ... Tuning model for up to 153.23s of the 26935.8s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r135_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.52%)\n","Fitted model: LightGBM_r135_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t44.28s\t = Training   runtime\n","\t1.12s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r22_BAG_L2 ... Tuning model for up to 153.23s of the 26890.53s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r22_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.60%)\n","Fitted model: XGBoost_r22_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t77.72s\t = Training   runtime\n","\t1.23s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r69_BAG_L2 ... Tuning model for up to 153.23s of the 26811.79s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r69_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r69_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t128.0s\t = Training   runtime\n","\t5.56s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r6_BAG_L2 ... Tuning model for up to 153.23s of the 26682.74s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r6_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.16%)\n","Fitted model: CatBoost_r6_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t23.46s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r138_BAG_L2 ... Tuning model for up to 153.23s of the 26658.25s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r138_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r138_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t123.43s\t = Training   runtime\n","\t8.5s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r121_BAG_L2 ... Tuning model for up to 153.23s of the 26533.78s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r121_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.53%)\n","Fitted model: LightGBM_r121_BAG_L2 ...\n","\t0.8184\t = Validation score   (accuracy)\n","\t11.78s\t = Training   runtime\n","\t0.2s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r172_BAG_L2 ... Tuning model for up to 153.23s of the 26520.95s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r172_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r172_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t127.7s\t = Training   runtime\n","\t2.16s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r180_BAG_L2 ... Tuning model for up to 153.23s of the 26392.15s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r180_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.37%)\n","Fitted model: CatBoost_r180_BAG_L2 ...\n","\t0.9409\t = Validation score   (accuracy)\n","\t55.86s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r76_BAG_L2 ... Tuning model for up to 153.23s of the 26335.25s of remaining time.\n","2024-11-14 12:09:02,529\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r76_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 12:11:35,925\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 12:11:35,942\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 12:11:35,984\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L2' in 0.0488s.\n","2024-11-14 12:11:36,009\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 5218ce0e: FileNotFoundError('Could not fetch metrics for 5218ce0e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L2/5218ce0e')\n","- 1a21c777: FileNotFoundError('Could not fetch metrics for 1a21c777: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L2/1a21c777')\n","- eca20485: FileNotFoundError('Could not fetch metrics for eca20485: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r76_BAG_L2/eca20485')\n","Fitted model: NeuralNetTorch_r76_BAG_L2/5218ce0e ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t125.72s\t = Training   runtime\n","\t7.94s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r197_BAG_L2 ... Tuning model for up to 153.23s of the 26180.51s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for ExtraTrees_r197_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 39.15s compared to 15.32s of available time.\n","Warning: Exception caused ExtraTrees_r197_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: NeuralNetTorch_r121_BAG_L2 ... Tuning model for up to 153.23s of the 25972.98s of remaining time.\n","2024-11-14 12:15:04,920\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r121_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 12:17:38,332\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 12:17:38,357\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 12:17:38,376\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2' in 0.0268s.\n","2024-11-14 12:17:44,518\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- fdaa9724: FileNotFoundError('Could not fetch metrics for fdaa9724: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2/fdaa9724')\n","- 1a1d0e0c: FileNotFoundError('Could not fetch metrics for 1a1d0e0c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2/1a1d0e0c')\n","- 1d474791: FileNotFoundError('Could not fetch metrics for 1d474791: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2/1d474791')\n","- da5756f5: FileNotFoundError('Could not fetch metrics for da5756f5: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r121_BAG_L2/da5756f5')\n","Fitted model: NeuralNetTorch_r121_BAG_L2/fdaa9724 ...\n","\t0.9396\t = Validation score   (accuracy)\n","\t121.44s\t = Training   runtime\n","\t9.99s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r127_BAG_L2 ... Tuning model for up to 153.23s of the 25811.97s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for NeuralNetFastAI_r127_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.91%)\n","Fitted model: NeuralNetFastAI_r127_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t88.56s\t = Training   runtime\n","\t1.5s\t = Validation runtime\n","Hyperparameter tuning model: RandomForest_r16_BAG_L2 ... Tuning model for up to 153.23s of the 25722.12s of remaining time.\n","\tNo hyperparameter search space specified for RandomForest_r16_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 39.67s compared to 15.32s of available time.\n","Warning: Exception caused RandomForest_r16_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n","    hpo_executor.validate_search_space(search_space, self.name)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/hpo/executors.py\", line 512, in validate_search_space\n","    raise EmptySearchSpace\n","autogluon.core.hpo.exceptions.EmptySearchSpace\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n","    hpo_models, hpo_results = model.hyperparameter_tune(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n","    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n","    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n","    return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n","    fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n","    model.fit(**fit_args, time_limit=time_left)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n","    out = self._fit(**kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n","    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n","    self._fit_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 524, in _fit_single\n","    raise TimeLimitExceeded\n","autogluon.core.utils.exceptions.TimeLimitExceeded\n","\n","Hyperparameter tuning model: NeuralNetFastAI_r194_BAG_L2 ... Tuning model for up to 153.23s of the 23516.74s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r194_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r194_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t125.9s\t = Training   runtime\n","\t4.18s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r12_BAG_L2 ... Tuning model for up to 153.23s of the 23389.74s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r12_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.37%)\n","Fitted model: CatBoost_r12_BAG_L2 ...\n","\t0.9406\t = Validation score   (accuracy)\n","\t71.53s\t = Training   runtime\n","\t0.14s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r135_BAG_L2 ... Tuning model for up to 153.23s of the 23317.08s of remaining time.\n","2024-11-14 12:59:20,735\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r135_BAG_L2   |\n","+---------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator              |\n","| Scheduler                        FIFOScheduler                |\n","| Number of trials                 1000                         |\n","+---------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 13:01:54,199\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 13:01:54,228\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 13:01:54,273\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L2' in 0.0543s.\n","2024-11-14 13:01:55,496\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 0099da8b: FileNotFoundError('Could not fetch metrics for 0099da8b: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L2/0099da8b')\n","- f96c2b05: FileNotFoundError('Could not fetch metrics for f96c2b05: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L2/f96c2b05')\n","- 6997eb28: FileNotFoundError('Could not fetch metrics for 6997eb28: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r135_BAG_L2/6997eb28')\n","Fitted model: NeuralNetTorch_r135_BAG_L2/0099da8b ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t124.47s\t = Training   runtime\n","\t8.77s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r4_BAG_L2 ... Tuning model for up to 153.23s of the 23160.99s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for NeuralNetFastAI_r4_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r4_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t129.69s\t = Training   runtime\n","\t2.76s\t = Validation runtime\n","Hyperparameter tuning model: ExtraTrees_r126_BAG_L2 ... Tuning model for up to 153.23s of the 23030.1s of remaining time.\n","\tNo hyperparameter search space specified for ExtraTrees_r126_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","Fitted model: ExtraTrees_r126_BAG_L2 ...\n","\t0.9399\t = Validation score   (accuracy)\n","\t30.56s\t = Training   runtime\n","\t9.66s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r36_BAG_L2 ... Tuning model for up to 153.23s of the 22998.4s of remaining time.\n","2024-11-14 13:04:39,517\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r36_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 13:07:12,985\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 13:07:13,001\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 13:07:13,035\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L2' in 0.0438s.\n","2024-11-14 13:07:16,139\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- d31a8902: FileNotFoundError('Could not fetch metrics for d31a8902: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L2/d31a8902')\n","- 685fed0c: FileNotFoundError('Could not fetch metrics for 685fed0c: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L2/685fed0c')\n","- 2e13326a: FileNotFoundError('Could not fetch metrics for 2e13326a: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r36_BAG_L2/2e13326a')\n","Fitted model: NeuralNetTorch_r36_BAG_L2/d31a8902 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t127.33s\t = Training   runtime\n","\t7.8s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r100_BAG_L2 ... Tuning model for up to 153.23s of the 22840.35s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for NeuralNetFastAI_r100_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r100_BAG_L2 ...\n","\t0.9402\t = Validation score   (accuracy)\n","\t128.06s\t = Training   runtime\n","\t2.98s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r163_BAG_L2 ... Tuning model for up to 153.23s of the 22711.21s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r163_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.19%)\n","Fitted model: CatBoost_r163_BAG_L2 ...\n","\t0.9404\t = Validation score   (accuracy)\n","\t21.81s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Hyperparameter tuning model: CatBoost_r198_BAG_L2 ... Tuning model for up to 153.23s of the 22688.21s of remaining time.\n","\tNo hyperparameter search space specified for CatBoost_r198_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.25%)\n","Fitted model: CatBoost_r198_BAG_L2 ...\n","\t0.9407\t = Validation score   (accuracy)\n","\t43.73s\t = Training   runtime\n","\t0.13s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetFastAI_r187_BAG_L2 ... Tuning model for up to 153.23s of the 22643.33s of remaining time.\n","\tNo hyperparameter search space specified for NeuralNetFastAI_r187_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.92%)\n","Fitted model: NeuralNetFastAI_r187_BAG_L2 ...\n","\t0.9405\t = Validation score   (accuracy)\n","\t128.43s\t = Training   runtime\n","\t1.68s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r19_BAG_L2 ... Tuning model for up to 153.23s of the 22513.76s of remaining time.\n","2024-11-14 13:12:43,989\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r19_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 13:15:17,449\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 13:15:17,457\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 13:15:17,504\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L2' in 0.0520s.\n","2024-11-14 13:15:17,717\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- f52ffbc4: FileNotFoundError('Could not fetch metrics for f52ffbc4: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L2/f52ffbc4')\n","- 10b504e8: FileNotFoundError('Could not fetch metrics for 10b504e8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L2/10b504e8')\n","- 161e8db0: FileNotFoundError('Could not fetch metrics for 161e8db0: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r19_BAG_L2/161e8db0')\n","Fitted model: NeuralNetTorch_r19_BAG_L2/f52ffbc4 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t126.14s\t = Training   runtime\n","\t8.65s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r95_BAG_L2 ... Tuning model for up to 153.23s of the 22358.8s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\tNo hyperparameter search space specified for XGBoost_r95_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.60%)\n","Fitted model: XGBoost_r95_BAG_L2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t80.13s\t = Training   runtime\n","\t1.34s\t = Validation runtime\n","Hyperparameter tuning model: XGBoost_r34_BAG_L2 ... Tuning model for up to 153.23s of the 22277.59s of remaining time.\n","\tNo hyperparameter search space specified for XGBoost_r34_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=2.43%)\n","Fitted model: XGBoost_r34_BAG_L2 ...\n","\t0.9408\t = Validation score   (accuracy)\n","\t126.67s\t = Training   runtime\n","\t2.52s\t = Validation runtime\n","Hyperparameter tuning model: LightGBM_r42_BAG_L2 ... Tuning model for up to 153.23s of the 22149.89s of remaining time.\n","\tNo hyperparameter search space specified for LightGBM_r42_BAG_L2. Skipping HPO. Will train one model based on the provided hyperparameters.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=1, gpus=0, memory=1.50%)\n","Fitted model: LightGBM_r42_BAG_L2 ...\n","\t0.9401\t = Validation score   (accuracy)\n","\t16.36s\t = Training   runtime\n","\t0.79s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r1_BAG_L2 ... Tuning model for up to 153.23s of the 22132.44s of remaining time.\n","2024-11-14 13:19:05,317\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+-------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r1_BAG_L2   |\n","+-------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator            |\n","| Scheduler                        FIFOScheduler              |\n","| Number of trials                 1000                       |\n","+-------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 13:21:38,703\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 13:21:38,727\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 13:21:38,764\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L2' in 0.0462s.\n","2024-11-14 13:21:41,266\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 3 trial(s):\n","- 18133377: FileNotFoundError('Could not fetch metrics for 18133377: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L2/18133377')\n","- 9a3f8482: FileNotFoundError('Could not fetch metrics for 9a3f8482: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L2/9a3f8482')\n","- 1b83a256: FileNotFoundError('Could not fetch metrics for 1b83a256: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r1_BAG_L2/1b83a256')\n","Fitted model: NeuralNetTorch_r1_BAG_L2/18133377 ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t128.02s\t = Training   runtime\n","\t8.17s\t = Validation runtime\n","Hyperparameter tuning model: NeuralNetTorch_r89_BAG_L2 ... Tuning model for up to 153.23s of the 21975.22s of remaining time.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["2024-11-14 13:21:42,747\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------+\n","| Configuration for experiment     NeuralNetTorch_r89_BAG_L2   |\n","+--------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator             |\n","| Scheduler                        FIFOScheduler               |\n","| Number of trials                 1000                        |\n","+--------------------------------------------------------------+\n","\n","View detailed results here: /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2\n"]},{"output_type":"stream","name":"stderr","text":["2024-11-14 13:24:16,139\tINFO timeout.py:54 -- Reached timeout of 153.2251231050319 seconds. Stopping all trials.\n","2024-11-14 13:24:16,150\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-11-14 13:24:16,181\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2' in 0.0383s.\n","2024-11-14 13:24:17,895\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 4 trial(s):\n","- 8f8efc6e: FileNotFoundError('Could not fetch metrics for 8f8efc6e: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2/8f8efc6e')\n","- e565dc15: FileNotFoundError('Could not fetch metrics for e565dc15: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2/e565dc15')\n","- abb1bfd8: FileNotFoundError('Could not fetch metrics for abb1bfd8: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2/abb1bfd8')\n","- 670bf8f3: FileNotFoundError('Could not fetch metrics for 670bf8f3: both result.json and progress.csv were not found at /content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e11_Exploring_Mental_Health_Data/Data/Autogluon/202411_ps4s11_20hr_accuracy/models/NeuralNetTorch_r89_BAG_L2/670bf8f3')\n","Fitted model: NeuralNetTorch_r89_BAG_L2/8f8efc6e ...\n","\t0.9403\t = Validation score   (accuracy)\n","\t122.72s\t = Training   runtime\n","\t9.04s\t = Validation runtime\n","Completed 1/10 k-fold bagging repeats ...\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["# Setting up\n","eval_metric = 'accuracy'\n","label = 'depression'\n","problem_type='binary'\n","hours = 20\n","\n","# Models to exclude\n","excluded_model_types = ['KNN']\n","\n","# Initialize the TabularPredictor\n","predictor = TabularPredictor(label=label, eval_metric=eval_metric, problem_type=problem_type,\n","                             path = os.path.join(base_path, \"Autogluon/202411_ps4s11_20hr_accuracy\"))\n","\n","# Fit the model\n","predictor.fit(train_data=train_data,\n","              time_limit=3600*hours,\n","              presets=\"best_quality\",\n","              excluded_model_types=excluded_model_types,\n","              hyperparameter_tune_kwargs=\"auto\",\n","              num_bag_folds=10,\n","              num_bag_sets = 10,\n","              num_stack_levels=3,\n","              full_weighted_ensemble_additionally=True\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5Y0v9G86LJJ5","executionInfo":{"status":"ok","timestamp":1731955567762,"user_tz":180,"elapsed":3882,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["predictor = TabularPredictor.load(os.path.join(base_path, \"Autogluon/202411_ps4s11_20hr_accuracy\"))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"executionInfo":{"elapsed":1398,"status":"ok","timestamp":1731955569156,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"},"user_tz":180},"id":"Omm8tqXhLJJ6","outputId":"c0676d54-deac-4673-9161-cff5ecd856c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     model  score_val eval_metric  pred_time_val  \\\n","0     LightGBMLarge_BAG_L4   0.941517    accuracy     961.737769   \n","1      WeightedEnsemble_L5   0.941517    accuracy     961.746224   \n","2  WeightedEnsemble_ALL_L5   0.941517    accuracy     961.752530   \n","3        XGBoost_BAG_L4/T1   0.941434    accuracy     962.307966   \n","4       LightGBM_BAG_L4/T1   0.941273    accuracy     961.320187   \n","5      CatBoost_r70_BAG_L4   0.941238    accuracy     961.067057   \n","6       LightGBM_BAG_L3/T3   0.941231    accuracy     629.629249   \n","7      WeightedEnsemble_L4   0.941231    accuracy     629.643276   \n","8     CatBoost_r180_BAG_L3   0.941210    accuracy     629.337719   \n","9       CatBoost_r9_BAG_L4   0.941210    accuracy     961.250075   \n","\n","       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n","0  23596.064260                0.818142          42.878393            4   \n","1  23601.403514                0.008455           5.339254            5   \n","2  23601.227719                0.014761           5.163459            5   \n","3  23597.535761                1.388339          44.349894            4   \n","4  23585.443075                0.400560          32.257209            4   \n","5  23591.278347                0.147430          38.092480            4   \n","6  16874.011506                0.542470          33.741126            3   \n","7  16879.541226                0.014027           5.529721            4   \n","8  16893.508550                0.250940          53.238170            3   \n","9  23597.961420                0.330448          44.775553            4   \n","\n","   can_infer  fit_order  \n","0       True        360  \n","1       True        429  \n","2       True        428  \n","3       True        358  \n","4       True        353  \n","5       True        381  \n","6       True        251  \n","7       True        350  \n","8       True        330  \n","9       True        364  "],"text/html":["\n","  <div id=\"df-c22e8777-7e84-4d38-8528-0d2bc44869c7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBMLarge_BAG_L4</td>\n","      <td>0.941517</td>\n","      <td>accuracy</td>\n","      <td>961.737769</td>\n","      <td>23596.064260</td>\n","      <td>0.818142</td>\n","      <td>42.878393</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>360</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>WeightedEnsemble_L5</td>\n","      <td>0.941517</td>\n","      <td>accuracy</td>\n","      <td>961.746224</td>\n","      <td>23601.403514</td>\n","      <td>0.008455</td>\n","      <td>5.339254</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WeightedEnsemble_ALL_L5</td>\n","      <td>0.941517</td>\n","      <td>accuracy</td>\n","      <td>961.752530</td>\n","      <td>23601.227719</td>\n","      <td>0.014761</td>\n","      <td>5.163459</td>\n","      <td>5</td>\n","      <td>True</td>\n","      <td>428</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XGBoost_BAG_L4/T1</td>\n","      <td>0.941434</td>\n","      <td>accuracy</td>\n","      <td>962.307966</td>\n","      <td>23597.535761</td>\n","      <td>1.388339</td>\n","      <td>44.349894</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>358</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LightGBM_BAG_L4/T1</td>\n","      <td>0.941273</td>\n","      <td>accuracy</td>\n","      <td>961.320187</td>\n","      <td>23585.443075</td>\n","      <td>0.400560</td>\n","      <td>32.257209</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>353</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CatBoost_r70_BAG_L4</td>\n","      <td>0.941238</td>\n","      <td>accuracy</td>\n","      <td>961.067057</td>\n","      <td>23591.278347</td>\n","      <td>0.147430</td>\n","      <td>38.092480</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>381</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LightGBM_BAG_L3/T3</td>\n","      <td>0.941231</td>\n","      <td>accuracy</td>\n","      <td>629.629249</td>\n","      <td>16874.011506</td>\n","      <td>0.542470</td>\n","      <td>33.741126</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>WeightedEnsemble_L4</td>\n","      <td>0.941231</td>\n","      <td>accuracy</td>\n","      <td>629.643276</td>\n","      <td>16879.541226</td>\n","      <td>0.014027</td>\n","      <td>5.529721</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>350</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoost_r180_BAG_L3</td>\n","      <td>0.941210</td>\n","      <td>accuracy</td>\n","      <td>629.337719</td>\n","      <td>16893.508550</td>\n","      <td>0.250940</td>\n","      <td>53.238170</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>330</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CatBoost_r9_BAG_L4</td>\n","      <td>0.941210</td>\n","      <td>accuracy</td>\n","      <td>961.250075</td>\n","      <td>23597.961420</td>\n","      <td>0.330448</td>\n","      <td>44.775553</td>\n","      <td>4</td>\n","      <td>True</td>\n","      <td>364</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c22e8777-7e84-4d38-8528-0d2bc44869c7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c22e8777-7e84-4d38-8528-0d2bc44869c7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c22e8777-7e84-4d38-8528-0d2bc44869c7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-068f2edb-7201-4396-93fb-bcbfabd7ef50\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-068f2edb-7201-4396-93fb-bcbfabd7ef50')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-068f2edb-7201-4396-93fb-bcbfabd7ef50 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"leaderboard_test","summary":"{\n  \"name\": \"leaderboard_test\",\n  \"rows\": 429,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 429,\n        \"samples\": [\n          \"LightGBM_r131_BAG_L4\",\n          \"RandomForestEntr_BAG_L3\",\n          \"NeuralNetTorch_r89_BAG_L3/52f700bf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038980694992294194,\n        \"min\": 0.8183531579829117,\n        \"max\": 0.9415172837437873,\n        \"num_unique_values\": 253,\n        \"samples\": [\n          0.9387948846819679,\n          0.9412031607751159,\n          0.9405818953481878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 357.24060769721734,\n        \"min\": 0.045400381088256836,\n        \"max\": 969.2988948822021,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          961.0701205730438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8800.990867032207,\n        \"min\": 3.536945343017578,\n        \"max\": 23603.734615802765,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          23562.17241358757\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.9530162692598947,\n        \"min\": 0.008455038070678711,\n        \"max\": 10.620455026626587,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          0.15049433708190918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.29930116693188,\n        \"min\": 3.536945343017578,\n        \"max\": 155.43062114715576,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          8.986546993255615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123,\n        \"min\": 1,\n        \"max\": 429,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["leaderboard_test = predictor.leaderboard()\n","leaderboard_test.head(10)"]},{"cell_type":"markdown","metadata":{"id":"KRvCFRQtLJJ6"},"source":["## **Submission**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sIGmKp-KLJJ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731961789594,"user_tz":180,"elapsed":4499146,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"576e11e0-a790-4cdb-cbe2-e1a62733033f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5690000000000001"]},"metadata":{},"execution_count":9}],"source":["# Calibrate the prediction threshold\n","predictor.calibrate_decision_threshold(train_data, metric='accuracy')"]},{"cell_type":"code","source":["model = \"LightGBMLarge_BAG_L4\"\n","suffix = \"m1\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.57, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YseF0a9Xbtp","executionInfo":{"status":"ok","timestamp":1731987390450,"user_tz":180,"elapsed":2128730,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"bfe2196c-78f2-48e4-cad2-b295bda56ed5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9415172837437873\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"BBC8zENpLJJ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731963822657,"user_tz":180,"elapsed":2030675,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"dd896d4f-c1b8-4e15-aa4e-8b2aa2062795"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9415172837437873\n"]}],"source":["model = \"LightGBMLarge_BAG_L4\"\n","suffix = \"m1\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.50, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"]},{"cell_type":"code","source":["model = \"WeightedEnsemble_L5\"\n","suffix = \"m2\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCNVllVcmszV","executionInfo":{"status":"ok","timestamp":1731965847391,"user_tz":180,"elapsed":2024747,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"01923335-6298-4f8c-bb1d-3569a57eaaf0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9415172837437873\n"]}]},{"cell_type":"code","source":["model = \"WeightedEnsemble_ALL_L5\"\n","suffix = \"m3\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZlcRUXAm4cS","executionInfo":{"status":"ok","timestamp":1731967837587,"user_tz":180,"elapsed":1990210,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"29ea6174-7c15-40bb-c3f6-7a9bcc8347ab"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9415172837437873\n"]}]},{"cell_type":"code","source":["model = \"XGBoost_BAG_L4/T1\"\n","suffix = \"m4\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_udUDV1tm8jq","executionInfo":{"status":"ok","timestamp":1731969870442,"user_tz":180,"elapsed":2032870,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"5437af6f-d333-4614-bcb4-8edad1b05292"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9414335176188083\n"]}]},{"cell_type":"code","source":["model = \"LightGBM_BAG_L4/T1\"\n","suffix = \"m5\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7Z8skdom_KF","executionInfo":{"status":"ok","timestamp":1731971852533,"user_tz":180,"elapsed":1982103,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"cf866c25-da63-4bce-e2f1-92acfc1ca948"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9412729658792651\n"]}]},{"cell_type":"code","source":["model = \"CatBoost_r70_BAG_L4\"\n","suffix = \"m6\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['Depression'] = predictor.predict_proba(test_data, as_pandas=False, model=model)[:, 1]\n","sub_autogluon['Depression'] = np.where(sub_autogluon['Depression'] > 0.5, 1, 0)\n","sub_autogluon.to_csv(os.path.join(base_path, f'submission_autogluon2_{suffix}.csv'), index=False)\n","\n","# Accuracy\n","oof_autogluon = predictor.predict_proba_oof(model=model)[1]\n","oof_autogluon.to_csv(os.path.join(base_path, f'oof_autogluon2_{suffix}.csv'), index=False)\n","predicted_classes = (oof_autogluon > 0.50).astype(int)\n","accuracy = accuracy_score(train_data['depression'], predicted_classes)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9PxUCwSnC_h","executionInfo":{"status":"ok","timestamp":1731973804581,"user_tz":180,"elapsed":1952071,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"cf499ffa-012b-476c-8d65-ea63c9f4d771"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9412380633271905\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ydo2BJDu4ktU"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyMdacqipP1kL/1OcDmSIcT8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}